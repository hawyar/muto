{
  "version": 3,
  "sources": ["../bin/cli.js", "../lib/engine.ts", "../lib/types.ts"],
  "sourcesContent": ["#!/usr/bin/env node\nimport arg from \"arg\"\nimport {createDataset} from \"../dist/muto.js\"\n\nconst usage = `\nUsage:\n  $muto [options]\n  \n  commands:\n    upload\tuploads the specified file to S3\n\n  options:\n    -h, --help      output usage information \\n -v, --version   output the version number\n    -v, --version  output the version number\n\n    -f --from       The path to the file to source from\n    -t --to         The path to the file to target to\n`;\n\nconst args = arg({\n    \"--help\": Boolean,\n    \"--version\": Boolean,\n    \"--from\": String,\n    \"--to\": String,\n\n    // aliases\n    \"-h\": \"--help\",\n    \"-v\": \"--version\",\n    \"-f\": \"--from\",\n    \"-t\": \"--to\",\n});\n\nif (args[\"--help\"]) {\n    stdWrite(usage);\n    process.exit(0);\n}\n\nif (args[\"--version\"]) {\n    stdWrite(`v0.1.0`);\n    process.exit(0);\n}\nconst commands = args[\"_\"];\nif (Object.keys(args).length === 1) {\n    stdWrite(usage);\n    process.exit(0);\n}\n\nconst operations = {\n    upload: \"UPLOAD\",\n};\n\nvoid (async function run() {\n    let input = {\n        from: '',\n        to: '',\n    }\n    if (args[\"--from\"]) {\n        input.from = args[\"--from\"];\n    }\n\n    if (args[\"--to\"]) {\n        input.to = args[\"--to\"];\n    }\n\n    if (commands.indexOf(\"upload\") == -1) {\n        input.operation = operations.upload;\n    }\n\n    const d = createDataset(input.from, {\n        delimiter: \",\",\n    })\n\n    const confirmed = await d.uploadToS3()\n\n    if (!confirmed) {\n        stdWrite(\"Upload cancelled\");\n        process.exit(0);\n    }\n    console.log(confirmed);\n\n    stdWrite(\"Upload complete\");\n    //\n    // if (!args[\"--from\"]) {\n    //     stdWrite(\n    //         `Error: no source given for operation, provide a valid source path \\nExample: \\n \\t File system: ./my-datasets  \\n \\t AWS S3: s3://my-bucket/datasets/\n    // \t\t`\n    //     );\n    //     process.exit(1);\n    // }\n    //\n    // if (!args[\"--to\"]) {\n    //     stdWrite(\n    //         `Error: no destination given for operation, provide a valid destination path \\nExample: \\n \\t File system: ./my-datasets  \\n \\t AWS S3: s3://my-bucket/datasets/\n    // \t\t`\n    //     );\n    //     process.exit(1);\n    // }\n    //\n    // config.from = args[\"--from\"];\n    // config.to = args[\"--to\"];\n    //\n    // const w = createWorkflow(\"my_etl\");\n    //\n    // // if fs and not dir throw before initializing engine\n    //\n    // if (\n    //     config.from.startsWith(\"/\") ||\n    //     config.from.startsWith(\"./\") ||\n    //     config.from.startsWith(\"../\")\n    // ) {\n    //     const isDir = await fs\n    //         .stat(config.from)\n    //         .then((stat) => stat.isDirectory())\n    //         .catch((err) => {\n    //             stdWrite(\"Error: given source is not a valid directory\");\n    //             process.exit(1);\n    //         });\n    //\n    //     if (!isDir) {\n    //         stdWrite(\n    //             \"Error: unable to open source, please make sure source is a valid path\"\n    //         );\n    //         process.exit(1);\n    //     }\n    //\n    //     stdWrite(`Created new worklow`);\n    //\n    //     const files = await fs\n    //         .readdir(config.from)\n    //         .then((files) => files)\n    //         .catch((err) => {\n    //             stdWrite(err);\n    //             process.exit(1);\n    //         });\n    //\n    //     for (const file of files) {\n    //         if (!file.endsWith(\".csv\")) return;\n    //         const src = \"./\" + path.normalize(path.join(config.from, file));\n    //\n    //         stdWrite(`Adding ${src} to workflow`);\n    //         const d1 = await w\n    //             .add(src, {\n    //                 delimiter: \",\",\n    //                 quote: '\"',\n    //                 header: true,\n    //             })\n    //             .catch((err) => {\n    //                 console.log(err);\n    //             });\n    //\n    //         console.log(d1);\n    //     }\n    // }\n\n    process.exit(0);\n})();\n\nfunction stdWrite(msg) {\n    typeof msg === \"string\"\n        ? process.stdout.write(`${msg} \\n`)\n        : process.stdout.write(`${JSON.stringify(msg, null, 2)}\\n`);\n}\n\n// catch unhandled promises\nprocess.on(\"unhandledRejection\", (reason, promise) => {\n    stdWrite(reason);\n    process.exit(1);\n});\n", "import * as fs from \"fs\";\nimport {CreateMultipartUploadCommand, PutObjectCommand, S3Client, S3ClientConfig} from \"@aws-sdk/client-s3\";\nimport {fromIni} from \"@aws-sdk/credential-providers\";\nimport {AthenaClient, AthenaClientConfig} from \"@aws-sdk/client-athena\";\nimport {ChildProcessWithoutNullStreams, spawn} from \"child_process\";\nimport os from \"os\";\nimport path from \"path\";\nimport {createInterface} from \"readline\";\nimport {\n    connectorType,\n    Dataset,\n    DatasetOptions,\n    datasetStateType,\n    env,\n    loaderType,\n    mlr,\n    ProcessResult,\n    Shape,\n    sqlparser,\n    Workflow,\n} from \"./types\"\n\nclass _Dataset implements Dataset {\n    name: string\n    source: string;\n    destination: string;\n    addedAt: Date;\n    options: DatasetOptions;\n    shape: Shape\n    env: env;\n    state: datasetStateType\n    connector: connectorType | null\n    loader: loaderType | null\n    pcount: number\n\n    constructor(source: string, options: DatasetOptions) {\n        this.name = options && options.name ? options.name : path.basename(source);\n        this.source = source;\n        this.destination = options.destination\n        this.options = options\n        this.env = this.determineEnv()\n        this.shape = {\n            type: \"\",\n            columns: [],\n            header: false,\n            encoding: \"\",\n            bom: false,\n            size: 0,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: \"\",\n            errors: {},\n            warnings: {},\n            preview: []\n        }\n        this.addedAt = new Date();\n        this.state = 'init'\n        this.connector = null\n        this.loader = null\n        this.pcount = 0\n    }\n\n    async toJson(): Promise<ChildProcessWithoutNullStreams> {\n        const json = this.exec(mlr, [\"--icsv\", \"--ojson\", \"clean-whitespace\", this.source])\n        if (!json.stdout) {\n            throw new Error(`failed to convert ${this.source} from CSV to JSON`)\n        }\n        return json\n    }\n\n    async toCSV(): Promise<ChildProcessWithoutNullStreams> {\n        const json = this.exec(mlr, [\"--icsv\", \"--ocsv\", \"cat\", this.source])\n        if (!json.stdout) {\n            throw new Error(`failed to convert ${this.source} from JSON to CSV`)\n        }\n        return json\n    }\n\n\n    async rowCount(): Promise<number> {\n        const count = await this.exec(mlr, [`--ojson`, `count`, this.source])\n\n        const rowCountExec = await this.promisifyProcessResult(count)\n\n        if (rowCountExec.code !== 0) {\n            throw new Error(`Error while counting rows: ${rowCountExec.stderr}`)\n        }\n\n        if (rowCountExec.stderr) {\n            throw new Error(rowCountExec.stderr)\n        }\n\n        const r = JSON.parse(rowCountExec.stdout)\n\n        if (r.length === 0) {\n            throw new Error('No rows found')\n        }\n\n        return r[0].count\n    }\n\n\n    async getColumnHeader(): Promise<string[] | null> {\n        const res = await this.exec(mlr, [`--icsv`, `--ojson`, `head`, `-n`, `1`, this.source])\n\n        const colExec = await this.promisifyProcessResult(res)\n\n        if (colExec.code !== 0) {\n            return null\n        }\n\n        if (colExec.stderr) {\n            throw new Error(colExec.stderr)\n        }\n        const columns = JSON.parse(colExec.stdout)\n\n        if (columns.length === 0) {\n            this.shape.header = false\n            return null\n        }\n\n        this.shape.columns = Object.keys(columns[0])\n        this.shape.header = true\n        return this.shape.columns\n    }\n\n    async formatValues() {\n        // --opprint format-values\n        const res = await this.exec(mlr, [`--icsv`, `format-values`, this.source])\n        const formatVal = await this.promisifyProcessResult(res)\n\n        if (formatVal.code !== 0) {\n            return null\n        }\n\n        if (formatVal.stderr) {\n            throw new Error(formatVal.stderr)\n        }\n\n        return this.shape.columns\n    }\n\n\n    async preview(count = 20, streamTo?: string): Promise<string[][] | string> {\n        let write: fs.WriteStream\n\n        const maxPreview = 1024 * 1024 * 10\n\n        const fsp = fs.promises\n        const stat = await fsp.stat(this.source)\n\n        if (streamTo && streamTo !== this.source && fs.createWriteStream(streamTo) instanceof fs.WriteStream || stat.size > maxPreview) {\n\n            if (streamTo === undefined) throw new Error('stream-destination-undefined')\n            write = fs.createWriteStream(streamTo)\n\n            const previewExec = await this.exec(mlr, [`--icsv`, `--ojson`, `head`, `-n`, count.toString(), this.source])\n\n            previewExec.stdout.pipe(write)\n\n            console.warn(`\uD83D\uDC40 Preview saved to: ${streamTo}`)\n            return streamTo\n        }\n\n        const previewExec = await this.exec(mlr, [`--icsv`, `--ojson`, `head`, `-n`, count.toString(), this.source])\n\n        const prev = await this.promisifyProcessResult(previewExec)\n\n        if (prev.stderr) {\n            throw new Error(prev.stderr)\n        }\n\n        if (prev.code !== 0) {\n            throw new Error(`Error while executing mlr command`)\n        }\n\n        this.shape.preview = JSON.parse(prev.stdout)\n        return this.shape.preview\n    }\n\n\n    async detectShape(): Promise<Shape> {\n        const path = this.source\n        const shape: Shape = {\n            type: '',\n            size: 0,\n            columns: [''],\n            header: false,\n            encoding: 'utf-8',\n            bom: false,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: ',',\n            errors: {},\n            warnings: {},\n            preview: [['']],\n        };\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`path-doesnt-exists: ${path} ,provide a valid path to a CSV file`)\n        }\n\n        const stat = fs.statSync(path)\n        this.shape.size = stat.size\n\n        if (stat.size > 1024 * 1024 * 1024) {\n            throw new Error(`file-size-exceeds-limit: ${path} is too large, please limit to under 1GB for now`)\n        }\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`${path} does not exist, provide a valid path to a CSV file`)\n        }\n\n        if (os.platform() === \"win32\") {\n            // TODO: handle\n            throw new Error(`scream`)\n        }\n\n        const mime = this.exec(\"file\", [path, \"--mime-type\"])\n\n        const mimeRes = await this.promisifyProcessResult(mime)\n\n        if (mimeRes.stderr) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        if (mimeRes.code !== 0) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        shape.type = mimeRes.stdout.trim()\n\n        const readLine = createInterface({\n            input: fs.createReadStream(path),\n            crlfDelay: Infinity,\n        });\n\n        let count = 0;\n        const max = 20;\n\n        const first = {\n            row: [''],\n            del: \"\",\n        };\n\n        // hold the previous line while rl proceeds to next line using \\r\\n as a delimiter\n        let previous = \"\";\n\n        const delimiters = [\",\", \";\", \"\\t\", \"|\", \":\", \" \", \"|\"];\n\n        readLine.on(\"line\", (current) => {\n            if (count === 0) {\n                delimiters.forEach((d) => {\n                    if (current.split(d).length > 1) {\n                        first.row = current.split(d)\n                        first.del = d;\n                    }\n                });\n\n                if (first.del === \"\" || first.row.length <= 1) {\n                    shape.errors[\"unrecognizedDelimiter\"] = `${path} does not have a recognized delimiter`;\n                    shape.header = false;\n                }\n                const isDigit = /\\d+/;\n\n                // assuming that numbers shouldn't start as column header\n                const hasDigitInHeader = first.row.some((el) => isDigit.test(el));\n                // if (hasDigitInHeader) {\n                //     shape.header = false;\n                //     shape.warnings[\"noHeader\"] = `no header found`;\n                //     count++;\n                //     return;\n                // }\n                shape.header = true;\n                shape.delimiter = first.del;\n                shape.columns = first.row;\n            }\n\n            if (count > 0 && count < max) {\n                // there is a chance the record spans next line\n                const inlineQuotes = current.split(`\"`).length - 1;\n\n                if (previous) {\n                    if (inlineQuotes % 2 !== 0) {\n                        // TODO: make sure previous + current\n                        // console.log(previous + l);\n                        shape.spanMultipleLines = true;\n                    }\n                }\n                // if odd number of quotes and consider escaped quotes such as: \"aaa\",\"b\"\"bb\",\"ccc\"\n                if (\n                    inlineQuotes % 2 !== 0 &&\n                    current.split(`\"\"`).length - 1 !== 1\n                ) {\n                    previous = current;\n                }\n\n                const width = current.split(first.del).length;\n\n                if (width !== first.row.length) {\n                    shape.errors['rowWidthMismatch'] = `row width mismatch`;\n                    return;\n                }\n                shape.preview.push(current.split(first.del));\n            }\n            count++;\n        });\n        return shape;\n    }\n\n    determineLoader(): void {\n        if (this.destination.startsWith(\"s3://\")) {\n            this.loader = s3Client({\n                credentials: credentials(\"default\"),\n                region: \"us-east-2\",\n            });\n            return;\n        }\n\n        if (\n            this.source.startsWith(\"/\") ||\n            this.source.startsWith(\"../\") ||\n            this.source.startsWith(\"./\")\n        ) {\n            this.loader = fs.createReadStream(this.source);\n            return;\n        }\n    }\n\n    determineConnector(): void {\n        if (this.env === \"local\") {\n            this.connector = fs.createReadStream(this.source);\n            return;\n        }\n\n        if (this.env === \"aws\") {\n            this.connector = s3Client({\n                credentials: credentials(\"default\"),\n                region: \"us-east-2\",\n            });\n            return;\n        }\n        throw new Error(`unsupported-source for: ${this.source}`)\n    }\n\n    determineEnv(): env {\n        if (\n            this.source.startsWith(\"/\") ||\n            this.source.startsWith(\"../\") ||\n            this.source.startsWith(\"./\")\n        ) {\n            return \"local\";\n        }\n\n        if (this.source.startsWith(\"s3://\")) {\n            return \"aws\";\n        }\n\n        throw new Error(`invalid-source-type: ${this.source}`);\n    }\n\n    fileSize(): number {\n        const max = 1024 * 1024 * 50\n\n        if (!fs.existsSync(this.source)) {\n            throw new Error(`path-doesnt-exists: ${this.source} ,provide a valid path to a CSV file`)\n        }\n\n        const stat = fs.statSync(this.source)\n\n        if (stat.size > max) {\n            throw new Error(`file-size-exceeds-limit: ${this.source} is too large, please limit to 50MB`)\n        }\n        return stat.size\n    }\n\n    async uploadToS3(): Promise<string> {\n        if (!this.source || !this.destination) {\n            throw new Error('source or destination not set. Both must be defined to upload to S3')\n        }\n\n        const fStream = fs.createReadStream(this.source)\n\n        if (!fStream.readable) {\n            throw new Error('failed-to-read-source: Make sure the provided file is readable')\n        }\n\n        const fSize = this.fileSize()\n\n        if (fSize > 100 * 1024 * 1024) {\n            //TODO: init multipart upload then upload parts\n            console.warn(`file size ${fSize} is larger than 100MB`)\n        }\n\n        const {data: uri, err} = parseS3Uri(this.destination, {\n            file: true,\n        });\n\n        if (err.toString().startsWith(`invalid-s3-uri`)) {\n            throw new Error(`failed-to-parse-s3-uri: ${err}`)\n        }\n\n        if (!uri.file) {\n            uri.file = path.basename(this.source)\n            console.warn(\"Destination filename not provided. Using source source basename\" + uri.file)\n        }\n\n        console.log(`uploading ${this.source} to ${this.destination}`);\n\n        const s3 = s3Client({\n            region: \"us-east-2\",\n        })\n\n        const res = await s3.send(new PutObjectCommand({\n            Bucket: uri.bucket,\n            Key: uri.key + uri.file,\n            Body: fStream,\n        })).catch(err => {\n            throw new Error(`failed-upload-s3: Error while uploading to S3: ${err}`)\n        }).finally(() => {\n            fStream.close()\n        })\n\n        if (res.$metadata.httpStatusCode !== 200) {\n            throw new Error(`failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`)\n        }\n\n        if (!res.$metadata.requestId) throw new Error(`failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`)\n        return res.$metadata.requestId\n    }\n\n    async initMultipartUpload(\n        bucket: string,\n        key: string\n    ): Promise<string> {\n\n        const client = s3Client({\n            credentials: credentials(\"default\"),\n            region: \"us-east-2\",\n        });\n\n        const command = new CreateMultipartUploadCommand({\n            Bucket: bucket,\n            ContentEncoding: \"utf8\",\n            ContentType: \"text/csv\",\n            Key: key,\n        });\n\n        const result = await client.send(command);\n\n        if (result.$metadata.httpStatusCode !== 200) {\n            throw new Error(`failed-multipart-upload: Error while creating multipart upload: ${result.UploadId} with status code ${result.$metadata.httpStatusCode}`)\n        }\n\n        if (!result.UploadId) {\n            throw new Error(`failed-multipart-upload: Error while creating multipart upload: ${result.UploadId}`)\n        }\n\n        return result.UploadId\n    }\n\n    exec(cmd: string, args: string[]): ChildProcessWithoutNullStreams {\n        console.log(`exec: ${cmd} ${args.join(' ')}`)\n\n        if (this.pcount > 5) {\n            throw new Error(`too-many-processes: ${this.pcount}`)\n        }\n\n        this.pcount++\n        return spawn(cmd, args, {})\n    }\n\n    promisifyProcessResult(child: ChildProcessWithoutNullStreams): Promise<ProcessResult> {\n        const result: ProcessResult = {\n            stdout: '',\n            stderr: '',\n            code: 0\n        }\n\n        return new Promise((resolve, reject) => {\n            child.stdout.on('data', (data) => {\n                result.stdout += data\n            })\n\n            child.stderr.on('data', (data) => {\n                result.stderr += data\n            })\n\n            child.on('close', (code) => {\n                result.code = code === 0 ? 0 : 1\n                resolve(result)\n            })\n\n            child.on('error', (err) => {\n                reject(err)\n            })\n        })\n    }\n}\n\nexport function createDataset(source: string, opt: DatasetOptions): Dataset {\n    return new _Dataset(source, opt);\n}\n\nfunction parseQuery(query: string): Promise<any> {\n    const qq = {\n        query: query,\n        select: [],\n        from: [],\n        where: [],\n        orderBy: [],\n        groupBy: [],\n        limit: null,\n        offset: null,\n    }\n\n    const child = spawn(sqlparser, [qq.query])\n\n    return new Promise((resolve, reject) => {\n        child.on('error', (err) => {\n            reject(err)\n        })\n\n        child.on('close', (code) => {\n            if (code !== 0) {\n                reject(`failed-sqlparser: Error while parsing query: ${code}`)\n            }\n        })\n\n        child.stdout.on('data', (data) => {\n            const parsed = JSON.parse(data.toString())\n            if (parsed.error) {\n                reject(`failed-sqlparser: Error while parsing query: ${parsed.error}`)\n            }\n            resolve(parsed)\n        })\n\n    })\n}\n\nclass _Workflow implements Workflow {\n    name: string;\n    datasets: Map<string, Dataset>;\n    readonly createdAt: Date;\n    env: env;\n    queryy: string;\n\n    constructor(name: string) {\n        this.name = name;\n        this.datasets = new Map();\n        this.createdAt = new Date();\n        this.env = 'local';\n        this.queryy = '';\n    }\n\n    list(): Dataset[] {\n        return Array.from(this.datasets.values());\n    }\n\n    remove(dataset: Dataset) {\n        this.datasets.delete(dataset.source);\n    }\n\n    get(source: string): Dataset | null {\n        return this.datasets.get(source) || null;\n    }\n\n    add(d: Dataset): Promise<string> {\n        return new Promise((resolve, reject) => {\n            if (this.datasets.has(d.source)) {\n                reject(`failed-add-dataset: Dataset with source ${d.source} already exists`)\n            }\n            Promise.all([d.determineConnector(), d.determineLoader()]).catch(err => {\n                throw new Error(err)\n            }).then(() => {\n                this.datasets.set(d.source, d);\n                resolve(d.source);\n            }).catch(err => {\n                reject(err)\n            })\n        })\n    }\n\n    query(q: string): Promise<string> {\n        parseQuery(q).then(parsed => {\n            this.queryy = q;\n            console.log(parsed)\n        }).catch(err => {\n            throw new Error(err)\n        })\n        return new Promise((resolve, reject) => {\n            resolve(\"ok\")\n        })\n    }\n}\n\nexport function createWorkflow(name: string): Workflow {\n    return new _Workflow(name);\n}\n\nconst credentials = (profile: string) => fromIni({\n    profile: profile,\n    mfaCodeProvider: async (mfaSerial) => {\n        return mfaSerial\n    },\n});\n\nlet s3: S3Client;\n\nfunction s3Client(config: S3ClientConfig): S3Client {\n    if (!s3) {\n        console.log('creating s3 client')\n        s3 = new S3Client(config);\n    }\n    return s3;\n}\n\nlet athena: AthenaClient\n\nfunction athenaClient(config: AthenaClientConfig): AthenaClient {\n    if (!athena) {\n        console.log('creating athena client')\n        athena = new AthenaClient(config);\n    }\n    return athena;\n}\n\n/**\n * Parses S3 (s3://) style URIs\n */\nfunction parseS3Uri(\n    uri: string,\n    options: {\n        file: boolean;\n    }\n): {\n    data: {\n        bucket: string;\n        key: string;\n        file: string;\n    };\n    err: string;\n} {\n    const opt = {\n        file: options && options.file ? options.file : false,\n    };\n\n    if (!uri.startsWith(\"s3://\") || uri.split(\":/\")[0] !== \"s3\") {\n        throw new Error(`invalid-s3-uri: ${uri}`);\n    }\n\n    let err = \"\";\n    const result = {\n        bucket: \"\",\n        key: \"\",\n        file: \"\",\n    };\n\n    const src = uri.split(\":/\")[1];\n    const [bucket, ...keys] = src.split(\"/\").splice(1);\n\n    result.bucket = bucket;\n    result.key = keys.join(\"/\");\n\n    keys.forEach((k, i) => {\n        if (i === keys.length - 1) {\n            const last = k.split(\".\").length;\n            if (opt.file && last === 1) err = `uri should be a given, given: ${uri}`;\n\n            if (!opt.file && last === 1) return;\n\n            if (!opt.file && last > 1) {\n                err = `Invalid S3 uri, ${uri} should not end with a file name`;\n                return;\n            }\n\n            if (!opt.file && k.split(\".\")[1] !== \"\" && last > 1)\n                err = `${uri} should not be a file endpoint: ${k}`;\n\n            if (last > 1 && k.split(\".\")[1] !== \"\") result.file = k;\n        }\n    });\n    return {\n        data: result,\n        err: err,\n    };\n}\n", "import {S3Client} from \"@aws-sdk/client-s3\";\nimport {join} from \"path\";\nimport fs from \"fs\";\nimport {ChildProcessWithoutNullStreams,} from \"child_process\";\n\nexport enum Delimiter {\n    COMMA = \",\",\n    TAB = \"\\t\",\n    SPACE = \" \",\n    PIPE = \"|\",\n    SEMICOLON = \";\",\n    COLON = \":\",\n    NONE = \"\",\n}\n\nexport const mlr = join(process.cwd(), 'node_modules', '.bin', 'mlr@v6.0.0')\nexport const sqlparser = join(process.cwd(), 'node_modules', '.bin', \"sqlparser@v0.1.4\")\n\nexport type env = 'local' | 'aws'\nexport type connectorType = S3Client | fs.ReadStream\nexport type loaderType = S3Client | fs.ReadStream\n\n// TODO: better error message for errors in transform\nexport type datasetStateType = 'init' | 'transforming' | 'uploading' | 'cancelled' | 'uploaded' | 'ready'\n// type ShapeErrType = 'unrecognizedDelimiter' | 'noHeader' | 'invalidFileType' | 'rowWidthMismatch'\n\nexport type Shape = {\n    type: string,\n    columns: Array<string>,\n    header: boolean,\n    encoding: string,\n    bom: boolean,\n    size: number,\n    spanMultipleLines: boolean,\n    quotes: boolean,\n    delimiter: string,\n    errors: { [key: string]: string }\n    warnings: { [key: string]: string },\n    preview: string[][],\n}\nexport type DatasetOptions = {\n    name: string,\n    destination: string;\n    columns: Array<string>,\n    header: boolean,\n    quotes: boolean,\n    output: 'csv' | 'json'\n    delimiter: Delimiter\n}\n\nexport interface Dataset {\n    source: string\n    destination: string\n    addedAt: Date;\n    options: DatasetOptions;\n    shape: Shape\n    state: datasetStateType\n    connector: connectorType | null\n    loader: loaderType | null\n\n\n    toJson(): Promise<ChildProcessWithoutNullStreams>\n\n    toCSV(): Promise<ChildProcessWithoutNullStreams>\n\n    determineEnv(): env\n\n    determineConnector(): void\n\n    determineLoader(): void\n\n    getColumnHeader(): Promise<string[] | null>\n\n    rowCount(): Promise<number>\n\n    fileSize(): number\n\n    preview(count: number, streamTo?: string): Promise<string[][] | string>\n\n    detectShape(): Promise<Shape>\n\n    uploadToS3(bucket: string, key: string): Promise<string>\n\n    initMultipartUpload(bucket: string, key: string): Promise<string>\n\n}\n\n\nexport interface Workflow {\n    name: string\n    createdAt: Date\n    datasets: Map<string, Dataset>\n    env: env\n    queryy: string\n\n    add(dataset: Dataset): Promise<string>\n\n    query(q: string): Promise<string>\n\n    remove(dataset: Dataset): void\n\n    get(name: string): Dataset | null\n\n    list(): Array<Dataset>\n}\n\nexport type ProcessResult = {\n    stdout: string,\n    stderr: string,\n    code: number\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;AACA;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;ACNA;;;;;;;;;;;;;;;;;AAcO,IAAM,IAAM,EAAK,QAAQ,OAAO,gBAAgB,QAAQ;AAAxD,IACM,IAAY,EAAK,QAAQ,OAAO,gBAAgB,QAAQ;ADMrE,IAAA,IAAA,MAAkC;EAa9B,YAAY,GAAgB,GAAyB;AACjD,SAAK,OAAO,KAAW,EAAQ,OAAO,EAAQ,OAAO,EAAK,SAAS,IACnE,KAAK,SAAS,GACd,KAAK,cAAc,EAAQ,aAC3B,KAAK,UAAU,GACf,KAAK,MAAM,KAAK,gBAChB,KAAK,QAAQ,EACT,MAAM,IACN,SAAS,IACT,QAAQ,OACR,UAAU,IACV,KAAK,OACL,MAAM,GACN,mBAAmB,OACnB,QAAQ,OACR,WAAW,IACX,QAAQ,IACR,UAAU,IACV,SAAS,MAEb,KAAK,UAAU,IAAI,QACnB,KAAK,QAAQ,QACb,KAAK,YAAY,MACjB,KAAK,SAAS,MACd,KAAK,SAAS;;EAGZ,SAAkD;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AACpD,UAAM,IAAO,KAAK,KAAK,GAAK,CAAC,UAAU,WAAW,oBAAoB,KAAK;AAC3E,UAAI,CAAC,EAAK;AACN,cAAM,IAAI,MAAM,qBAAqB,KAAK;AAE9C,aAAO;;;EAGL,QAAiD;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AACnD,UAAM,IAAO,KAAK,KAAK,GAAK,CAAC,UAAU,UAAU,OAAO,KAAK;AAC7D,UAAI,CAAC,EAAK;AACN,cAAM,IAAI,MAAM,qBAAqB,KAAK;AAE9C,aAAO;;;EAIL,WAA4B;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AAC9B,UAAM,IAAQ,MAAM,KAAK,KAAK,GAAK,CAAC,WAAW,SAAS,KAAK,UAEvD,IAAe,MAAM,KAAK,uBAAuB;AAEvD,UAAI,EAAa,SAAS;AACtB,cAAM,IAAI,MAAM,8BAA8B,EAAa;AAG/D,UAAI,EAAa;AACb,cAAM,IAAI,MAAM,EAAa;AAGjC,UAAM,IAAI,KAAK,MAAM,EAAa;AAElC,UAAI,EAAE,WAAW;AACb,cAAM,IAAI,MAAM;AAGpB,aAAO,EAAE,GAAG;;;EAIV,kBAA4C;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AAC9C,UAAM,IAAM,MAAM,KAAK,KAAK,GAAK,CAAC,UAAU,WAAW,QAAQ,MAAM,KAAK,KAAK,UAEzE,IAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,EAAQ,SAAS;AACjB,eAAO;AAGX,UAAI,EAAQ;AACR,cAAM,IAAI,MAAM,EAAQ;AAE5B,UAAM,IAAU,KAAK,MAAM,EAAQ;AAEnC,aAAI,EAAQ,WAAW,IACnB,MAAK,MAAM,SAAS,OACb,QAGX,MAAK,MAAM,UAAU,OAAO,KAAK,EAAQ,KACzC,KAAK,MAAM,SAAS,MACb,KAAK,MAAM;;;EAGhB,eAAe;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AAEjB,UAAM,IAAM,MAAM,KAAK,KAAK,GAAK,CAAC,UAAU,iBAAiB,KAAK,UAC5D,IAAY,MAAM,KAAK,uBAAuB;AAEpD,UAAI,EAAU,SAAS;AACnB,eAAO;AAGX,UAAI,EAAU;AACV,cAAM,IAAI,MAAM,EAAU;AAG9B,aAAO,KAAK,MAAM;;;EAIhB,QAAQ,IAAQ,IAAI,GAAiD;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AACvE,UAAI,GAEE,IAAa,OAAO,OAAO,IAG3B,IAAO,MADE,AAAA,WACQ,KAAK,KAAK;AAEjC,UAAI,KAAY,MAAa,KAAK,UAAa,AAAA,oBAAkB,cAAwB,iBAAe,EAAK,OAAO,GAAY;AAE5H,YAAI,MAAa;AAAW,gBAAM,IAAI,MAAM;AAC5C,eAAA,IAAW,AAAA,oBAAkB,IAET,OAAM,KAAK,KAAK,GAAK,CAAC,UAAU,WAAW,QAAQ,MAAM,EAAM,YAAY,KAAK,UAExF,OAAO,KAAK,IAExB,QAAQ,KAAK,+BAAwB,MAC9B;;AAGX,UAAM,IAAc,MAAM,KAAK,KAAK,GAAK,CAAC,UAAU,WAAW,QAAQ,MAAM,EAAM,YAAY,KAAK,UAE9F,IAAO,MAAM,KAAK,uBAAuB;AAE/C,UAAI,EAAK;AACL,cAAM,IAAI,MAAM,EAAK;AAGzB,UAAI,EAAK,SAAS;AACd,cAAM,IAAI,MAAM;AAGpB,aAAA,KAAK,MAAM,UAAU,KAAK,MAAM,EAAK,SAC9B,KAAK,MAAM;;;EAIhB,cAA8B;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AAChC,UAAM,IAAO,KAAK,QACZ,IAAe,EACjB,MAAM,IACN,MAAM,GACN,SAAS,CAAC,KACV,QAAQ,OACR,UAAU,SACV,KAAK,OACL,mBAAmB,OACnB,QAAQ,OACR,WAAW,KACX,QAAQ,IACR,UAAU,IACV,SAAS,CAAC,CAAC;AAGf,UAAI,CAAI,AAAA,aAAW;AACf,cAAM,IAAI,MAAM,uBAAuB;AAG3C,UAAM,IAAU,AAAA,WAAS;AAGzB,UAFA,KAAK,MAAM,OAAO,EAAK,MAEnB,EAAK,OAAO,OAAO,OAAO;AAC1B,cAAM,IAAI,MAAM,4BAA4B;AAGhD,UAAI,CAAI,AAAA,aAAW;AACf,cAAM,IAAI,MAAM,GAAG;AAGvB,UAAI,EAAG,eAAe;AAElB,cAAM,IAAI,MAAM;AAGpB,UAAM,IAAO,KAAK,KAAK,QAAQ,CAAC,GAAM,iBAEhC,IAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,EAAQ;AACR,cAAM,IAAI,MAAM,+BAA+B,EAAQ;AAG3D,UAAI,EAAQ,SAAS;AACjB,cAAM,IAAI,MAAM,+BAA+B,EAAQ;AAG3D,QAAM,OAAO,EAAQ,OAAO;AAE5B,UAAM,IAAW,EAAgB,EAC7B,OAAU,AAAA,mBAAiB,IAC3B,WAAW,IAAA,MAGX,IAAQ,GACN,IAAM,IAEN,IAAQ,EACV,KAAK,CAAC,KACN,KAAK,MAIL,IAAW,IAET,IAAa,CAAC,KAAK,KAAK,KAAM,KAAK,KAAK,KAAK;AAEnD,aAAA,EAAS,GAAG,QAAS,OAAY;AAC7B,YAAI,MAAU,GAAG;AACb,YAAW,QAAS,OAAM;AAClB,cAAQ,MAAM,GAAG,SAAS,KAC1B,GAAM,MAAM,EAAQ,MAAM,IAC1B,EAAM,MAAM;cAIhB,GAAM,QAAQ,MAAM,EAAM,IAAI,UAAU,MACxC,GAAM,OAAO,wBAA2B,GAAG,0CAC3C,EAAM,SAAS;AAEnB,cAAM,IAAU,OAGV,IAAmB,EAAM,IAAI,KAAM,OAAO,EAAQ,KAAK;AAO7D,YAAM,SAAS,MACf,EAAM,YAAY,EAAM,KACxB,EAAM,UAAU,EAAM;;AAG1B,YAAI,IAAQ,KAAK,IAAQ,GAAK;AAE1B,cAAM,IAAe,EAAQ,MAAM,KAAK,SAAS;AAmBjD,cAjBI,KACI,IAAe,MAAM,KAGrB,GAAM,oBAAoB,OAK9B,IAAe,MAAM,KACrB,EAAQ,MAAM,MAAM,SAAS,MAAM,KAEnC,KAAW,IAGD,EAAQ,MAAM,EAAM,KAAK,WAEzB,EAAM,IAAI,QAAQ;AAC5B,cAAM,OAAO,mBAAsB;AACnC;;AAEJ,YAAM,QAAQ,KAAK,EAAQ,MAAM,EAAM;;AAE3C;UAEG;;;EAGX,kBAAwB;AACpB,QAAI,KAAK,YAAY,WAAW,UAAU;AACtC,WAAK,SAAS,EAAS,EACnB,aAAa,EAAY,YACzB,QAAQ;AAEZ;;AAGJ,QACI,KAAK,OAAO,WAAW,QACvB,KAAK,OAAO,WAAW,UACvB,KAAK,OAAO,WAAW,OACzB;AACE,WAAK,SAAY,AAAA,mBAAiB,KAAK;AACvC;;;EAIR,qBAA2B;AACvB,QAAI,KAAK,QAAQ,SAAS;AACtB,WAAK,YAAe,AAAA,mBAAiB,KAAK;AAC1C;;AAGJ,QAAI,KAAK,QAAQ,OAAO;AACpB,WAAK,YAAY,EAAS,EACtB,aAAa,EAAY,YACzB,QAAQ;AAEZ;;AAEJ,UAAM,IAAI,MAAM,2BAA2B,KAAK;;EAGpD,eAAoB;AAChB,QACI,KAAK,OAAO,WAAW,QACvB,KAAK,OAAO,WAAW,UACvB,KAAK,OAAO,WAAW;AAEvB,aAAO;AAGX,QAAI,KAAK,OAAO,WAAW;AACvB,aAAO;AAGX,UAAM,IAAI,MAAM,wBAAwB,KAAK;;EAGjD,WAAmB;AACf,QAAM,IAAM,OAAO,OAAO;AAE1B,QAAI,CAAI,AAAA,aAAW,KAAK;AACpB,YAAM,IAAI,MAAM,uBAAuB,KAAK;AAGhD,QAAM,IAAU,AAAA,WAAS,KAAK;AAE9B,QAAI,EAAK,OAAO;AACZ,YAAM,IAAI,MAAM,4BAA4B,KAAK;AAErD,WAAO,EAAK;;EAGV,aAA8B;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AAChC,UAAI,CAAC,KAAK,UAAU,CAAC,KAAK;AACtB,cAAM,IAAI,MAAM;AAGpB,UAAM,IAAa,AAAA,mBAAiB,KAAK;AAEzC,UAAI,CAAC,EAAQ;AACT,cAAM,IAAI,MAAM;AAGpB,UAAM,IAAQ,KAAK;AAEf,UAAQ,MAAM,OAAO,QAErB,QAAQ,KAAK,aAAa;AAG9B,UAAM,EAAC,MAAM,GAAK,KAAA,MAAO,EAAW,KAAK,aAAa,EAClD,MAAM;AAGV,UAAI,EAAI,WAAW,WAAW;AAC1B,cAAM,IAAI,MAAM,2BAA2B;AAG1C,QAAI,QACL,GAAI,OAAO,EAAK,SAAS,KAAK,SAC9B,QAAQ,KAAK,oEAAoE,EAAI,QAGzF,QAAQ,IAAI,aAAa,KAAK,aAAa,KAAK;AAMhD,UAAM,IAAM,MAJD,EAAS,EAChB,QAAQ,eAGS,KAAK,IAAI,EAAiB,EAC3C,QAAQ,EAAI,QACZ,KAAK,EAAI,MAAM,EAAI,MACnB,MAAM,MACN,MAAM,OAAO;AACb,cAAM,IAAI,MAAM,kDAAkD;SACnE,QAAQ,MAAM;AACb,UAAQ;;AAGZ,UAAI,EAAI,UAAU,mBAAmB;AACjC,cAAM,IAAI,MAAM,kDAAkD,EAAI,UAAU;AAGpF,UAAI,CAAC,EAAI,UAAU;AAAW,cAAM,IAAI,MAAM,kDAAkD,EAAI,UAAU;AAC9G,aAAO,EAAI,UAAU;;;EAGnB,oBACF,GACA,GACe;AAAA,WAAA,EAAA,MAAA,MAAA,aAAA;AAEf,UAAM,IAAS,EAAS,EACpB,aAAa,EAAY,YACzB,QAAQ,gBAGN,IAAU,IAAI,EAA6B,EAC7C,QAAQ,GACR,iBAAiB,QACjB,aAAa,YACb,KAAK,MAGH,IAAS,MAAM,EAAO,KAAK;AAEjC,UAAI,EAAO,UAAU,mBAAmB;AACpC,cAAM,IAAI,MAAM,mEAAmE,EAAO,6BAA6B,EAAO,UAAU;AAG5I,UAAI,CAAC,EAAO;AACR,cAAM,IAAI,MAAM,mEAAmE,EAAO;AAG9F,aAAO,EAAO;;;EAGlB,KAAK,GAAa,GAAgD;AAG9D,QAFA,QAAQ,IAAI,SAAS,KAAO,EAAK,KAAK,SAElC,KAAK,SAAS;AACd,YAAM,IAAI,MAAM,uBAAuB,KAAK;AAGhD,WAAA,KAAK,UACE,EAAM,GAAK,GAAM;;EAG5B,uBAAuB,GAA+D;AAClF,QAAM,IAAwB,EAC1B,QAAQ,IACR,QAAQ,IACR,MAAM;AAGV,WAAO,IAAI,QAAQ,CAAC,GAAS,MAAW;AACpC,QAAM,OAAO,GAAG,QAAS,OAAS;AAC9B,UAAO,UAAU;UAGrB,EAAM,OAAO,GAAG,QAAS,OAAS;AAC9B,UAAO,UAAU;UAGrB,EAAM,GAAG,SAAU,OAAS;AACxB,UAAO,OAAO,MAAS,IAAI,IAAI,GAC/B,EAAQ;UAGZ,EAAM,GAAG,SAAU,OAAQ;AACvB,UAAO;;;;;AAMhB,WAAuB,GAAgB,GAA8B;AACxE,SAAO,IAAI,EAAS,GAAQ;;AAmGhC,IAAM,IAAe,OAAoB,EAAQ,EAC7C,SAAS,GACT,iBAAwB,OAAc,EAAA,QAAA,MAAA,aAAA;AAClC,SAAO;;AAHf,IAOI;AAEJ,WAAkB,GAAkC;AAChD,SAAK,KACD,SAAQ,IAAI,uBACZ,IAAK,IAAI,EAAS,KAEf;;AAgBX,WACI,GACA,GAUF;AACE,MAAM,IAAM,EACR,MAAM,KAAW,EAAQ,OAAO,EAAQ,OAAO;AAGnD,MAAI,CAAC,EAAI,WAAW,YAAY,EAAI,MAAM,MAAM,OAAO;AACnD,UAAM,IAAI,MAAM,mBAAmB;AAGvC,MAAI,IAAM,IACJ,IAAS,EACX,QAAQ,IACR,KAAK,IACL,MAAM,MAGJ,IAAM,EAAI,MAAM,MAAM,IACtB,CAAC,MAAW,KAAQ,EAAI,MAAM,KAAK,OAAO;AAEhD,SAAA,EAAO,SAAS,GAChB,EAAO,MAAM,EAAK,KAAK,MAEvB,EAAK,QAAQ,CAAC,GAAG,MAAM;AACnB,QAAI,MAAM,EAAK,SAAS,GAAG;AACvB,UAAM,IAAO,EAAE,MAAM,KAAK;AAG1B,UAFI,EAAI,QAAQ,MAAS,KAAG,KAAM,iCAAiC,MAE/D,CAAC,EAAI,QAAQ,MAAS;AAAG;AAE7B,UAAI,CAAC,EAAI,QAAQ,IAAO,GAAG;AACvB,YAAM,mBAAmB;AACzB;;AAGA,OAAC,EAAI,QAAQ,EAAE,MAAM,KAAK,OAAO,MAAM,IAAO,KAC9C,KAAM,GAAG,oCAAsC,MAE/C,IAAO,KAAK,EAAE,MAAM,KAAK,OAAO,MAAI,GAAO,OAAO;;MAGvD,EACH,MAAM,GACN,KAAK;;;;ADxqBb,IAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAed,IAAM,OAAO,IAAI;AAAA,EACb,UAAU;AAAA,EACV,aAAa;AAAA,EACb,UAAU;AAAA,EACV,QAAQ;AAAA,EAGR,MAAM;AAAA,EACN,MAAM;AAAA,EACN,MAAM;AAAA,EACN,MAAM;AAAA;AAGV,IAAI,KAAK,WAAW;AAChB,WAAS;AACT,UAAQ,KAAK;AAAA;AAGjB,IAAI,KAAK,cAAc;AACnB,WAAS;AACT,UAAQ,KAAK;AAAA;AAEjB,IAAM,WAAW,KAAK;AACtB,IAAI,OAAO,KAAK,MAAM,WAAW,GAAG;AAChC,WAAS;AACT,UAAQ,KAAK;AAAA;AAGjB,IAAM,aAAa;AAAA,EACf,QAAQ;AAAA;AAGZ,KAAM,eAAqB;AAAA;AACvB,QAAI,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,IAAI;AAAA;AAER,QAAI,KAAK,WAAW;AAChB,YAAM,OAAO,KAAK;AAAA;AAGtB,QAAI,KAAK,SAAS;AACd,YAAM,KAAK,KAAK;AAAA;AAGpB,QAAI,SAAS,QAAQ,aAAa,IAAI;AAClC,YAAM,YAAY,WAAW;AAAA;AAGjC,UAAM,IAAI,EAAc,MAAM,MAAM;AAAA,MAChC,WAAW;AAAA;AAGf,UAAM,YAAY,MAAM,EAAE;AAE1B,QAAI,CAAC,WAAW;AACZ,eAAS;AACT,cAAQ,KAAK;AAAA;AAEjB,YAAQ,IAAI;AAEZ,aAAS;AA0ET,YAAQ,KAAK;AAAA;AAAA;AAGjB,kBAAkB,KAAK;AACnB,SAAO,QAAQ,WACT,QAAQ,OAAO,MAAM,GAAG;AAAA,KACxB,QAAQ,OAAO,MAAM,GAAG,KAAK,UAAU,KAAK,MAAM;AAAA;AAAA;AAI5D,QAAQ,GAAG,sBAAsB,CAAC,QAAQ,YAAY;AAClD,WAAS;AACT,UAAQ,KAAK;AAAA;",
  "names": []
}
