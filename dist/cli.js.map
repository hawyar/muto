{
  "version": 3,
  "sources": ["../bin/cli.js", "../lib/engine.ts", "../lib/types.ts"],
  "sourcesContent": ["#!/usr/bin/env node\nimport arg from \"arg\"\nimport {createDataset} from \"../dist/muto.js\"\n\nconst usage = `\nUsage:\n  $muto [options]\n  \n  commands:\n    upload\tuploads the specified file to S3\n\n  options:\n    -h, --help      output usage information \\n -v, --version   output the version number\n    -v, --version  output the version number\n\n    -f --from       The path to the file to source from\n    -t --to         The path to the file to target to\n`;\n\nconst args = arg({\n    \"--help\": Boolean,\n    \"--version\": Boolean,\n    \"--from\": String,\n    \"--to\": String,\n\n    // aliases\n    \"-h\": \"--help\",\n    \"-v\": \"--version\",\n    \"-f\": \"--from\",\n    \"-t\": \"--to\",\n});\n\nif (args[\"--help\"]) {\n    stdWrite(usage);\n    process.exit(0);\n}\n\nif (args[\"--version\"]) {\n    stdWrite(`v0.1.0`);\n    process.exit(0);\n}\nconst commands = args[\"_\"];\nif (Object.keys(args).length === 1) {\n    stdWrite(usage);\n    process.exit(0);\n}\n\nconst operations = {\n    upload: \"UPLOAD\",\n};\n\nvoid (async function run() {\n    let input = {\n        from: '',\n        to: '',\n    }\n    if (args[\"--from\"]) {\n        input.from = args[\"--from\"];\n    }\n\n    if (args[\"--to\"]) {\n        input.to = args[\"--to\"];\n    }\n\n    if (commands.indexOf(\"upload\") == -1) {\n        input.operation = operations.upload;\n    }\n\n    const d = createDataset(input.from, {\n        delimiter: \",\",\n    })\n\n    const confirmed = await d.uploadToS3()\n\n    if (!confirmed) {\n        stdWrite(\"Upload cancelled\");\n        process.exit(0);\n    }\n    console.log(confirmed);\n\n    stdWrite(\"Upload complete\");\n    //\n    // if (!args[\"--from\"]) {\n    //     stdWrite(\n    //         `Error: no source given for operation, provide a valid source path \\nExample: \\n \\t File system: ./my-datasets  \\n \\t AWS S3: s3://my-bucket/datasets/\n    // \t\t`\n    //     );\n    //     process.exit(1);\n    // }\n    //\n    // if (!args[\"--to\"]) {\n    //     stdWrite(\n    //         `Error: no destination given for operation, provide a valid destination path \\nExample: \\n \\t File system: ./my-datasets  \\n \\t AWS S3: s3://my-bucket/datasets/\n    // \t\t`\n    //     );\n    //     process.exit(1);\n    // }\n    //\n    // config.from = args[\"--from\"];\n    // config.to = args[\"--to\"];\n    //\n    // const w = createWorkflow(\"my_etl\");\n    //\n    // // if fs and not dir throw before initializing engine\n    //\n    // if (\n    //     config.from.startsWith(\"/\") ||\n    //     config.from.startsWith(\"./\") ||\n    //     config.from.startsWith(\"../\")\n    // ) {\n    //     const isDir = await fs\n    //         .stat(config.from)\n    //         .then((stat) => stat.isDirectory())\n    //         .catch((err) => {\n    //             stdWrite(\"Error: given source is not a valid directory\");\n    //             process.exit(1);\n    //         });\n    //\n    //     if (!isDir) {\n    //         stdWrite(\n    //             \"Error: unable to open source, please make sure source is a valid path\"\n    //         );\n    //         process.exit(1);\n    //     }\n    //\n    //     stdWrite(`Created new worklow`);\n    //\n    //     const files = await fs\n    //         .readdir(config.from)\n    //         .then((files) => files)\n    //         .catch((err) => {\n    //             stdWrite(err);\n    //             process.exit(1);\n    //         });\n    //\n    //     for (const file of files) {\n    //         if (!file.endsWith(\".csv\")) return;\n    //         const src = \"./\" + path.normalize(path.join(config.from, file));\n    //\n    //         stdWrite(`Adding ${src} to workflow`);\n    //         const d1 = await w\n    //             .add(src, {\n    //                 delimiter: \",\",\n    //                 quote: '\"',\n    //                 header: true,\n    //             })\n    //             .catch((err) => {\n    //                 console.log(err);\n    //             });\n    //\n    //         console.log(d1);\n    //     }\n    // }\n\n    process.exit(0);\n})();\n\nfunction stdWrite(msg) {\n    typeof msg === \"string\"\n        ? process.stdout.write(`${msg} \\n`)\n        : process.stdout.write(`${JSON.stringify(msg, null, 2)}\\n`);\n}\n\n// catch unhandled promises\nprocess.on(\"unhandledRejection\", (reason, promise) => {\n    stdWrite(reason);\n    process.exit(1);\n});\n", "import * as fs from \"fs\";\nimport {readFileSync, writeFileSync} from 'atomically';\nimport {CreateMultipartUploadCommand, PutObjectCommand, S3Client, S3ClientConfig} from \"@aws-sdk/client-s3\";\nimport {fromIni} from \"@aws-sdk/credential-providers\";\nimport {AthenaClient, AthenaClientConfig} from \"@aws-sdk/client-athena\";\nimport {ChildProcessWithoutNullStreams, spawn} from \"child_process\";\nimport os from \"os\";\nimport path from \"path\";\nimport {createInterface} from \"readline\";\nimport {\n    Cache,\n    connectorType,\n    Dataset,\n    DatasetOptions,\n    datasetStateType,\n    env,\n    mlrCmd,\n    ProcessResult,\n    Shape\n} from \"./types\"\n\nconst credentials = (profile: string) => fromIni({\n    profile: profile,\n    mfaCodeProvider: async (mfaSerial) => {\n        return mfaSerial\n    },\n});\n\nlet s3: S3Client;\n\n/**\n * Creates a new S3 client if one already doesn't exist.\n *  @param {S3ClientConfig} config\n *  @returns {S3Client}\n */\nfunction s3Client(config: S3ClientConfig): S3Client {\n    if (!s3) {\n        console.log('creating s3 client')\n        s3 = new S3Client(config);\n    }\n    return s3;\n}\n\n\nlet athena: AthenaClient\n\n\n/**\n * Creates a new athena client if one already doesn't exist.\n *  @param {AthenaClientConfig} config\n *  @returns {AthenaClient}\n */\nfunction athenaClient(config: AthenaClientConfig): AthenaClient {\n    if (!athena) {\n        console.log('creating athena client')\n        athena = new AthenaClient(config);\n    }\n    return athena;\n}\n\n/**\n * Parses S3 (s3://) style URIs\n */\nfunction parseS3Uri(\n    uri: string,\n    options: {\n        file: boolean;\n    }\n): {\n    data: {\n        bucket: string;\n        key: string;\n        file: string;\n    };\n    err: string;\n} {\n    const opt = {\n        file: options && options.file ? options.file : false,\n    };\n\n    if (!uri.startsWith(\"s3://\") || uri.split(\":/\")[0] !== \"s3\") {\n        throw new Error(`invalid-s3-uri: ${uri}`);\n    }\n\n    let err = \"\";\n\n    const result = {\n        bucket: \"\",\n        key: \"\",\n        file: \"\",\n    };\n\n    const src = uri.split(\":/\")[1];\n    const [bucket, ...keys] = src.split(\"/\").splice(1);\n\n    result.bucket = bucket;\n    result.key = keys.join(\"/\");\n\n    keys.forEach((k, i) => {\n        if (i === keys.length - 1) {\n            const last = k.split(\".\").length;\n            if (opt.file && last === 1) err = `uri should be a given, given: ${uri}`;\n\n            if (!opt.file && last === 1) return;\n\n            if (!opt.file && last > 1) {\n                err = `Invalid S3 uri, ${uri} should not end with a file name`;\n                return;\n            }\n\n            if (!opt.file && k.split(\".\")[1] !== \"\" && last > 1)\n                err = `${uri} should not be a file endpoint: ${k}`;\n\n            if (last > 1 && k.split(\".\")[1] !== \"\") result.file = k;\n        }\n    });\n    return {\n        data: result,\n        err: err,\n    };\n}\n\n/**\n * Dataset represent a file for processing\n */\nclass _Dataset implements Dataset {\n    source: string;\n    destination: string;\n    addedAt: Date;\n    options: DatasetOptions;\n    shape: Shape\n    cut: string[]\n    cached: boolean;\n    state: datasetStateType\n    connector: connectorType | null\n    env: string\n\n    constructor(source: string, options: DatasetOptions) {\n        this.source = source;\n        this.cached = false;\n        this.destination = options.destination\n        this.options = options;\n        this.env = this.determineSource();\n        this.shape = {\n            type: \"\",\n            columns: [],\n            header: false,\n            encoding: \"\",\n            bom: false,\n            size: 0,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: \"\",\n            errors: {},\n            warnings: {},\n            preview: [[]]\n        }\n        this.cut = []\n        this.addedAt = new Date();\n        this.state = 'init'\n        this.connector = null\n    }\n\n    setDestination(destination: string) {\n        this.destination = destination\n    }\n\n    /**\n     * Convert CSV to JSON\n     * @return {Promise<string>} source of the dataset\n     */\n    async toJson(): Promise<string> {\n        const write = fs.createWriteStream(this.destination)\n\n        const json = this.exec(mlrCmd, [\"--icsv\", \"--ojson\", \"clean-whitespace\", \"cat\", this.source])\n        json.stdout.pipe(write)\n\n        write.on('close', () => {\n            console.log(\"\uD83D\uDCDD Dataset converted to JSON\")\n            return this.destination\n        })\n\n        write.on('error', (err) => {\n            throw new Error(err.message)\n        })\n        return this.destination\n    }\n\n    /**\n     * Count number of rows\n     * @return {Promise<string>} number of rows\n     */\n    async rowCount(): Promise<number> {\n        const count = await this.exec(mlrCmd, [`--ojson`, `count`, this.source])\n\n        const rowCountExec = await this.promisifyProcessResult(count)\n\n        if (rowCountExec.code !== 0) {\n            throw new Error(`Error while counting rows: ${rowCountExec.stderr}`)\n        }\n\n        if (rowCountExec.stderr) {\n            throw new Error(rowCountExec.stderr)\n        }\n\n        const r = JSON.parse(rowCountExec.stdout)\n\n        if (r.length === 0) {\n            throw new Error('No rows found')\n        }\n\n        return r[0].count\n    }\n\n\n    /**\n     * Extracts the header row from the dataset, defined columns\n     * @return Promise<string[] | null> header row or null if no header\n     */\n    async getColumnHeader(): Promise<string[] | null> {\n        const res = await this.exec(mlrCmd, [`--icsv`, `--ojson`, `head`, `-n`, `1`, this.source])\n\n        const colExec = await this.promisifyProcessResult(res)\n\n        if (colExec.code !== 0) {\n            return null\n        }\n\n        if (colExec.stderr) {\n            throw new Error(colExec.stderr)\n        }\n        const columns = JSON.parse(colExec.stdout)\n\n        if (columns.length === 0) {\n            this.shape.header = false\n            return null\n        }\n\n        this.shape.columns = Object.keys(columns[0])\n        this.shape.header = true\n        return this.shape.columns\n    }\n\n    async formatValues() {\n        // --opprint format-values\n        const res = await this.exec(mlrCmd, [`--icsv`, `format-values`, this.source])\n        const formatVal = await this.promisifyProcessResult(res)\n\n        if (formatVal.code !== 0) {\n            return null\n        }\n\n        if (formatVal.stderr) {\n            throw new Error(formatVal.stderr)\n        }\n\n        return this.shape.columns\n    }\n\n    /**\n     * Extracts rows from the dataset for preview.\n     * If the dataset is too large to preview then it will stream the result and return the file path\n     * @param {number} count - number of rows to preview\n     * @param {string} streamTo - path to the file to stream to\n     * @return Promise<string[][] | string> - preview rows or path to the file the preview was streamed to\n     */\n    async preview(count = 20, streamTo?: string): Promise<string[][] | string> {\n        let write: fs.WriteStream\n\n        const maxPreview = 1024 * 1024 * 10\n\n        const fsp = fs.promises\n        const stat = await fsp.stat(this.source)\n\n        if (streamTo && streamTo !== this.source && fs.createWriteStream(streamTo) instanceof fs.WriteStream || stat.size > maxPreview) {\n\n            if (streamTo === undefined) throw new Error('stream-destination-undefined')\n            write = fs.createWriteStream(streamTo)\n\n            const previewExec = await this.exec(mlrCmd, [`--icsv`, `--ojson`, `head`, `-n`, count.toString(), this.source])\n\n            previewExec.stdout.pipe(write)\n\n            console.warn(`\uD83D\uDC40 Preview saved to: ${streamTo}`)\n            return streamTo\n        }\n\n        const previewExec = await this.exec(mlrCmd, [`--icsv`, `--ojson`, `head`, `-n`, count.toString(), this.source])\n\n        const prev = await this.promisifyProcessResult(previewExec)\n\n        if (prev.stderr) {\n            throw new Error(prev.stderr)\n        }\n\n        if (prev.code !== 0) {\n            throw new Error(`Error while executing mlr command`)\n        }\n\n        this.shape.preview = JSON.parse(prev.stdout)\n        return this.shape.preview\n    }\n\n\n    async detectShape(): Promise<Shape> {\n        const path = this.source\n        const shape: Shape = {\n            type: '',\n            size: 0,\n            columns: [''],\n            header: false,\n            encoding: 'utf-8',\n            bom: false,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: ',',\n            errors: {},\n            warnings: {},\n            preview: [['']],\n        };\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`path-doesnt-exists: ${path} ,provide a valid path to a CSV file`)\n        }\n\n        const stat = fs.statSync(path)\n        this.shape.size = stat.size\n\n        if (stat.size > 1024 * 1024 * 1024) {\n            throw new Error(`file-size-exceeds-limit: ${path} is too large, please limit to under 1GB for now`)\n        }\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`${path} does not exist, provide a valid path to a CSV file`)\n        }\n\n        if (os.platform() === \"win32\") {\n            // TODO: handle\n            throw new Error(`scream`)\n        }\n\n        const mime = this.exec(\"file\", [path, \"--mime-type\"])\n\n        const mimeRes = await this.promisifyProcessResult(mime)\n\n        if (mimeRes.stderr) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        if (mimeRes.code !== 0) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        const mimeType = mimeRes.stdout.trim()\n\n        const readLine = createInterface({\n            input: fs.createReadStream(path),\n            crlfDelay: Infinity,\n        });\n\n        let count = 0;\n        const max = 20;\n\n        const first = {\n            row: [''],\n            del: \"\",\n        };\n\n        // hold the previous line while rl proceeds to next line using \\r\\n as a delimiter\n        let previous = \"\";\n\n        const delimiters = [\",\", \";\", \"\\t\", \"|\", \":\", \" \", \"|\"];\n\n        readLine.on(\"line\", (current) => {\n            if (count === 0) {\n                delimiters.forEach((d) => {\n                    if (current.split(d).length > 1) {\n                        first.row = current.split(d)\n                        first.del = d;\n                    }\n                });\n\n                if (first.del === \"\" || first.row.length <= 1) {\n                    shape.errors[\"unrecognizedDelimiter\"] = `${path} does not have a recognized delimiter`;\n                    shape.header = false;\n                }\n                const isDigit = /\\d+/;\n\n                // assuming that numbers shouldn't start as column header\n                const hasDigitInHeader = first.row.some((el) => isDigit.test(el));\n                // if (hasDigitInHeader) {\n                //     shape.header = false;\n                //     shape.warnings[\"noHeader\"] = `no header found`;\n                //     count++;\n                //     return;\n                // }\n                shape.header = true;\n                shape.delimiter = first.del;\n                shape.columns = first.row;\n            }\n\n            if (count > 0 && count < max) {\n                // there is a chance the record spans next line\n                const inlineQuotes = current.split(`\"`).length - 1;\n\n                if (previous) {\n                    if (inlineQuotes % 2 !== 0) {\n                        // TODO: make sure previous + current\n                        // console.log(previous + l);\n                        shape.spanMultipleLines = true;\n                    }\n                }\n                // if odd number of quotes and consider escaped quotes such as: \"aaa\",\"b\"\"bb\",\"ccc\"\n                if (\n                    inlineQuotes % 2 !== 0 &&\n                    current.split(`\"\"`).length - 1 !== 1\n                ) {\n                    previous = current;\n                }\n\n                const width = current.split(first.del).length;\n\n                if (width !== first.row.length) {\n                    shape.errors['rowWidthMismatch'] = `row width mismatch`;\n                    return;\n                }\n                shape.preview.push(current.split(first.del));\n            }\n            count++;\n        });\n        return shape;\n    }\n\n    determineConnector(): connectorType {\n        const env = this.determineSource();\n        if (env === \"local\") {\n            const stream = fs.createReadStream(this.source);\n            return stream\n        }\n\n        if (env === \"aws\") {\n            const client = s3Client({\n                credentials: credentials(\"default\"),\n                region: \"us-east-2\",\n            });\n            return client\n        }\n        throw new Error(`unsupported-source for: ${this.source}`)\n    }\n\n    determineSource(): string {\n        if (\n            this.source.startsWith(\"/\") ||\n            this.source.startsWith(\"../\") ||\n            this.source.startsWith(\"./\")\n        ) {\n            return \"local\";\n        }\n\n        if (this.source.startsWith(\"s3://\")) {\n            return \"remote\";\n        }\n\n        throw new Error(`invalid-source-type: ${this.source}`);\n    }\n\n    fileSize(): number {\n        const max = 1024 * 1024 * 50\n\n        if (!fs.existsSync(this.source)) {\n            throw new Error(`path-doesnt-exists: ${this.source} ,provide a valid path to a CSV file`)\n        }\n\n        const stat = fs.statSync(this.source)\n\n        if (stat.size > max) {\n            throw new Error(`file-size-exceeds-limit: ${this.source} is too large, please limit to 50MB`)\n        }\n        return stat.size\n    }\n\n    async uploadToS3(): Promise<string> {\n        if (!this.source || !this.destination) {\n            throw new Error('source or destination not set. Both must be defined to upload to S3')\n        }\n\n        const fStream = fs.createReadStream(this.source)\n\n        if (!fStream.readable) {\n            throw new Error('failed-to-read-source: Make sure the provided file is readable')\n        }\n\n        const fSize = this.fileSize()\n\n        if (fSize > 100 * 1024 * 1024) {\n            //TODO: init multipart upload then upload parts\n            console.warn(`file size ${fSize} is larger than 100MB`)\n        }\n\n        const {data: uri, err} = parseS3Uri(this.destination, {\n            file: true,\n        });\n\n        if (err.toString().startsWith(`invalid-s3-uri`)) {\n            throw new Error(`failed-to-parse-s3-uri: ${err}`)\n        }\n\n        if (!uri.file) {\n            uri.file = path.basename(this.source)\n            console.warn(\"Destination filename not provided. Using source source basename\" + uri.file)\n        }\n\n        console.log(`uploading ${this.source} to ${this.destination}`);\n\n        const s3 = s3Client({\n            region: \"us-east-2\",\n        })\n\n        const res = await s3.send(new PutObjectCommand({\n            Bucket: uri.bucket,\n            Key: uri.key + uri.file,\n            Body: fStream,\n        })).catch(err => {\n            throw new Error(`failed-upload-s3: Error while uploading to S3: ${err}`)\n        }).finally(() => {\n            fStream.close()\n        })\n        if (res.$metadata.httpStatusCode !== 200) {\n            throw new Error(`failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`)\n        }\n\n        if (!res.$metadata.requestId) throw new Error(`failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`)\n        return res.$metadata.requestId\n    }\n\n    /**\n     * Initiates a multipart upload and returns an upload ID\n     * @returns {string} uploadID\n     * @private\n     */\n    async initMultipartUpload(\n        bucket: string,\n        key: string\n    ): Promise<string> {\n\n        const client = s3Client({\n            credentials: credentials(\"default\"),\n            region: \"us-east-2\",\n        });\n\n        const command = new CreateMultipartUploadCommand({\n            Bucket: bucket,\n            ContentEncoding: \"utf8\",\n            ContentType: \"text/csv\",\n            Key: key,\n        });\n\n        const result = await client.send(command);\n\n        if (result.$metadata.httpStatusCode !== 200) {\n            throw new Error(`failed-multipart-upload: Error while creating multipart upload: ${result.UploadId} with status code ${result.$metadata.httpStatusCode}`)\n        }\n\n        if (!result.UploadId) {\n            throw new Error(`failed-multipart-upload: Error while creating multipart upload: ${result.UploadId}`)\n        }\n\n        return result.UploadId\n    }\n\n    exec(cmd: string, args: string[]): ChildProcessWithoutNullStreams {\n        console.log(`exec: ${cmd} ${args.join(' ')}`)\n        return spawn(cmd, args)\n    }\n\n    promisifyProcessResult(child: ChildProcessWithoutNullStreams): Promise<ProcessResult> {\n        const result: ProcessResult = {\n            stdout: '',\n            stderr: '',\n            code: 0\n        }\n\n        return new Promise((resolve, reject) => {\n            child.stdout.on('data', (data) => {\n                result.stdout += data\n            })\n\n            child.stderr.on('data', (data) => {\n                result.stderr += data\n            })\n\n            child.on('close', (code) => {\n                result.code = code === 0 ? 0 : 1\n                resolve(result)\n            })\n\n            child.on('error', (err) => {\n                reject(err)\n            })\n        })\n    }\n}\n\n/**\n * Returns a new dataset\n * @param {string} source - Source of the dataset\n * @returns {Options} options - Options for the dataset\n */\nexport function createDataset(source: string, options: DatasetOptions): Dataset {\n    const d = new _Dataset(source, options);\n    Promise.all([d.detectShape(), d.determineSource(), d.determineConnector()]).then((val) => {\n        // console.log(val)\n    }).catch((err) => {\n        throw new Error(err)\n    })\n    return d;\n}\n\nconst cache = (function (): { getInstance: () => Cache } {\n    let cache: Cache;\n\n    function init() {\n        const cachePath = path.join(process.cwd(), '.muto-cache')\n\n        if (!fs.existsSync(cachePath)) {\n            console.log('creating cache file at', cachePath)\n            writeFileSync(cachePath, JSON.stringify({}))\n        } else {\n            console.log('loading cache from', cachePath)\n        }\n\n        return {\n            init: new Date(),\n            path: cachePath,\n            get: (key: string): Dataset | undefined => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key].source !== key) {\n                    return undefined\n                }\n                return cache[key]\n            },\n            set: (key: string, value: Dataset): string | void => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key]) {\n                    return\n                }\n\n                cache[key] = value\n                writeFileSync(cachePath, JSON.stringify(cache))\n                return key\n            },\n            has: (key: string): boolean => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key]) {\n                    return true\n                }\n                return false\n            },\n            delete: (key: string) => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                delete cache[key]\n\n                writeFileSync(cachePath, JSON.stringify(cache))\n            },\n            clear: () => {\n                writeFileSync(cachePath, JSON.stringify({}))\n            },\n            size: () => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return Object.keys(cache).length\n            },\n            keys: () => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return Object.keys(cache)\n            }\n        }\n    }\n\n    return {\n        getInstance: () => {\n            if (!cache) {\n                cache = init()\n            }\n            return cache\n        }\n    }\n})()\n\nclass Workflow {\n    name: string;\n    datasets: Map<string, Dataset>;\n    readonly createdAt: Date;\n    env: env;\n    lcache: Cache | null\n\n    constructor(name: string) {\n        this.name = name;\n        this.datasets = new Map();\n        this.createdAt = new Date();\n        this.env = 'local';\n        this.lcache = null;\n        // this.lcache = cache.getInstance()\n    }\n\n    list(): Dataset[] {\n        return Array.from(this.datasets.values());\n    }\n\n    remove(dataset: Dataset) {\n        this.datasets.delete(dataset.source);\n    }\n\n    async add(source: string, options: DatasetOptions): Promise<string> {\n        if (options.destination === \"\") {\n            console.warn(`destination-not-provided: provide a destination for ${source}`);\n        }\n\n        // if (this.lcache.has(source)) {\n        //     return source\n        // }\n        const dataset = new _Dataset(source, options);\n\n        this.datasets.set(source, dataset);\n        return source\n    }\n}\n\n\n/**\n * Returns a new workflow\n * @param {string} name - Name of the workflow\n * @returns {Workflow} - New workflow\n */\nexport function createWorkflow(name: string): Workflow {\n    return new Workflow(name);\n}\n", "import {S3Client} from \"@aws-sdk/client-s3\";\nimport {join} from \"path\";\nimport fs from \"fs\";\n\nexport enum Delimiters {\n    COMMA = \",\",\n    SEMICOLON = \";\",\n    PIPE = \"|\",\n    COLON = \":\",\n    TAB = \"\\t\",\n    SPACE = \" \",\n    TILDE = \"~\",\n    DASH = \"-\",\n    UNDERSCORE = \"_\"\n}\n\nexport type env = 'local' | 'aws'\nexport type connectorType = S3Client | fs.ReadStream\nexport const mlrCmd = join(process.cwd(), 'node_modules', '.bin', 'mlr@v6.0.0')\n\n\n// TODO: better error message for errors in transform\nexport type datasetStateType = 'init' | 'transforming' | 'uploading' | 'cancelled' | 'uploaded' | 'ready'\nexport type ShapeErrType = 'unrecognizedDelimiter' | 'noHeader' | 'invalidFileType' | 'rowWidthMismatch'\n\n\nexport type Shape = {\n    type: string,\n    columns: Array<string>,\n    header: boolean,\n    encoding: string,\n    bom: boolean,\n    size: number,\n    spanMultipleLines: boolean,\n    quotes: boolean,\n    delimiter: string,\n    errors: { [key: string]: string }\n    warnings: { [key: string]: string },\n    preview: string[][],\n}\n\nexport interface Dataset {\n    source: string\n    destination: string\n    addedAt: Date;\n    options: DatasetOptions;\n    shape: Shape\n    cached: boolean\n    state: datasetStateType\n    connector: connectorType | null\n\n    setDestination(destination: string): void\n\n    toJson(): Promise<string>\n\n    getColumnHeader(): Promise<string[] | null>\n\n    rowCount(): Promise<number>\n\n    fileSize(): number\n\n    preview(count: number, streamTo?: string): Promise<string[][] | string>\n\n    detectShape(): Promise<Shape>\n\n    determineSource(): string\n\n    determineSource(): string\n\n    determineConnector(): connectorType\n\n    uploadToS3(bucket: string, key: string): Promise<string>\n\n    initMultipartUpload(bucket: string, key: string): Promise<string>\n\n}\n\nexport type DatasetOptions = {\n    destination: string;\n    columns: Array<string>,\n    header: boolean,\n    quotes: boolean,\n    transform: (row: object) => object\n    delimiter: Delimiters\n    keepColumns: Array<string>\n    sortBy: string\n}\n\nexport interface Cache {\n    path: string\n    init: Date\n\n    get(key: string): Dataset | undefined\n\n    set(key: string, value: Dataset): void\n\n    has(key: string): boolean\n\n    delete(key: string): void\n\n    clear(): void\n\n    size(): number\n\n    keys(): string[]\n}\n\nexport type ProcessResult = {\n    stdout: string,\n    stderr: string,\n    code: number\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;AACA;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;ACPA;;;;;;;;;;;;;;;;;;;;;AAiBO,IAAM,SAAS,KAAK,QAAQ,OAAO,gBAAgB,QAAQ;ADGlE,IAAM,cAAc,CAAC,YAAoB,QAAQ;EAC7C;EACA,iBAAiB,CAAO,cAAc,SAAA,QAAA,MAAA,aAAA;AAClC,WAAO;;;AAIf,IAAI;AAOJ,kBAAkB,QAAkC;AAChD,MAAI,CAAC,IAAI;AACL,YAAQ,IAAI;AACZ,SAAK,IAAI,SAAS;;AAEtB,SAAO;;AAuBX,oBACI,KACA,SAUF;AACE,QAAM,MAAM;IACR,MAAM,WAAW,QAAQ,OAAO,QAAQ,OAAO;;AAGnD,MAAI,CAAC,IAAI,WAAW,YAAY,IAAI,MAAM,MAAM,OAAO,MAAM;AACzD,UAAM,IAAI,MAAM,mBAAmB;;AAGvC,MAAI,MAAM;AAEV,QAAM,SAAS;IACX,QAAQ;IACR,KAAK;IACL,MAAM;;AAGV,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,QAAM,CAAC,WAAW,QAAQ,IAAI,MAAM,KAAK,OAAO;AAEhD,SAAO,SAAS;AAChB,SAAO,MAAM,KAAK,KAAK;AAEvB,OAAK,QAAQ,CAAC,GAAG,MAAM;AACnB,QAAI,MAAM,KAAK,SAAS,GAAG;AACvB,YAAM,OAAO,EAAE,MAAM,KAAK;AAC1B,UAAI,IAAI,QAAQ,SAAS;AAAG,cAAM,iCAAiC;AAEnE,UAAI,CAAC,IAAI,QAAQ,SAAS;AAAG;AAE7B,UAAI,CAAC,IAAI,QAAQ,OAAO,GAAG;AACvB,cAAM,mBAAmB;AACzB;;AAGJ,UAAI,CAAC,IAAI,QAAQ,EAAE,MAAM,KAAK,OAAO,MAAM,OAAO;AAC9C,cAAM,GAAG,sCAAsC;AAEnD,UAAI,OAAO,KAAK,EAAE,MAAM,KAAK,OAAO;AAAI,eAAO,OAAO;;;AAG9D,SAAO;IACH,MAAM;IACN;;;AAOR,IAAA,WAAA,MAAkC;EAY9B,YAAY,QAAgB,SAAyB;AACjD,SAAK,SAAS;AACd,SAAK,SAAS;AACd,SAAK,cAAc,QAAQ;AAC3B,SAAK,UAAU;AACf,SAAK,MAAM,KAAK;AAChB,SAAK,QAAQ;MACT,MAAM;MACN,SAAS;MACT,QAAQ;MACR,UAAU;MACV,KAAK;MACL,MAAM;MACN,mBAAmB;MACnB,QAAQ;MACR,WAAW;MACX,QAAQ;MACR,UAAU;MACV,SAAS,CAAC;;AAEd,SAAK,MAAM;AACX,SAAK,UAAU,IAAI;AACnB,SAAK,QAAQ;AACb,SAAK,YAAY;;EAGrB,eAAe,aAAqB;AAChC,SAAK,cAAc;;EAOjB,SAA0B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAC5B,YAAM,QAAW,AAAA,qBAAkB,KAAK;AAExC,YAAM,OAAO,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,oBAAoB,OAAO,KAAK;AACrF,WAAK,OAAO,KAAK;AAEjB,YAAM,GAAG,SAAS,MAAM;AACpB,gBAAQ,IAAI;AACZ,eAAO,KAAK;;AAGhB,YAAM,GAAG,SAAS,CAAC,QAAQ;AACvB,cAAM,IAAI,MAAM,IAAI;;AAExB,aAAO,KAAK;;;EAOV,WAA4B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAC9B,YAAM,QAAQ,MAAM,KAAK,KAAK,QAAQ,CAAC,WAAW,SAAS,KAAK;AAEhE,YAAM,eAAe,MAAM,KAAK,uBAAuB;AAEvD,UAAI,aAAa,SAAS,GAAG;AACzB,cAAM,IAAI,MAAM,8BAA8B,aAAa;;AAG/D,UAAI,aAAa,QAAQ;AACrB,cAAM,IAAI,MAAM,aAAa;;AAGjC,YAAM,IAAI,KAAK,MAAM,aAAa;AAElC,UAAI,EAAE,WAAW,GAAG;AAChB,cAAM,IAAI,MAAM;;AAGpB,aAAO,EAAE,GAAG;;;EAQV,kBAA4C;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAC9C,YAAM,MAAM,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,QAAQ,MAAM,KAAK,KAAK;AAElF,YAAM,UAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,QAAQ,SAAS,GAAG;AACpB,eAAO;;AAGX,UAAI,QAAQ,QAAQ;AAChB,cAAM,IAAI,MAAM,QAAQ;;AAE5B,YAAM,UAAU,KAAK,MAAM,QAAQ;AAEnC,UAAI,QAAQ,WAAW,GAAG;AACtB,aAAK,MAAM,SAAS;AACpB,eAAO;;AAGX,WAAK,MAAM,UAAU,OAAO,KAAK,QAAQ;AACzC,WAAK,MAAM,SAAS;AACpB,aAAO,KAAK,MAAM;;;EAGhB,eAAe;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAEjB,YAAM,MAAM,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,iBAAiB,KAAK;AACrE,YAAM,YAAY,MAAM,KAAK,uBAAuB;AAEpD,UAAI,UAAU,SAAS,GAAG;AACtB,eAAO;;AAGX,UAAI,UAAU,QAAQ;AAClB,cAAM,IAAI,MAAM,UAAU;;AAG9B,aAAO,KAAK,MAAM;;;EAUhB,QAAQ,QAAQ,IAAI,UAAiD;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AACvE,UAAI;AAEJ,YAAM,aAAa,OAAO,OAAO;AAEjC,YAAM,MAAS;AACf,YAAM,OAAO,MAAM,IAAI,KAAK,KAAK;AAEjC,UAAI,YAAY,aAAa,KAAK,UAAa,AAAA,qBAAkB,qBAAwB,kBAAe,KAAK,OAAO,YAAY;AAE5H,YAAI,aAAa;AAAW,gBAAM,IAAI,MAAM;AAC5C,gBAAW,AAAA,qBAAkB;AAE7B,cAAM,eAAc,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,QAAQ,MAAM,MAAM,YAAY,KAAK;AAEvG,qBAAY,OAAO,KAAK;AAExB,gBAAQ,KAAK,+BAAwB;AACrC,eAAO;;AAGX,YAAM,cAAc,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,QAAQ,MAAM,MAAM,YAAY,KAAK;AAEvG,YAAM,OAAO,MAAM,KAAK,uBAAuB;AAE/C,UAAI,KAAK,QAAQ;AACb,cAAM,IAAI,MAAM,KAAK;;AAGzB,UAAI,KAAK,SAAS,GAAG;AACjB,cAAM,IAAI,MAAM;;AAGpB,WAAK,MAAM,UAAU,KAAK,MAAM,KAAK;AACrC,aAAO,KAAK,MAAM;;;EAIhB,cAA8B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAChC,YAAM,QAAO,KAAK;AAClB,YAAM,QAAe;QACjB,MAAM;QACN,MAAM;QACN,SAAS,CAAC;QACV,QAAQ;QACR,UAAU;QACV,KAAK;QACL,mBAAmB;QACnB,QAAQ;QACR,WAAW;QACX,QAAQ;QACR,UAAU;QACV,SAAS,CAAC,CAAC;;AAGf,UAAI,CAAI,AAAA,cAAW,QAAO;AACtB,cAAM,IAAI,MAAM,uBAAuB;;AAG3C,YAAM,OAAU,AAAA,YAAS;AACzB,WAAK,MAAM,OAAO,KAAK;AAEvB,UAAI,KAAK,OAAO,OAAO,OAAO,MAAM;AAChC,cAAM,IAAI,MAAM,4BAA4B;;AAGhD,UAAI,CAAI,AAAA,cAAW,QAAO;AACtB,cAAM,IAAI,MAAM,GAAG;;AAGvB,UAAI,GAAG,eAAe,SAAS;AAE3B,cAAM,IAAI,MAAM;;AAGpB,YAAM,OAAO,KAAK,KAAK,QAAQ,CAAC,OAAM;AAEtC,YAAM,UAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,QAAQ,QAAQ;AAChB,cAAM,IAAI,MAAM,+BAA+B,QAAQ;;AAG3D,UAAI,QAAQ,SAAS,GAAG;AACpB,cAAM,IAAI,MAAM,+BAA+B,QAAQ;;AAG3D,YAAM,WAAW,QAAQ,OAAO;AAEhC,YAAM,WAAW,gBAAgB;QAC7B,OAAU,AAAA,oBAAiB;QAC3B,WAAW;;AAGf,UAAI,QAAQ;AACZ,YAAM,MAAM;AAEZ,YAAM,QAAQ;QACV,KAAK,CAAC;QACN,KAAK;;AAIT,UAAI,WAAW;AAEf,YAAM,aAAa,CAAC,KAAK,KAAK,KAAM,KAAK,KAAK,KAAK;AAEnD,eAAS,GAAG,QAAQ,CAAC,YAAY;AAC7B,YAAI,UAAU,GAAG;AACb,qBAAW,QAAQ,CAAC,MAAM;AACtB,gBAAI,QAAQ,MAAM,GAAG,SAAS,GAAG;AAC7B,oBAAM,MAAM,QAAQ,MAAM;AAC1B,oBAAM,MAAM;;;AAIpB,cAAI,MAAM,QAAQ,MAAM,MAAM,IAAI,UAAU,GAAG;AAC3C,kBAAM,OAAO,2BAA2B,GAAG;AAC3C,kBAAM,SAAS;;AAEnB,gBAAM,UAAU;AAGhB,gBAAM,mBAAmB,MAAM,IAAI,KAAK,CAAC,OAAO,QAAQ,KAAK;AAO7D,gBAAM,SAAS;AACf,gBAAM,YAAY,MAAM;AACxB,gBAAM,UAAU,MAAM;;AAG1B,YAAI,QAAQ,KAAK,QAAQ,KAAK;AAE1B,gBAAM,eAAe,QAAQ,MAAM,KAAK,SAAS;AAEjD,cAAI,UAAU;AACV,gBAAI,eAAe,MAAM,GAAG;AAGxB,oBAAM,oBAAoB;;;AAIlC,cACI,eAAe,MAAM,KACrB,QAAQ,MAAM,MAAM,SAAS,MAAM,GACrC;AACE,uBAAW;;AAGf,gBAAM,QAAQ,QAAQ,MAAM,MAAM,KAAK;AAEvC,cAAI,UAAU,MAAM,IAAI,QAAQ;AAC5B,kBAAM,OAAO,sBAAsB;AACnC;;AAEJ,gBAAM,QAAQ,KAAK,QAAQ,MAAM,MAAM;;AAE3C;;AAEJ,aAAO;;;EAGX,qBAAoC;AAChC,UAAM,OAAM,KAAK;AACjB,QAAI,SAAQ,SAAS;AACjB,YAAM,SAAY,AAAA,oBAAiB,KAAK;AACxC,aAAO;;AAGX,QAAI,SAAQ,OAAO;AACf,YAAM,SAAS,SAAS;QACpB,aAAa,YAAY;QACzB,QAAQ;;AAEZ,aAAO;;AAEX,UAAM,IAAI,MAAM,2BAA2B,KAAK;;EAGpD,kBAA0B;AACtB,QACI,KAAK,OAAO,WAAW,QACvB,KAAK,OAAO,WAAW,UACvB,KAAK,OAAO,WAAW,OACzB;AACE,aAAO;;AAGX,QAAI,KAAK,OAAO,WAAW,UAAU;AACjC,aAAO;;AAGX,UAAM,IAAI,MAAM,wBAAwB,KAAK;;EAGjD,WAAmB;AACf,UAAM,MAAM,OAAO,OAAO;AAE1B,QAAI,CAAI,AAAA,cAAW,KAAK,SAAS;AAC7B,YAAM,IAAI,MAAM,uBAAuB,KAAK;;AAGhD,UAAM,OAAU,AAAA,YAAS,KAAK;AAE9B,QAAI,KAAK,OAAO,KAAK;AACjB,YAAM,IAAI,MAAM,4BAA4B,KAAK;;AAErD,WAAO,KAAK;;EAGV,aAA8B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAChC,UAAI,CAAC,KAAK,UAAU,CAAC,KAAK,aAAa;AACnC,cAAM,IAAI,MAAM;;AAGpB,YAAM,UAAa,AAAA,oBAAiB,KAAK;AAEzC,UAAI,CAAC,QAAQ,UAAU;AACnB,cAAM,IAAI,MAAM;;AAGpB,YAAM,QAAQ,KAAK;AAEnB,UAAI,QAAQ,MAAM,OAAO,MAAM;AAE3B,gBAAQ,KAAK,aAAa;;AAG9B,YAAM,EAAC,MAAM,KAAK,QAAO,WAAW,KAAK,aAAa;QAClD,MAAM;;AAGV,UAAI,IAAI,WAAW,WAAW,mBAAmB;AAC7C,cAAM,IAAI,MAAM,2BAA2B;;AAG/C,UAAI,CAAC,IAAI,MAAM;AACX,YAAI,OAAO,KAAK,SAAS,KAAK;AAC9B,gBAAQ,KAAK,oEAAoE,IAAI;;AAGzF,cAAQ,IAAI,aAAa,KAAK,aAAa,KAAK;AAEhD,YAAM,MAAK,SAAS;QAChB,QAAQ;;AAGZ,YAAM,MAAM,MAAM,IAAG,KAAK,IAAI,iBAAiB;QAC3C,QAAQ,IAAI;QACZ,KAAK,IAAI,MAAM,IAAI;QACnB,MAAM;UACN,MAAM,CAAA,SAAO;AACb,cAAM,IAAI,MAAM,kDAAkD;SACnE,QAAQ,MAAM;AACb,gBAAQ;;AAEZ,UAAI,IAAI,UAAU,mBAAmB,KAAK;AACtC,cAAM,IAAI,MAAM,kDAAkD,IAAI,UAAU;;AAGpF,UAAI,CAAC,IAAI,UAAU;AAAW,cAAM,IAAI,MAAM,kDAAkD,IAAI,UAAU;AAC9G,aAAO,IAAI,UAAU;;;EAQnB,oBACF,QACA,KACe;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAEf,YAAM,SAAS,SAAS;QACpB,aAAa,YAAY;QACzB,QAAQ;;AAGZ,YAAM,UAAU,IAAI,6BAA6B;QAC7C,QAAQ;QACR,iBAAiB;QACjB,aAAa;QACb,KAAK;;AAGT,YAAM,SAAS,MAAM,OAAO,KAAK;AAEjC,UAAI,OAAO,UAAU,mBAAmB,KAAK;AACzC,cAAM,IAAI,MAAM,mEAAmE,OAAO,6BAA6B,OAAO,UAAU;;AAG5I,UAAI,CAAC,OAAO,UAAU;AAClB,cAAM,IAAI,MAAM,mEAAmE,OAAO;;AAG9F,aAAO,OAAO;;;EAGlB,KAAK,KAAa,OAAgD;AAC9D,YAAQ,IAAI,SAAS,OAAO,MAAK,KAAK;AACtC,WAAO,MAAM,KAAK;;EAGtB,uBAAuB,OAA+D;AAClF,UAAM,SAAwB;MAC1B,QAAQ;MACR,QAAQ;MACR,MAAM;;AAGV,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,YAAM,OAAO,GAAG,QAAQ,CAAC,SAAS;AAC9B,eAAO,UAAU;;AAGrB,YAAM,OAAO,GAAG,QAAQ,CAAC,SAAS;AAC9B,eAAO,UAAU;;AAGrB,YAAM,GAAG,SAAS,CAAC,SAAS;AACxB,eAAO,OAAO,SAAS,IAAI,IAAI;AAC/B,gBAAQ;;AAGZ,YAAM,GAAG,SAAS,CAAC,QAAQ;AACvB,eAAO;;;;;AAWhB,uBAAuB,QAAgB,SAAkC;AAC5E,QAAM,IAAI,IAAI,SAAS,QAAQ;AAC/B,UAAQ,IAAI,CAAC,EAAE,eAAe,EAAE,mBAAmB,EAAE,uBAAuB,KAAK,CAAC,QAAQ;KAEvF,MAAM,CAAC,QAAQ;AACd,UAAM,IAAI,MAAM;;AAEpB,SAAO;;AAGX,IAAM,QAAS,WAA0C;AACrD,MAAI;AAEJ,kBAAgB;AACZ,UAAM,YAAY,KAAK,KAAK,QAAQ,OAAO;AAE3C,QAAI,CAAI,AAAA,cAAW,YAAY;AAC3B,cAAQ,IAAI,0BAA0B;AACtC,oBAAc,WAAW,KAAK,UAAU;WACrC;AACH,cAAQ,IAAI,sBAAsB;;AAGtC,WAAO;MACH,MAAM,IAAI;MACV,MAAM;MACN,KAAK,CAAC,QAAqC;AACvC,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,YAAI,OAAM,KAAK,WAAW,KAAK;AAC3B,iBAAO;;AAEX,eAAO,OAAM;;MAEjB,KAAK,CAAC,KAAa,UAAkC;AACjD,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,YAAI,OAAM,MAAM;AACZ;;AAGJ,eAAM,OAAO;AACb,sBAAc,WAAW,KAAK,UAAU;AACxC,eAAO;;MAEX,KAAK,CAAC,QAAyB;AAC3B,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,YAAI,OAAM,MAAM;AACZ,iBAAO;;AAEX,eAAO;;MAEX,QAAQ,CAAC,QAAgB;AACrB,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,eAAO,OAAM;AAEb,sBAAc,WAAW,KAAK,UAAU;;MAE5C,OAAO,MAAM;AACT,sBAAc,WAAW,KAAK,UAAU;;MAE5C,MAAM,MAAM;AACR,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAC9B,eAAO,OAAO,KAAK,QAAO;;MAE9B,MAAM,MAAM;AACR,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAC9B,eAAO,OAAO,KAAK;;;;AAK/B,SAAO;IACH,aAAa,MAAM;AACf,UAAI,CAAC,QAAO;AACR,iBAAQ;;AAEZ,aAAO;;;;;;ADjrBnB,IAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAed,IAAM,OAAO,IAAI;AAAA,EACb,UAAU;AAAA,EACV,aAAa;AAAA,EACb,UAAU;AAAA,EACV,QAAQ;AAAA,EAGR,MAAM;AAAA,EACN,MAAM;AAAA,EACN,MAAM;AAAA,EACN,MAAM;AAAA;AAGV,IAAI,KAAK,WAAW;AAChB,WAAS;AACT,UAAQ,KAAK;AAAA;AAGjB,IAAI,KAAK,cAAc;AACnB,WAAS;AACT,UAAQ,KAAK;AAAA;AAEjB,IAAM,WAAW,KAAK;AACtB,IAAI,OAAO,KAAK,MAAM,WAAW,GAAG;AAChC,WAAS;AACT,UAAQ,KAAK;AAAA;AAGjB,IAAM,aAAa;AAAA,EACf,QAAQ;AAAA;AAGZ,KAAM,eAAqB;AAAA;AACvB,QAAI,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,IAAI;AAAA;AAER,QAAI,KAAK,WAAW;AAChB,YAAM,OAAO,KAAK;AAAA;AAGtB,QAAI,KAAK,SAAS;AACd,YAAM,KAAK,KAAK;AAAA;AAGpB,QAAI,SAAS,QAAQ,aAAa,IAAI;AAClC,YAAM,YAAY,WAAW;AAAA;AAGjC,UAAM,IAAI,cAAc,MAAM,MAAM;AAAA,MAChC,WAAW;AAAA;AAGf,UAAM,YAAY,MAAM,EAAE;AAE1B,QAAI,CAAC,WAAW;AACZ,eAAS;AACT,cAAQ,KAAK;AAAA;AAEjB,YAAQ,IAAI;AAEZ,aAAS;AA0ET,YAAQ,KAAK;AAAA;AAAA;AAGjB,kBAAkB,KAAK;AACnB,SAAO,QAAQ,WACT,QAAQ,OAAO,MAAM,GAAG;AAAA,KACxB,QAAQ,OAAO,MAAM,GAAG,KAAK,UAAU,KAAK,MAAM;AAAA;AAAA;AAI5D,QAAQ,GAAG,sBAAsB,CAAC,QAAQ,YAAY;AAClD,WAAS;AACT,UAAQ,KAAK;AAAA;",
  "names": []
}
