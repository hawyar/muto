{
  "version": 3,
  "sources": ["../bin/cli.js", "../lib/engine.ts"],
  "sourcesContent": ["#!/usr/bin/env node\nimport arg from \"arg\"\nimport {createCatalog} from \"../dist/muto.js\";\n\nconst usage = `\nUsage:\n  $muto [options]\n  \n  commands:\n    upload\tuploads the specified file to S3\n\n  options:\n    -h, --help      output usage information \\n -v, --version   output the version number\n    -v, --version  output the version number\n\n    -f --from       The path to the file to source from\n    -t --to         The path to the file to target to\n`;\n\nconst args = arg({\n    \"--help\": Boolean,\n    \"--version\": Boolean,\n    \"--from\": String,\n    \"--to\": String,\n\n    // aliases\n    \"-h\": \"--help\",\n    \"-v\": \"--version\",\n    \"-f\": \"--from\",\n    \"-t\": \"--to\",\n});\n\nif (args[\"--help\"]) {\n    stdWrite(usage);\n    process.exit(0);\n}\n\nif (args[\"--version\"]) {\n    stdWrite(`v0.1.0`);\n    process.exit(0);\n}\nconst commands = args[\"_\"];\nif (Object.keys(args).length === 1) {\n    stdWrite(usage);\n    process.exit(0);\n}\n\nconst operations = {\n    upload: \"UPLOAD\",\n};\n\nvoid (async function run() {\n    let input = {\n        from: '',\n        to: '',\n    }\n    if (args[\"--from\"]) {\n        input.from = args[\"--from\"];\n    }\n\n    if (args[\"--to\"]) {\n        input.to = args[\"--to\"];\n    }\n\n    if (commands.indexOf(\"upload\") == -1) {\n        input.operation = operations.upload;\n    }\n\n\n    const dataset = await createCatalog(input.from, {\n        name: \"albums\",\n        destination: \"s3://hwyr-cms/testme/albums.csv\",\n        output: \"json\",\n    })\n\n    //\n    // if (!args[\"--from\"]) {\n    //     stdWrite(\n    //         `Error: no source given for operation, provide a valid source path \\nExample: \\n \\t File system: ./my-datasets  \\n \\t AWS S3: s3://my-bucket/datasets/\n    // \t\t`\n    //     );\n    //     process.exit(1);\n    // }\n    //\n    // if (!args[\"--to\"]) {\n    //     stdWrite(\n    //         `Error: no destination given for operation, provide a valid destination path \\nExample: \\n \\t File system: ./my-datasets  \\n \\t AWS S3: s3://my-bucket/datasets/\n    // \t\t`\n    //     );\n    //     process.exit(1);\n    // }\n    //\n    // config.from = args[\"--from\"];\n    // config.to = args[\"--to\"];\n    //\n    // const w = createWorkflow(\"my_etl\");\n    //\n    // // if fs and not dir throw before initializing engine\n    //\n    // if (\n    //     config.from.startsWith(\"/\") ||\n    //     config.from.startsWith(\"./\") ||\n    //     config.from.startsWith(\"../\")\n    // ) {\n    //     const isDir = await fs\n    //         .stat(config.from)\n    //         .then((stat) => stat.isDirectory())\n    //         .catch((err) => {\n    //             stdWrite(\"Error: given source is not a valid directory\");\n    //             process.exit(1);\n    //         });\n    //\n    //     if (!isDir) {\n    //         stdWrite(\n    //             \"Error: unable to open source, please make sure source is a valid path\"\n    //         );\n    //         process.exit(1);\n    //     }\n    //\n    //     stdWrite(`Created new worklow`);\n    //\n    //     const files = await fs\n    //         .readdir(config.from)\n    //         .then((files) => files)\n    //         .catch((err) => {\n    //             stdWrite(err);\n    //             process.exit(1);\n    //         });\n    //\n    //     for (const file of files) {\n    //         if (!file.endsWith(\".csv\")) return;\n    //         const src = \"./\" + path.normalize(path.join(config.from, file));\n    //\n    //         stdWrite(`Adding ${src} to workflow`);\n    //         const d1 = await w\n    //             .add(src, {\n    //                 delimiter: \",\",\n    //                 quote: '\"',\n    //                 header: true,\n    //             })\n    //             .catch((err) => {\n    //                 console.log(err);\n    //             });\n    //\n    //         console.log(d1);\n    //     }\n    // }\n\n    process.exit(0);\n})();\n\nfunction stdWrite(msg) {\n    typeof msg === \"string\"\n        ? process.stdout.write(`${msg} \\n`)\n        : process.stdout.write(`${JSON.stringify(msg, null, 2)}\\n`);\n}\n\n// catch unhandled promises\nprocess.on(\"unhandledRejection\", (reason, promise) => {\n    stdWrite(reason);\n    process.exit(1);\n});\n", "import fs from \"fs\"\nimport {\n    CreateMultipartUploadCommand,\n    PutObjectCommand,\n    S3Client,\n    S3ClientConfig\n} from \"@aws-sdk/client-s3\"\nimport { fromIni } from \"@aws-sdk/credential-providers\"\nimport { AthenaClient, AthenaClientConfig } from \"@aws-sdk/client-athena\"\nimport { ChildProcessWithoutNullStreams, spawn } from \"child_process\"\nimport os from \"os\"\nimport path, { join } from \"path\"\nimport { VFile } from \"vfile\"\nimport { createInterface } from \"readline\"\n\nexport enum Delimiter {\n    COMMA = \",\",\n    TAB = \"\\t\",\n    SPACE = \" \",\n    PIPE = \"|\",\n    SEMICOLON = \";\",\n    COLON = \":\"\n}\n\nexport const mlr = join(process.cwd(), \"node_modules\", \".bin\", \"mlr@v6.0.0\")\nexport const sqlparser = join(\n    process.cwd(),\n    \"node_modules\",\n    \".bin\",\n    \"sqlparser@v0.1.4\"\n)\n\nexport type env = \"local\" | \"aws\"\nexport type connectorType = S3Client | fs.ReadStream\nexport type loaderType = S3Client | fs.ReadStream\n\n// TODO: better error message for errors in transform\nexport type datasetStateType =\n    | \"init\"\n    | \"transforming\"\n    | \"uploading\"\n    | \"cancelled\"\n    | \"uploaded\"\n    | \"ready\"\n\nexport type ProcessResult = {\n    stdout: string\n    stderr: string\n    code: number\n}\n\nexport type Shape = {\n    type: string\n    columns: Array<string>\n    header: boolean\n    encoding: string\n    bom: boolean\n    size: number\n    spanMultipleLines: boolean\n    quotes: boolean\n    delimiter: string\n    errors: { [key: string]: string }\n    warnings: { [key: string]: string }\n    preview: string[][]\n}\nexport type DatasetOptions = {\n    name: string\n    destination: string\n    columns: Array<string>\n    header: boolean\n    quotes: boolean\n    output: \"csv\" | \"json\"\n    delimiter: Delimiter\n}\n\nclass Catalog {\n    name: string\n    source: string\n    options: DatasetOptions\n    destination: string\n    init: Date\n    env: env\n    state: datasetStateType\n    vfile: VFile\n    pcount: number\n\n    constructor(source: string, options: DatasetOptions) {\n        this.name =\n            options && options.name ? options.name : path.basename(source)\n        this.source = source\n        this.options = options\n        this.destination = options.destination\n        this.env = \"local\"\n        this.init = new Date()\n        this.state = \"init\"\n        this.pcount = 0\n        this.vfile = new VFile({ path: this.source })\n    }\n\n    async toJson(): Promise<ChildProcessWithoutNullStreams> {\n        const json = this.exec(mlr, [\n            \"--icsv\",\n            \"--ojson\",\n            \"clean-whitespace\",\n            this.source\n        ])\n        if (!json.stdout) {\n            throw new Error(`failed to convert ${this.source} from CSV to JSON`)\n        }\n        return json\n    }\n\n    async toCSV(): Promise<ChildProcessWithoutNullStreams> {\n        const json = this.exec(mlr, [\"--icsv\", \"--ocsv\", \"cat\", this.source])\n        if (!json.stdout) {\n            throw new Error(`failed to convert ${this.source} from JSON to CSV`)\n        }\n        return json\n    }\n\n    async rowCount(): Promise<number> {\n        const count = await this.exec(mlr, [`--ojson`, `count`, this.source])\n\n        const rowCountExec = await this.promisifyProcessResult(count)\n\n        if (rowCountExec.code !== 0) {\n            throw new Error(`Error while counting rows: ${rowCountExec.stderr}`)\n        }\n\n        if (rowCountExec.stderr) {\n            throw new Error(rowCountExec.stderr)\n        }\n\n        const r = JSON.parse(rowCountExec.stdout)\n\n        if (r.length === 0) {\n            throw new Error(\"No rows found\")\n        }\n\n        return r[0].count\n    }\n\n    async getColumnHeader(): Promise<string[] | null> {\n        const res = await this.exec(mlr, [\n            `--icsv`,\n            `--ojson`,\n            `head`,\n            `-n`,\n            `1`,\n            this.source\n        ])\n\n        const colExec = await this.promisifyProcessResult(res)\n\n        if (colExec.code !== 0) {\n            return null\n        }\n\n        if (colExec.stderr) {\n            throw new Error(colExec.stderr)\n        }\n        const columns = JSON.parse(colExec.stdout)\n\n        if (columns.length === 0) {\n            return null\n        }\n\n        const first = Object.keys(columns[0])\n        this.vfile.data.columns = first\n        return first\n    }\n\n    async preview(count = 20, streamTo?: string): Promise<string[][] | string> {\n        let write: fs.WriteStream\n\n        const maxPreview = 1024 * 1024 * 10\n\n        const fsp = fs.promises\n        const stat = await fsp.stat(this.source)\n\n        if (\n            (streamTo &&\n                streamTo !== this.source &&\n                fs.createWriteStream(streamTo) instanceof fs.WriteStream) ||\n            stat.size > maxPreview\n        ) {\n            if (streamTo === undefined)\n                throw new Error(\"stream-destination-undefined\")\n            write = fs.createWriteStream(streamTo)\n\n            const previewExec = await this.exec(mlr, [\n                `--icsv`,\n                `--ojson`,\n                `head`,\n                `-n`,\n                count.toString(),\n                this.source\n            ])\n\n            previewExec.stdout.pipe(write)\n\n            console.warn(`\uD83D\uDC40 Preview saved to: ${streamTo}`)\n            return streamTo\n        }\n\n        const previewExec = await this.exec(mlr, [\n            `--icsv`,\n            `--ojson`,\n            `head`,\n            `-n`,\n            count.toString(),\n            this.source\n        ])\n\n        const prev = await this.promisifyProcessResult(previewExec)\n\n        if (prev.stderr) {\n            throw new Error(prev.stderr)\n        }\n\n        if (prev.code !== 0) {\n            throw new Error(`Error while executing mlr command`)\n        }\n\n        this.vfile.data.preview = JSON.parse(prev.stdout)\n        return JSON.parse(prev.stdout)\n    }\n\n    async detectShape(): Promise<void> {\n        const path = this.source\n        const shape: Shape = {\n            type: \"\",\n            size: 0,\n            columns: [\"\"],\n            header: false,\n            encoding: \"utf-8\",\n            bom: false,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: \",\",\n            errors: {},\n            warnings: {},\n            preview: [[\"\"]]\n        }\n\n        if (!fs.existsSync(path)) {\n            throw new Error(\n                `path-doesnt-exists: ${path} ,provide a valid path to a CSV file`\n            )\n        }\n\n        const stat = fs.statSync(path)\n        shape.size = stat.size\n\n        if (stat.size > 1024 * 1024 * 1024) {\n            throw new Error(\n                `file-size-exceeds-limit: ${path} is too large, please limit to under 1GB for now`\n            )\n        }\n\n        if (!fs.existsSync(path)) {\n            throw new Error(\n                `${path} does not exist, provide a valid path to a CSV file`\n            )\n        }\n\n        if (os.platform() === \"win32\") {\n            // TODO: handle\n            throw new Error(`scream`)\n        }\n\n        const mime = this.exec(\"file\", [path, \"--mime-type\"])\n\n        const mimeRes = await this.promisifyProcessResult(mime)\n\n        if (mimeRes.stderr) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        if (mimeRes.code !== 0) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        shape.type = mimeRes.stdout.trim()\n\n        const readLine = createInterface({\n            input: fs.createReadStream(path),\n            crlfDelay: Infinity\n        })\n\n        let count = 0\n        const max = 20\n\n        const first = {\n            row: [\"\"],\n            del: \"\"\n        }\n\n        // hold the previous line while rl proceeds to next line using \\r\\n as a delimiter\n        let previous = \"\"\n\n        const delimiters = [\",\", \";\", \"\\t\", \"|\", \":\", \" \", \"|\"]\n\n        readLine.on(\"line\", (current) => {\n            if (count === 0) {\n                delimiters.forEach((d) => {\n                    if (current.split(d).length > 1) {\n                        first.row = current.split(d)\n                        first.del = d\n                    }\n                })\n\n                if (first.del === \"\" || first.row.length <= 1) {\n                    shape.errors[\n                        \"unrecognizedDelimiter\"\n                    ] = `${path} does not have a recognized delimiter`\n                    shape.header = false\n                }\n                const isDigit = /\\d+/\n\n                // const hasDigitInHeader = first.row.some((el) => isDigit.test(el));\n                // if (hasDigitInHeader) {\n                //     shape.header = false;\n                //     shape.warnings[\"noHeader\"] = `no header found`;\n                //     count++;\n                //     return;\n                // }\n\n                shape.header = true\n                shape.delimiter = first.del\n                shape.columns = first.row\n            }\n\n            if (count > 0 && count < max) {\n                // there is a chance the record spans next line\n                const inlineQuotes = current.split(`\"`).length - 1\n\n                if (previous) {\n                    if (inlineQuotes % 2 !== 0) {\n                        // TODO: make sure previous + current\n                        // console.log(previous + l);\n                        shape.spanMultipleLines = true\n                    }\n                }\n                // if odd number of quotes and consider escaped quotes such as: \"aaa\",\"b\"\"bb\",\"ccc\"\n                if (\n                    inlineQuotes % 2 !== 0 &&\n                    current.split(`\"\"`).length - 1 !== 1\n                ) {\n                    previous = current\n                }\n\n                const width = current.split(first.del).length\n\n                if (width !== first.row.length) {\n                    shape.errors[\"rowWidthMismatch\"] = `row width mismatch`\n                    return\n                }\n                shape.preview.push(current.split(first.del))\n            }\n            count++\n        })\n\n        readLine.on(\"close\", () => {\n            this.vfile.data.shape = shape\n        })\n    }\n\n    determineLoader(): void {\n        if (this.destination.startsWith(\"s3://\")) {\n            this.vfile.data.loader = s3Client({\n                credentials: credentials(\"default\"),\n                region: \"us-east-2\"\n            })\n            return\n        }\n\n        if (\n            this.source.startsWith(\"/\") ||\n            this.source.startsWith(\"../\") ||\n            this.source.startsWith(\"./\")\n        ) {\n            this.vfile.data.loader = fs.createReadStream(this.source)\n            return\n        }\n    }\n\n    determineConnector(): void {\n        switch (this.env) {\n            case \"local\":\n                if (!fs.existsSync(this.source)) {\n                    throw new Error(\n                        `file: ${this.source} not found, please provide a valid file path`\n                    )\n                }\n                this.vfile.data.connector = fs.createReadStream(this.source)\n                break\n\n            case \"aws\":\n                this.vfile.data.connector = s3Client({\n                    credentials: credentials(\"default\"),\n                    region: \"us-east-2\"\n                })\n                break\n\n            default:\n                throw new Error(`unsupported-source for: ${this.source}`)\n        }\n    }\n\n    determineEnv() {\n        this.vfile.data.source = this.source\n        if (\n            this.source.startsWith(\"/\") ||\n            this.source.startsWith(\"../\") ||\n            this.source.startsWith(\"./\")\n        ) {\n            this.env = \"local\"\n            return\n        }\n\n        if (this.source.startsWith(\"s3://\")) {\n            this.env = \"aws\"\n            return\n        }\n\n        throw new Error(`invalid-source-type: ${this.source}`)\n    }\n\n    fileSize(): number {\n        const max = 1024 * 1024 * 50\n\n        if (!fs.existsSync(this.source)) {\n            throw new Error(\n                `path-doesnt-exists: ${this.source} ,provide a valid path to a CSV file`\n            )\n        }\n\n        const stat = fs.statSync(this.source)\n\n        if (stat.size > max) {\n            throw new Error(\n                `file-size-exceeds-limit: ${this.source} is too large, please limit to 50MB`\n            )\n        }\n        return stat.size\n    }\n\n    async uploadToS3(): Promise<string> {\n        if (!this.source || !this.destination) {\n            throw new Error(\n                \"source or destination not set. Both must be defined to upload to S3\"\n            )\n        }\n\n        const fStream = fs.createReadStream(this.source)\n\n        if (!fStream.readable) {\n            throw new Error(\n                \"failed-to-read-source: Make sure the provided file is readable\"\n            )\n        }\n\n        const fSize = this.fileSize()\n\n        if (fSize > 100 * 1024 * 1024) {\n            //TODO: init multipart upload then upload parts\n            console.warn(`file size ${fSize} is larger than 100MB`)\n        }\n\n        const { data: uri, err } = parseS3Uri(this.destination, {\n            file: true\n        })\n\n        if (err.toString().startsWith(`invalid-s3-uri`)) {\n            throw new Error(`failed-to-parse-s3-uri: ${err}`)\n        }\n\n        if (!uri.file) {\n            uri.file = path.basename(this.source)\n            console.warn(\n                \"Destination filename not provided. Using source source basename\" +\n                    uri.file\n            )\n        }\n\n        console.log(`uploading ${this.source} to ${this.destination}`)\n\n        const s3 = s3Client({\n            region: \"us-east-2\"\n        })\n\n        const res = await s3\n            .send(\n                new PutObjectCommand({\n                    Bucket: uri.bucket,\n                    Key: uri.key + uri.file,\n                    Body: fStream\n                })\n            )\n            .catch((err) => {\n                throw new Error(\n                    `failed-upload-s3: Error while uploading to S3: ${err}`\n                )\n            })\n            .finally(() => {\n                fStream.close()\n            })\n\n        if (res.$metadata.httpStatusCode !== 200) {\n            throw new Error(\n                `failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`\n            )\n        }\n\n        if (!res.$metadata.requestId)\n            throw new Error(\n                `failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`\n            )\n        return res.$metadata.requestId\n    }\n\n    async initMultipartUpload(bucket: string, key: string): Promise<string> {\n        const client = s3Client({\n            credentials: credentials(\"default\"),\n            region: \"us-east-2\"\n        })\n\n        const command = new CreateMultipartUploadCommand({\n            Bucket: bucket,\n            ContentEncoding: \"utf8\",\n            ContentType: \"text/csv\",\n            Key: key\n        })\n\n        const result = await client.send(command)\n\n        if (result.$metadata.httpStatusCode !== 200) {\n            throw new Error(\n                `failed-multipart-upload: Error while creating multipart upload: ${result.UploadId} with status code ${result.$metadata.httpStatusCode}`\n            )\n        }\n\n        if (!result.UploadId) {\n            throw new Error(\n                `failed-multipart-upload: Error while creating multipart upload: ${result.UploadId}`\n            )\n        }\n\n        return result.UploadId\n    }\n\n    exec(cmd: string, args: string[]): ChildProcessWithoutNullStreams {\n        console.log(`exec: ${cmd} ${args.join(\" \")}`)\n\n        if (this.pcount > 5) {\n            throw new Error(`too-many-processes: ${this.pcount}`)\n        }\n\n        this.pcount++\n        return spawn(cmd, args, {})\n    }\n\n    promisifyProcessResult(\n        child: ChildProcessWithoutNullStreams\n    ): Promise<ProcessResult> {\n        const result: ProcessResult = {\n            stdout: \"\",\n            stderr: \"\",\n            code: 0\n        }\n\n        return new Promise((resolve, reject) => {\n            child.stdout.on(\"data\", (data) => {\n                result.stdout += data\n            })\n\n            child.stderr.on(\"data\", (data) => {\n                result.stderr += data\n            })\n\n            child.on(\"close\", (code) => {\n                result.code = code === 0 ? 0 : 1\n                resolve(result)\n            })\n\n            child.on(\"error\", (err) => {\n                reject(err)\n            })\n        })\n    }\n}\n\nexport async function createCatalog(\n    source: string,\n    opt: DatasetOptions\n): Promise<Catalog> {\n    return new Promise((resolve, reject) => {\n        if (!source) {\n            reject(new Error(`failed-to-create-dataset: source is required`))\n        }\n\n        if (!opt || !opt.destination) {\n            reject(\n                new Error(`failed-to-create-dataset: destination is required`)\n            )\n        }\n\n        if (!source.endsWith(\".csv\")) {\n            reject(\n                new Error(\n                    `failed to create dataset: ${source}, source must be a csv file`\n                )\n            )\n        }\n\n        const catalog = new Catalog(source, opt)\n\n        Promise.all([\n            catalog.determineEnv(),\n            catalog.detectShape(),\n            catalog.determineConnector(),\n            catalog.determineLoader()\n        ])\n            .then(() => {\n                console.log(`created catalog for ${source}`)\n                resolve(catalog)\n            })\n            .catch((err) => reject(err))\n    })\n}\n\nfunction parseQuery(query: string): Promise<any> {\n    const qq = {\n        query: query,\n        select: [],\n        from: [],\n        where: [],\n        orderBy: [],\n        groupBy: [],\n        limit: null,\n        offset: null\n    }\n\n    const child = spawn(sqlparser, [qq.query])\n\n    return new Promise((resolve, reject) => {\n        child.on(\"error\", (err) => {\n            reject(err)\n        })\n\n        child.on(\"close\", (code) => {\n            if (code !== 0) {\n                reject(`failed-sqlparser: Error while parsing query: ${code}`)\n            }\n        })\n\n        child.stdout.on(\"data\", (data) => {\n            const parsed = JSON.parse(data.toString())\n            if (parsed.error) {\n                reject(\n                    `failed-sqlparser: Error while parsing query: ${parsed.error}`\n                )\n            }\n            resolve(parsed)\n        })\n    })\n}\n\nclass Workflow {\n    name: string\n    catalogs: Map<string, Catalog>\n    readonly createdAt: Date\n    env: env\n    qquery: string\n\n    constructor(name: string) {\n        this.name = name\n        this.catalogs = new Map()\n        this.createdAt = new Date()\n        this.env = \"local\"\n        this.qquery = \"\"\n    }\n\n    list(): Catalog[] {\n        return Array.from(this.catalogs.values())\n    }\n\n    remove(dataset: Catalog) {\n        this.catalogs.delete(dataset.source)\n    }\n\n    get(source: string): Catalog | null {\n        return this.catalogs.get(source) || null\n    }\n\n    add(d: Catalog): Promise<string> {\n        return new Promise((resolve, reject) => {\n            if (this.catalogs.has(d.source)) {\n                reject(\n                    `failed-add-dataset: Dataset with source ${d.source} already exists`\n                )\n            }\n            Promise.all([d.determineConnector(), d.determineLoader()])\n                .catch((err) => {\n                    throw new Error(err)\n                })\n                .then(() => {\n                    this.catalogs.set(d.source, d)\n                    resolve(d.source)\n                })\n                .catch((err) => {\n                    reject(err)\n                })\n        })\n    }\n\n    query(q: string): Promise<string> {\n        parseQuery(q)\n            .then((parsed) => {\n                this.qquery = q\n                console.log(parsed)\n            })\n            .catch((err) => {\n                throw new Error(err)\n            })\n        return new Promise((resolve, reject) => {\n            resolve(\"ok\")\n        })\n    }\n}\n\nexport function createWorkflow(name: string): Workflow {\n    return new Workflow(name)\n}\n\nconst credentials = (profile: string) =>\n    fromIni({\n        profile: profile,\n        mfaCodeProvider: async (mfaSerial) => {\n            return mfaSerial\n        }\n    })\n\nlet s3: S3Client\n\nfunction s3Client(config: S3ClientConfig): S3Client {\n    if (!s3) {\n        console.log(\"setting up s3 client\")\n        s3 = new S3Client(config)\n    }\n    return s3\n}\n\nlet athena: AthenaClient\n\nfunction athenaClient(config: AthenaClientConfig): AthenaClient {\n    if (!athena) {\n        console.log(\"creating athena client\")\n        athena = new AthenaClient(config)\n    }\n    return athena\n}\n\nfunction parseS3Uri(\n    uri: string,\n    options: {\n        file: boolean\n    }\n): {\n    data: {\n        bucket: string\n        key: string\n        file: string\n    }\n    err: string\n} {\n    const opt = {\n        file: options && options.file ? options.file : false\n    }\n\n    if (!uri.startsWith(\"s3://\") || uri.split(\":/\")[0] !== \"s3\") {\n        throw new Error(`invalid-s3-uri: ${uri}`)\n    }\n\n    let err = \"\"\n    const result = {\n        bucket: \"\",\n        key: \"\",\n        file: \"\"\n    }\n\n    const src = uri.split(\":/\")[1]\n    const [bucket, ...keys] = src.split(\"/\").splice(1)\n\n    result.bucket = bucket\n    result.key = keys.join(\"/\")\n\n    keys.forEach((k, i) => {\n        if (i === keys.length - 1) {\n            const last = k.split(\".\").length\n            if (opt.file && last === 1)\n                err = `uri should be a given, given: ${uri}`\n\n            if (!opt.file && last === 1) return\n\n            if (!opt.file && last > 1) {\n                err = `Invalid S3 uri, ${uri} should not end with a file name`\n                return\n            }\n\n            if (!opt.file && k.split(\".\")[1] !== \"\" && last > 1)\n                err = `${uri} should not be a file endpoint: ${k}`\n\n            if (last > 1 && k.split(\".\")[1] !== \"\") result.file = k\n        }\n    })\n    return {\n        data: result,\n        err: err\n    }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;AACA;;;ACDA;AACA;;;;;AAMA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AAWO,IAAM,MAAM,KAAK,QAAQ,OAAO,gBAAgB,QAAQ;AACxD,IAAM,YAAY,KACrB,QAAQ,OACR,gBACA,QACA;AA8CJ,IAAA,UAAA,MAAc;EAWV,YAAY,QAAgB,SAAyB;AACjD,SAAK,OACD,WAAW,QAAQ,OAAO,QAAQ,OAAO,KAAK,SAAS;AAC3D,SAAK,SAAS;AACd,SAAK,UAAU;AACf,SAAK,cAAc,QAAQ;AAC3B,SAAK,MAAM;AACX,SAAK,OAAO,IAAI;AAChB,SAAK,QAAQ;AACb,SAAK,SAAS;AACd,SAAK,QAAQ,IAAI,MAAM,EAAE,MAAM,KAAK;;EAGlC,SAAkD;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AACpD,YAAM,OAAO,KAAK,KAAK,KAAK;QACxB;QACA;QACA;QACA,KAAK;;AAET,UAAI,CAAC,KAAK,QAAQ;AACd,cAAM,IAAI,MAAM,qBAAqB,KAAK;;AAE9C,aAAO;;;EAGL,QAAiD;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AACnD,YAAM,OAAO,KAAK,KAAK,KAAK,CAAC,UAAU,UAAU,OAAO,KAAK;AAC7D,UAAI,CAAC,KAAK,QAAQ;AACd,cAAM,IAAI,MAAM,qBAAqB,KAAK;;AAE9C,aAAO;;;EAGL,WAA4B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAC9B,YAAM,QAAQ,MAAM,KAAK,KAAK,KAAK,CAAC,WAAW,SAAS,KAAK;AAE7D,YAAM,eAAe,MAAM,KAAK,uBAAuB;AAEvD,UAAI,aAAa,SAAS,GAAG;AACzB,cAAM,IAAI,MAAM,8BAA8B,aAAa;;AAG/D,UAAI,aAAa,QAAQ;AACrB,cAAM,IAAI,MAAM,aAAa;;AAGjC,YAAM,IAAI,KAAK,MAAM,aAAa;AAElC,UAAI,EAAE,WAAW,GAAG;AAChB,cAAM,IAAI,MAAM;;AAGpB,aAAO,EAAE,GAAG;;;EAGV,kBAA4C;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAC9C,YAAM,MAAM,MAAM,KAAK,KAAK,KAAK;QAC7B;QACA;QACA;QACA;QACA;QACA,KAAK;;AAGT,YAAM,UAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,QAAQ,SAAS,GAAG;AACpB,eAAO;;AAGX,UAAI,QAAQ,QAAQ;AAChB,cAAM,IAAI,MAAM,QAAQ;;AAE5B,YAAM,UAAU,KAAK,MAAM,QAAQ;AAEnC,UAAI,QAAQ,WAAW,GAAG;AACtB,eAAO;;AAGX,YAAM,QAAQ,OAAO,KAAK,QAAQ;AAClC,WAAK,MAAM,KAAK,UAAU;AAC1B,aAAO;;;EAGL,QAAQ,QAAQ,IAAI,UAAiD;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AACvE,UAAI;AAEJ,YAAM,aAAa,OAAO,OAAO;AAEjC,YAAM,MAAM,GAAG;AACf,YAAM,OAAO,MAAM,IAAI,KAAK,KAAK;AAEjC,UACK,YACG,aAAa,KAAK,UAClB,GAAG,kBAAkB,qBAAqB,GAAG,eACjD,KAAK,OAAO,YACd;AACE,YAAI,aAAa;AACb,gBAAM,IAAI,MAAM;AACpB,gBAAQ,GAAG,kBAAkB;AAE7B,cAAM,eAAc,MAAM,KAAK,KAAK,KAAK;UACrC;UACA;UACA;UACA;UACA,MAAM;UACN,KAAK;;AAGT,qBAAY,OAAO,KAAK;AAExB,gBAAQ,KAAK,+BAAwB;AACrC,eAAO;;AAGX,YAAM,cAAc,MAAM,KAAK,KAAK,KAAK;QACrC;QACA;QACA;QACA;QACA,MAAM;QACN,KAAK;;AAGT,YAAM,OAAO,MAAM,KAAK,uBAAuB;AAE/C,UAAI,KAAK,QAAQ;AACb,cAAM,IAAI,MAAM,KAAK;;AAGzB,UAAI,KAAK,SAAS,GAAG;AACjB,cAAM,IAAI,MAAM;;AAGpB,WAAK,MAAM,KAAK,UAAU,KAAK,MAAM,KAAK;AAC1C,aAAO,KAAK,MAAM,KAAK;;;EAGrB,cAA6B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAC/B,YAAM,QAAO,KAAK;AAClB,YAAM,QAAe;QACjB,MAAM;QACN,MAAM;QACN,SAAS,CAAC;QACV,QAAQ;QACR,UAAU;QACV,KAAK;QACL,mBAAmB;QACnB,QAAQ;QACR,WAAW;QACX,QAAQ;QACR,UAAU;QACV,SAAS,CAAC,CAAC;;AAGf,UAAI,CAAC,GAAG,WAAW,QAAO;AACtB,cAAM,IAAI,MACN,uBAAuB;;AAI/B,YAAM,OAAO,GAAG,SAAS;AACzB,YAAM,OAAO,KAAK;AAElB,UAAI,KAAK,OAAO,OAAO,OAAO,MAAM;AAChC,cAAM,IAAI,MACN,4BAA4B;;AAIpC,UAAI,CAAC,GAAG,WAAW,QAAO;AACtB,cAAM,IAAI,MACN,GAAG;;AAIX,UAAI,GAAG,eAAe,SAAS;AAE3B,cAAM,IAAI,MAAM;;AAGpB,YAAM,OAAO,KAAK,KAAK,QAAQ,CAAC,OAAM;AAEtC,YAAM,UAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,QAAQ,QAAQ;AAChB,cAAM,IAAI,MAAM,+BAA+B,QAAQ;;AAG3D,UAAI,QAAQ,SAAS,GAAG;AACpB,cAAM,IAAI,MAAM,+BAA+B,QAAQ;;AAG3D,YAAM,OAAO,QAAQ,OAAO;AAE5B,YAAM,WAAW,gBAAgB;QAC7B,OAAO,GAAG,iBAAiB;QAC3B,WAAW;;AAGf,UAAI,QAAQ;AACZ,YAAM,MAAM;AAEZ,YAAM,QAAQ;QACV,KAAK,CAAC;QACN,KAAK;;AAIT,UAAI,WAAW;AAEf,YAAM,aAAa,CAAC,KAAK,KAAK,KAAM,KAAK,KAAK,KAAK;AAEnD,eAAS,GAAG,QAAQ,CAAC,YAAY;AAC7B,YAAI,UAAU,GAAG;AACb,qBAAW,QAAQ,CAAC,MAAM;AACtB,gBAAI,QAAQ,MAAM,GAAG,SAAS,GAAG;AAC7B,oBAAM,MAAM,QAAQ,MAAM;AAC1B,oBAAM,MAAM;;;AAIpB,cAAI,MAAM,QAAQ,MAAM,MAAM,IAAI,UAAU,GAAG;AAC3C,kBAAM,OACF,2BACA,GAAG;AACP,kBAAM,SAAS;;AAEnB,gBAAM,UAAU;AAUhB,gBAAM,SAAS;AACf,gBAAM,YAAY,MAAM;AACxB,gBAAM,UAAU,MAAM;;AAG1B,YAAI,QAAQ,KAAK,QAAQ,KAAK;AAE1B,gBAAM,eAAe,QAAQ,MAAM,KAAK,SAAS;AAEjD,cAAI,UAAU;AACV,gBAAI,eAAe,MAAM,GAAG;AAGxB,oBAAM,oBAAoB;;;AAIlC,cACI,eAAe,MAAM,KACrB,QAAQ,MAAM,MAAM,SAAS,MAAM,GACrC;AACE,uBAAW;;AAGf,gBAAM,QAAQ,QAAQ,MAAM,MAAM,KAAK;AAEvC,cAAI,UAAU,MAAM,IAAI,QAAQ;AAC5B,kBAAM,OAAO,sBAAsB;AACnC;;AAEJ,gBAAM,QAAQ,KAAK,QAAQ,MAAM,MAAM;;AAE3C;;AAGJ,eAAS,GAAG,SAAS,MAAM;AACvB,aAAK,MAAM,KAAK,QAAQ;;;;EAIhC,kBAAwB;AACpB,QAAI,KAAK,YAAY,WAAW,UAAU;AACtC,WAAK,MAAM,KAAK,SAAS,SAAS;QAC9B,aAAa,YAAY;QACzB,QAAQ;;AAEZ;;AAGJ,QACI,KAAK,OAAO,WAAW,QACvB,KAAK,OAAO,WAAW,UACvB,KAAK,OAAO,WAAW,OACzB;AACE,WAAK,MAAM,KAAK,SAAS,GAAG,iBAAiB,KAAK;AAClD;;;EAIR,qBAA2B;AACvB,YAAQ,KAAK;WACJ;AACD,YAAI,CAAC,GAAG,WAAW,KAAK,SAAS;AAC7B,gBAAM,IAAI,MACN,SAAS,KAAK;;AAGtB,aAAK,MAAM,KAAK,YAAY,GAAG,iBAAiB,KAAK;AACrD;WAEC;AACD,aAAK,MAAM,KAAK,YAAY,SAAS;UACjC,aAAa,YAAY;UACzB,QAAQ;;AAEZ;;AAGA,cAAM,IAAI,MAAM,2BAA2B,KAAK;;;EAI5D,eAAe;AACX,SAAK,MAAM,KAAK,SAAS,KAAK;AAC9B,QACI,KAAK,OAAO,WAAW,QACvB,KAAK,OAAO,WAAW,UACvB,KAAK,OAAO,WAAW,OACzB;AACE,WAAK,MAAM;AACX;;AAGJ,QAAI,KAAK,OAAO,WAAW,UAAU;AACjC,WAAK,MAAM;AACX;;AAGJ,UAAM,IAAI,MAAM,wBAAwB,KAAK;;EAGjD,WAAmB;AACf,UAAM,MAAM,OAAO,OAAO;AAE1B,QAAI,CAAC,GAAG,WAAW,KAAK,SAAS;AAC7B,YAAM,IAAI,MACN,uBAAuB,KAAK;;AAIpC,UAAM,OAAO,GAAG,SAAS,KAAK;AAE9B,QAAI,KAAK,OAAO,KAAK;AACjB,YAAM,IAAI,MACN,4BAA4B,KAAK;;AAGzC,WAAO,KAAK;;EAGV,aAA8B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AAChC,UAAI,CAAC,KAAK,UAAU,CAAC,KAAK,aAAa;AACnC,cAAM,IAAI,MACN;;AAIR,YAAM,UAAU,GAAG,iBAAiB,KAAK;AAEzC,UAAI,CAAC,QAAQ,UAAU;AACnB,cAAM,IAAI,MACN;;AAIR,YAAM,QAAQ,KAAK;AAEnB,UAAI,QAAQ,MAAM,OAAO,MAAM;AAE3B,gBAAQ,KAAK,aAAa;;AAG9B,YAAM,EAAE,MAAM,KAAK,QAAQ,WAAW,KAAK,aAAa;QACpD,MAAM;;AAGV,UAAI,IAAI,WAAW,WAAW,mBAAmB;AAC7C,cAAM,IAAI,MAAM,2BAA2B;;AAG/C,UAAI,CAAC,IAAI,MAAM;AACX,YAAI,OAAO,KAAK,SAAS,KAAK;AAC9B,gBAAQ,KACJ,oEACI,IAAI;;AAIhB,cAAQ,IAAI,aAAa,KAAK,aAAa,KAAK;AAEhD,YAAM,MAAK,SAAS;QAChB,QAAQ;;AAGZ,YAAM,MAAM,MAAM,IACb,KACG,IAAI,iBAAiB;QACjB,QAAQ,IAAI;QACZ,KAAK,IAAI,MAAM,IAAI;QACnB,MAAM;UAGb,MAAM,CAAC,SAAQ;AACZ,cAAM,IAAI,MACN,kDAAkD;SAGzD,QAAQ,MAAM;AACX,gBAAQ;;AAGhB,UAAI,IAAI,UAAU,mBAAmB,KAAK;AACtC,cAAM,IAAI,MACN,kDAAkD,IAAI,UAAU;;AAIxE,UAAI,CAAC,IAAI,UAAU;AACf,cAAM,IAAI,MACN,kDAAkD,IAAI,UAAU;AAExE,aAAO,IAAI,UAAU;;;EAGnB,oBAAoB,QAAgB,KAA8B;AAAA,WAAA,SAAA,MAAA,MAAA,aAAA;AACpE,YAAM,SAAS,SAAS;QACpB,aAAa,YAAY;QACzB,QAAQ;;AAGZ,YAAM,UAAU,IAAI,6BAA6B;QAC7C,QAAQ;QACR,iBAAiB;QACjB,aAAa;QACb,KAAK;;AAGT,YAAM,SAAS,MAAM,OAAO,KAAK;AAEjC,UAAI,OAAO,UAAU,mBAAmB,KAAK;AACzC,cAAM,IAAI,MACN,mEAAmE,OAAO,6BAA6B,OAAO,UAAU;;AAIhI,UAAI,CAAC,OAAO,UAAU;AAClB,cAAM,IAAI,MACN,mEAAmE,OAAO;;AAIlF,aAAO,OAAO;;;EAGlB,KAAK,KAAa,OAAgD;AAC9D,YAAQ,IAAI,SAAS,OAAO,MAAK,KAAK;AAEtC,QAAI,KAAK,SAAS,GAAG;AACjB,YAAM,IAAI,MAAM,uBAAuB,KAAK;;AAGhD,SAAK;AACL,WAAO,MAAM,KAAK,OAAM;;EAG5B,uBACI,OACsB;AACtB,UAAM,SAAwB;MAC1B,QAAQ;MACR,QAAQ;MACR,MAAM;;AAGV,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,YAAM,OAAO,GAAG,QAAQ,CAAC,SAAS;AAC9B,eAAO,UAAU;;AAGrB,YAAM,OAAO,GAAG,QAAQ,CAAC,SAAS;AAC9B,eAAO,UAAU;;AAGrB,YAAM,GAAG,SAAS,CAAC,SAAS;AACxB,eAAO,OAAO,SAAS,IAAI,IAAI;AAC/B,gBAAQ;;AAGZ,YAAM,GAAG,SAAS,CAAC,QAAQ;AACvB,eAAO;;;;;AAMvB,uBACI,QACA,KACgB;AAAA,SAAA,SAAA,MAAA,MAAA,aAAA;AAChB,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,UAAI,CAAC,QAAQ;AACT,eAAO,IAAI,MAAM;;AAGrB,UAAI,CAAC,OAAO,CAAC,IAAI,aAAa;AAC1B,eACI,IAAI,MAAM;;AAIlB,UAAI,CAAC,OAAO,SAAS,SAAS;AAC1B,eACI,IAAI,MACA,6BAA6B;;AAKzC,YAAM,UAAU,IAAI,QAAQ,QAAQ;AAEpC,cAAQ,IAAI;QACR,QAAQ;QACR,QAAQ;QACR,QAAQ;QACR,QAAQ;SAEP,KAAK,MAAM;AACR,gBAAQ,IAAI,uBAAuB;AACnC,gBAAQ;SAEX,MAAM,CAAC,QAAQ,OAAO;;;;AA4GnC,IAAM,cAAc,CAAC,YACjB,QAAQ;EACJ;EACA,iBAAiB,CAAO,cAAc,SAAA,QAAA,MAAA,aAAA;AAClC,WAAO;;;AAInB,IAAI;AAEJ,kBAAkB,QAAkC;AAChD,MAAI,CAAC,IAAI;AACL,YAAQ,IAAI;AACZ,SAAK,IAAI,SAAS;;AAEtB,SAAO;;AAaX,oBACI,KACA,SAUF;AACE,QAAM,MAAM;IACR,MAAM,WAAW,QAAQ,OAAO,QAAQ,OAAO;;AAGnD,MAAI,CAAC,IAAI,WAAW,YAAY,IAAI,MAAM,MAAM,OAAO,MAAM;AACzD,UAAM,IAAI,MAAM,mBAAmB;;AAGvC,MAAI,MAAM;AACV,QAAM,SAAS;IACX,QAAQ;IACR,KAAK;IACL,MAAM;;AAGV,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,QAAM,CAAC,WAAW,QAAQ,IAAI,MAAM,KAAK,OAAO;AAEhD,SAAO,SAAS;AAChB,SAAO,MAAM,KAAK,KAAK;AAEvB,OAAK,QAAQ,CAAC,GAAG,MAAM;AACnB,QAAI,MAAM,KAAK,SAAS,GAAG;AACvB,YAAM,OAAO,EAAE,MAAM,KAAK;AAC1B,UAAI,IAAI,QAAQ,SAAS;AACrB,cAAM,iCAAiC;AAE3C,UAAI,CAAC,IAAI,QAAQ,SAAS;AAAG;AAE7B,UAAI,CAAC,IAAI,QAAQ,OAAO,GAAG;AACvB,cAAM,mBAAmB;AACzB;;AAGJ,UAAI,CAAC,IAAI,QAAQ,EAAE,MAAM,KAAK,OAAO,MAAM,OAAO;AAC9C,cAAM,GAAG,sCAAsC;AAEnD,UAAI,OAAO,KAAK,EAAE,MAAM,KAAK,OAAO;AAAI,eAAO,OAAO;;;AAG9D,SAAO;IACH,MAAM;IACN;;;;;AD/yBR,IAAM,QAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAed,IAAM,OAAO,IAAI;AAAA,EACb,UAAU;AAAA,EACV,aAAa;AAAA,EACb,UAAU;AAAA,EACV,QAAQ;AAAA,EAGR,MAAM;AAAA,EACN,MAAM;AAAA,EACN,MAAM;AAAA,EACN,MAAM;AAAA;AAGV,IAAI,KAAK,WAAW;AAChB,WAAS;AACT,UAAQ,KAAK;AAAA;AAGjB,IAAI,KAAK,cAAc;AACnB,WAAS;AACT,UAAQ,KAAK;AAAA;AAEjB,IAAM,WAAW,KAAK;AACtB,IAAI,OAAO,KAAK,MAAM,WAAW,GAAG;AAChC,WAAS;AACT,UAAQ,KAAK;AAAA;AAGjB,IAAM,aAAa;AAAA,EACf,QAAQ;AAAA;AAGZ,KAAM,eAAqB;AAAA;AACvB,QAAI,QAAQ;AAAA,MACR,MAAM;AAAA,MACN,IAAI;AAAA;AAER,QAAI,KAAK,WAAW;AAChB,YAAM,OAAO,KAAK;AAAA;AAGtB,QAAI,KAAK,SAAS;AACd,YAAM,KAAK,KAAK;AAAA;AAGpB,QAAI,SAAS,QAAQ,aAAa,IAAI;AAClC,YAAM,YAAY,WAAW;AAAA;AAIjC,UAAM,UAAU,MAAM,cAAc,MAAM,MAAM;AAAA,MAC5C,MAAM;AAAA,MACN,aAAa;AAAA,MACb,QAAQ;AAAA;AA4EZ,YAAQ,KAAK;AAAA;AAAA;AAGjB,kBAAkB,KAAK;AACnB,SAAO,QAAQ,WACT,QAAQ,OAAO,MAAM,GAAG;AAAA,KACxB,QAAQ,OAAO,MAAM,GAAG,KAAK,UAAU,KAAK,MAAM;AAAA;AAAA;AAI5D,QAAQ,GAAG,sBAAsB,CAAC,QAAQ,YAAY;AAClD,WAAS;AACT,UAAQ,KAAK;AAAA;",
  "names": []
}
