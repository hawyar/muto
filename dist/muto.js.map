{
  "version": 3,
  "sources": ["../lib/engine.ts"],
  "sourcesContent": ["import * as fs from \"fs\";\nimport * as os from \"os\";\nimport {createInterface} from \"readline\"\nimport {spawn} from \"child_process\";\nimport {fromIni} from \"@aws-sdk/credential-providers\"\nimport * as fastq from \"fastq\";\nimport type {queueAsPromised} from \"fastq\";\n\nimport {\n    S3Client,\n    GetObjectCommand,\n    S3ClientConfig,\n    CreateMultipartUploadCommand\n} from \"@aws-sdk/client-s3\";\n\ntype ShapeErrType = 'unrecognizedDelimiter' | 'noHeader' | 'invalidFileType' | 'rowWidthMismatch'\n\ntype supportedDelimiters = \",\" | \";\" | \"|\" | \":\" | \"\\t\" | \" \" | \"^\" | \"~\" | \"*\" | \"!\" | \"-\" | \"_\" | \"|\"\ntype env = 'local' | 'aws'\ntype connectorType = S3Client | fs.ReadStream\n\n// Shape of a dataset object\ninterface Shape {\n    type: string,\n    columns: Array<string>,\n    header: boolean,\n    encoding: string,\n    bom: boolean,\n    spanMultipleLines: boolean,\n    quotes: boolean,\n    delimiter: string,\n    errors: { [key: string]: string }\n    warnings: { [key: string]: string },\n    preview: string[][],\n}\n\n// Dataset represents a file from a supported a data source\ninterface Dataset {\n    source: string\n    options: Options;\n    shape?: Shape\n    data?: string[][];\n    createdAt: Date;\n    connector: connectorType;\n}\n\n// Options for a dataset\ninterface Options {\n    destination: string;\n    columns: Array<string>,\n    header: boolean,\n    bom: boolean,\n    delimiter: supportedDelimiters\n}\n\n\nconst credentials = (profile: string) => fromIni({\n    profile: profile,\n    mfaCodeProvider: async (mfaSerial) => {\n        return mfaSerial\n    },\n});\n\ntype Args = {\n    source: string,\n    options: Options\n}\n\n\nclass Dataset {\n    source: string\n    options: Options\n    createdAt: Date\n    connector: connectorType\n\n    constructor(args: Args, connector: connectorType) {\n        this.source = args.source;\n        this.options = args.options;\n        this.createdAt = new Date();\n        this.connector = connector;\n    }\n}\n\n\n// Represents a workflow with a list of datasets in a local or cloud env\nclass Workflow {\n    name: string;\n    datasets: Map<string, Dataset>;\n    readonly createdAt: Date;\n    env: env;\n    queue: queueAsPromised<Args>\n\n    constructor(name: string) {\n        this.name = name;\n        this.datasets = new Map();\n        this.createdAt = new Date();\n        this.env = 'local';\n        this.queue = fastq.promise(this.#worker, 1)\n    }\n\n    async #worker({source, options}: Args): Promise<Dataset> {\n        return new Promise((resolve, reject) => {\n            if (this.datasets.has(source)) {\n                reject(new Error(`Dataset ${options.destination} already exists in the workflow`).message);\n            }\n\n            if (options.destination === \"\") {\n                console.warn(`Dataset ${source} does not have a destination`);\n            }\n\n            if (options.destination && options.destination.startsWith(\"s3://\")) {\n                const exists = this.#existsInS3(source);\n\n                if (exists) {\n                    const conn = this.#s3Connector({\n                        credentials: credentials(\"default\"),\n                        region: \"us-east-2\",\n                    });\n                    const dataset = new Dataset({source, options}, conn);\n                    this.datasets.set(source, dataset);\n                    resolve(dataset);\n                }\n                // push new dataset to the workflow\n                reject(new Error(`Dataset ${source} does not exist in S3`));\n            }\n\n            if (\n                source.startsWith(\"/\") ||\n                source.startsWith(\"../\") ||\n                source.startsWith(\"./\")\n            ) {\n                if (!source.endsWith(\".csv\")) {\n                    reject(new Error(`${source} is not a CSV file`));\n                }\n\n                const dataset = new Dataset({source, options}, this.#fsConnector(source));\n                this.datasets.set(source, dataset);\n                resolve(dataset);\n            }\n            reject(new Error(`Invalid source ${source} type`));\n        });\n\n    }\n\n\n    /**\n     * List datasets in the workflow\n     * @param options\n     * @returns\n     */\n    list(): Dataset[] {\n        return Array.from(this.datasets.values());\n    }\n\n    /**\n     * Removes dataset from the workflow\n     * @param source\n     * @param options\n     */\n    remove(dataset: Dataset) {\n        this.datasets.delete(dataset.source);\n    }\n\n\n    /**\n     * Adds a dataset to workflow\n     * @param source\n     * @param options\n     * @returns\n     */\n    add(source: string, opt: Options): Promise<Dataset | Error> {\n        return new Promise((resolve, reject) => {\n\n            if (this.datasets.has(source)) {\n                reject(new Error(`Dataset ${opt.destination} already exists in the workflow`).message);\n            }\n\n            if (opt.destination === \"\") {\n                console.warn(`Dataset ${source} does not have a destination`);\n            }\n\n            if (opt.destination && opt.destination.startsWith(\"s3://\")) {\n                const exists = this.#existsInS3(source);\n\n                if (exists) {\n                    const conn = this.#s3Connector({\n                        credentials: credentials(\"default\"),\n                        region: \"us-east-2\",\n                    });\n                    const dataset = new Dataset({source, options: opt}, conn);\n\n                    this.datasets.set(source, dataset);\n                    resolve(dataset);\n                }\n                // push new dataset to the workflow\n                reject(new Error(`Dataset ${source} does not exist in S3`));\n            }\n\n            if (\n                source.startsWith(\"/\") ||\n                source.startsWith(\"../\") ||\n                source.startsWith(\"./\")\n            ) {\n                if (!source.endsWith(\".csv\")) {\n                    reject(new Error(`${source} is not a CSV file`));\n                }\n\n                const dataset = new Dataset({source, options: opt}, this.#fsConnector(source));\n                this.datasets.set(source, dataset);\n                resolve(dataset);\n            }\n            reject(new Error(`Invalid source ${source} type`));\n        });\n    }\n\n\n    /**\n     * Checks if a file exists in a S3 bucket\n     * @param source\n     * @param options\n     * @returns\n     */\n    #existsInS3(source: string): boolean {\n        const {data, err} = this.#parseS3URI(source, {\n            file: true,\n        });\n\n        if (err || !data.file) {\n            console.error(`Invalid S3 URI: ${source}, URI must point to a file`);\n            return false;\n        }\n\n\n        const conn = this.#s3Connector({\n            credentials: credentials(\"default\"),\n            region: \"us-east-2\",\n        });\n\n        const getObjectCommand = new GetObjectCommand({\n            Bucket: data.bucket,\n            Key: data.file,\n        });\n\n        conn.send(getObjectCommand).then((res) => {\n                if (res.$metadata.httpStatusCode === 200 && res.ContentType === \"text/csv\") {\n                    return true\n                }\n                return false\n            }\n        ).catch((err) => {\n            console.error(err);\n            return false;\n        });\n        return false\n    }\n\n    /**\n     * Connects to given path directory in the filesystem\n     * @param path\n     * @returns {fs.Dirent[]}\n     */\n    #fsConnector(path: string): fs.ReadStream {\n        return fs.createReadStream(path);\n    }\n\n    /**\n     * Creates a new S3 client\n     * @param opt - S3 client config\n     * @returns S3Client\n     */\n    #s3Connector(opt: S3ClientConfig): S3Client {\n        if (!opt.region) {\n            opt.region = 'us-east-2';\n        }\n        return new S3Client(opt);\n    }\n\n    // Early on we check the csv file for some attributes to determine the shape of the data\n    #detectShape(d: Dataset): Shape {\n        const shape: Shape = {\n            type: '',\n            columns: [''],\n            header: false,\n            encoding: 'utf-8',\n            bom: false,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: ',',\n            errors: {},\n            warnings: {},\n            preview: [['']],\n        };\n\n        if (!fs.existsSync(d.source)) {\n            throw new Error(`${d.source} does not exist, provide a valid path to a CSV file`)\n        }\n\n        if (os.platform() === \"win32\") {\n            console.error(`handle windows later`)\n            return shape;\n        }\n\n        const mime = spawn(\"file\", [d.source, \"--mime-type\"])\n\n        mime.stdout.on(\"data\", (data) => {\n            const type = data.toString().split(\":\")[1].trim();\n\n            if (type === \"text/csv\" || type === \"text/plain\") {\n                shape.type = type;\n            } else {\n                shape.errors[\"incorrectType\"] = `${d.source} is not a CSV file`;\n            }\n        });\n\n        mime.on(\"close\", (code) => {\n            if (code !== 0 || shape.type === \"\") {\n                console.warn(\"unable to use file() cmd\");\n            }\n        });\n\n        const readLine = createInterface({\n            input: fs.createReadStream(d.source),\n            crlfDelay: Infinity,\n        });\n\n        let count = 0;\n        const max = 20;\n\n        // to store the column header if it exists for further checks\n        const first = {\n            row: [''],\n            del: \"\",\n        };\n\n        // hold the previous line while rl proceeds to next line using \\r\\n as a delimiter\n        let previous = \"\";\n\n        // create an array of delimiter from supported delimiter\n        const delimiters = [\",\", \";\", \"\\t\", \"|\", \":\", \" \", \"|\"];\n\n        readLine.on(\"line\", (current) => {\n\n            if (count === 0) {\n                delimiters.forEach((d) => {\n                    if (current.split(d).length > 1) {\n                        first.row = current.split(d)\n                        first.del = d;\n                    }\n                });\n\n                if (first.del === \"\" || first.row.length <= 1) {\n                    shape.errors[\"unrecognizedDelimiter\"] = `${d.source} does not have a recognized delimiter`;\n                    shape.header = false;\n                }\n\n                const isDigit = /\\d+/;\n\n                // betting on numbers should not appear as header values\n                const hasDigitInHeader = first.row.some((el) => isDigit.test(el));\n\n                if (hasDigitInHeader) {\n                    shape.header = false;\n                    shape.warnings[\"noHeader\"] = `no header found`;\n                    count++;\n                    return;\n                }\n\n                shape.header = true;\n                shape.delimiter = first.del;\n                shape.columns = first.row;\n            }\n\n            if (count > 0 && count < max) {\n                // there is a chance the record spans next line\n                const inlineQuotes = current.split(`\"`).length - 1;\n\n                if (previous) {\n                    if (inlineQuotes % 2 !== 0) {\n                        // TODO: make sure previous + current\n                        // console.log(previous + l);\n                        shape.spanMultipleLines = true;\n                    }\n                }\n                // if odd number of quotes and consider escaped quotes such as: \"aaa\",\"b\"\"bb\",\"ccc\"\n                if (\n                    inlineQuotes % 2 !== 0 &&\n                    current.split(`\"\"`).length - 1 !== 1\n                ) {\n                    previous = current;\n                }\n\n                const width = current.split(first.del).length;\n\n                if (width !== first.row.length) {\n                    shape.errors['rowWidthMismatch'] = `row width mismatch`;\n                    return;\n                }\n                shape.preview.push(current.split(first.del));\n            }\n            count++;\n        });\n        return shape;\n    }\n\n    //\n    // checkFileSize(d: Dataset): Promise<Dataset> {\n    //     const max = 1024 * 1024 * 20;\n    //     return new Promise((resolve, reject) => {\n    //         const size = fs.statSync(d.source).size;\n    //         if (size > max) {\n    //             d.errors[\"fileSize\"] = `${d.source} is too large`;\n    //             reject(d);\n    //         } else {\n    //             resolve(d);\n    //         }\n    //     });\n    // }\n\n    /**\n     * Initiates a multipart upload and returns an upload ID\n     * @returns {string} uploadID\n     * @private\n     */\n    #uploadToS3(d: Dataset) {\n        // grab the connector of the dataset\n        const c = d.connector;\n\n\n    }\n\n    /**\n     * Initiates a multipart upload and returns an upload ID\n     * @returns {string} uploadID\n     * @private\n     */\n    #initMultipartUpload(\n        d: Dataset,\n        bucket: string,\n        key: string\n    ): Promise<string> {\n        return new Promise((resolve, reject) => {\n            try {\n                const conn = this.#s3Connector({\n                    credentials: credentials(\"default\"),\n                    region: \"us-east-2\",\n                });\n\n                if (!(conn instanceof S3Client))\n                    throw new Error(`Invalid operation for ${d.source}`);\n\n                const command = new CreateMultipartUploadCommand({\n                    Bucket: bucket,\n                    ContentEncoding: \"utf8\",\n                    ContentType: \"text/csv\",\n                    Key: key,\n                });\n\n                conn\n                    .send(command)\n                    .then((data) => {\n                        if (data.UploadId) {\n                            resolve(data.UploadId);\n                        }\n                        reject(new Error(\"noop\"))\n                    })\n                    .catch((error) => {\n                        reject(error);\n                    })\n                    .finally(() => {\n                        console.log(\"init multipart upload\");\n                    });\n            } catch (err) {\n                reject(err);\n            }\n        });\n    }\n\n    /**\n     * Parse (s3://) style uri\n     */\n    #parseS3URI(\n        uri: string,\n        options: {\n            file: boolean;\n        }\n    ): {\n        data: {\n            bucket: string;\n            key: string;\n            file: string;\n        };\n        err: string;\n    } {\n        const opt = {\n            file: options && options.file ? options.file : false,\n        };\n\n        if (!uri.startsWith(\"s3://\") || uri.split(\":/\")[0] !== \"s3\") {\n            throw new Error(\"Invalid S3 URI\");\n        }\n\n        let err = \"\";\n\n        const result = {\n            bucket: \"\",\n            key: \"\",\n            file: \"\",\n        };\n\n        const src = uri.split(\":/\")[1];\n        const [bucket, ...keys] = src.split(\"/\").splice(1);\n\n        result.bucket = bucket;\n        result.key = keys.join(\"/\");\n\n        keys.forEach((k, i) => {\n            if (i === keys.length - 1) {\n                const last = k.split(\".\").length;\n                if (opt.file && last === 1) err = `uri should be a given, given: ${uri}`;\n\n                if (!opt.file && last === 1) return;\n\n                if (!opt.file && last > 1) {\n                    err = `Invalid S3 uri, ${uri} should not end with a file name`;\n                    return;\n                }\n\n                if (!opt.file && k.split(\".\")[1] !== \"\" && last > 1)\n                    err = `${uri} should not be a file endpoint: ${k}`;\n\n                if (last > 1 && k.split(\".\")[1] !== \"\") result.file = k;\n            }\n        });\n        return {\n            data: result,\n            err: err,\n        };\n    }\n}\n\n/**\n * Returns a new workflow\n * @param {string} name - Name of the workflow\n * @returns {Workflow} - New workflow\n */\n\nexport function createWorkflow(name: string): Workflow {\n    return new Workflow(name);\n}\n\n"],
  "mappings": "qcAAA,qBACA,qBACA,2CACA,sCACA,wDACA,wBAGA,sGAgDA,GAAM,GAAc,AAAC,GAAoB,EAAQ,CAC7C,QAAS,EACT,gBAAiB,AAAO,GAAc,0BAClC,MAAO,OAUf,OAAc,CAMV,YAAY,EAAY,EAA0B,CAC9C,KAAK,OAAS,EAAK,OACnB,KAAK,QAAU,EAAK,QACpB,KAAK,UAAY,GAAI,MACrB,KAAK,UAAY,IA/EzB,gCAqFA,OAAe,CAOX,YAAY,EAAc,CAQpB,UA0HN,UAuCA,UASA,UAQA,UAiJA,UAYA,UA6CA,UAnYI,KAAK,KAAO,EACZ,KAAK,SAAW,GAAI,KACpB,KAAK,UAAY,GAAI,MACrB,KAAK,IAAM,QACX,KAAK,MAAQ,AAAM,UAAQ,OAAK,KAAS,GAqD7C,MAAkB,CACd,MAAO,OAAM,KAAK,KAAK,SAAS,UAQpC,OAAO,EAAkB,CACrB,KAAK,SAAS,OAAO,EAAQ,QAUjC,IAAI,EAAgB,EAAwC,CACxD,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CAUpC,GARI,KAAK,SAAS,IAAI,IAClB,EAAO,GAAI,OAAM,WAAW,EAAI,8CAA8C,SAG9E,EAAI,cAAgB,IACpB,QAAQ,KAAK,WAAW,iCAGxB,EAAI,aAAe,EAAI,YAAY,WAAW,SAAU,CAGxD,GAFe,OAAK,KAAL,UAAiB,GAEpB,CACR,GAAM,GAAO,OAAK,KAAL,UAAkB,CAC3B,YAAa,EAAY,WACzB,OAAQ,cAEN,EAAU,GAAI,GAAQ,CAAC,SAAQ,QAAS,GAAM,GAEpD,KAAK,SAAS,IAAI,EAAQ,GAC1B,EAAQ,GAGZ,EAAO,GAAI,OAAM,WAAW,2BAGhC,GACI,EAAO,WAAW,MAClB,EAAO,WAAW,QAClB,EAAO,WAAW,MACpB,CACE,AAAK,EAAO,SAAS,SACjB,EAAO,GAAI,OAAM,GAAG,wBAGxB,GAAM,GAAU,GAAI,GAAQ,CAAC,SAAQ,QAAS,GAAM,OAAK,KAAL,UAAkB,IACtE,KAAK,SAAS,IAAI,EAAQ,GAC1B,EAAQ,GAEZ,EAAO,GAAI,OAAM,kBAAkB,eA/GrC,gBAAO,SAAC,EAA2C,mCAA3C,CAAC,SAAQ,WAAkC,CACrD,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CASpC,GARI,KAAK,SAAS,IAAI,IAClB,EAAO,GAAI,OAAM,WAAW,EAAQ,8CAA8C,SAGlF,EAAQ,cAAgB,IACxB,QAAQ,KAAK,WAAW,iCAGxB,EAAQ,aAAe,EAAQ,YAAY,WAAW,SAAU,CAGhE,GAFe,OAAK,KAAL,UAAiB,GAEpB,CACR,GAAM,GAAO,OAAK,KAAL,UAAkB,CAC3B,YAAa,EAAY,WACzB,OAAQ,cAEN,EAAU,GAAI,GAAQ,CAAC,SAAQ,WAAU,GAC/C,KAAK,SAAS,IAAI,EAAQ,GAC1B,EAAQ,GAGZ,EAAO,GAAI,OAAM,WAAW,2BAGhC,GACI,EAAO,WAAW,MAClB,EAAO,WAAW,QAClB,EAAO,WAAW,MACpB,CACE,AAAK,EAAO,SAAS,SACjB,EAAO,GAAI,OAAM,GAAG,wBAGxB,GAAM,GAAU,GAAI,GAAQ,CAAC,SAAQ,WAAU,OAAK,KAAL,UAAkB,IACjE,KAAK,SAAS,IAAI,EAAQ,GAC1B,EAAQ,GAEZ,EAAO,GAAI,OAAM,kBAAkB,gBAmF3C,gBAAW,SAAC,EAAyB,CACjC,GAAM,CAAC,OAAM,OAAO,OAAK,KAAL,UAAiB,EAAQ,CACzC,KAAM,KAGV,GAAI,GAAO,CAAC,EAAK,KACb,eAAQ,MAAM,mBAAmB,+BAC1B,GAIX,GAAM,GAAO,OAAK,KAAL,UAAkB,CAC3B,YAAa,EAAY,WACzB,OAAQ,cAGN,EAAmB,GAAI,GAAiB,CAC1C,OAAQ,EAAK,OACb,IAAK,EAAK,OAGd,SAAK,KAAK,GAAkB,KAAK,AAAC,GACtB,EAAI,UAAU,iBAAmB,KAAO,EAAI,cAAgB,YAKtE,MAAM,AAAC,GACL,SAAQ,MAAM,GACP,KAEJ,IAQX,gBAAY,SAAC,EAA6B,CACtC,MAAO,AAAG,oBAAiB,IAQ/B,gBAAY,SAAC,EAA+B,CACxC,MAAK,GAAI,QACL,GAAI,OAAS,aAEV,GAAI,GAAS,IAIxB,gBAAY,SAAC,EAAmB,CAC5B,GAAM,GAAe,CACjB,KAAM,GACN,QAAS,CAAC,IACV,OAAQ,GACR,SAAU,QACV,IAAK,GACL,kBAAmB,GACnB,OAAQ,GACR,UAAW,IACX,OAAQ,GACR,SAAU,GACV,QAAS,CAAC,CAAC,MAGf,GAAI,CAAC,AAAG,aAAW,EAAE,QACjB,KAAM,IAAI,OAAM,GAAG,EAAE,6DAGzB,GAAI,AAAG,eAAe,QAClB,eAAQ,MAAM,wBACP,EAGX,GAAM,GAAO,EAAM,OAAQ,CAAC,EAAE,OAAQ,gBAEtC,EAAK,OAAO,GAAG,OAAQ,AAAC,GAAS,CAC7B,GAAM,GAAO,EAAK,WAAW,MAAM,KAAK,GAAG,OAE3C,AAAI,IAAS,YAAc,IAAS,aAChC,EAAM,KAAO,EAEb,EAAM,OAAO,cAAmB,GAAG,EAAE,6BAI7C,EAAK,GAAG,QAAS,AAAC,GAAS,CACvB,AAAI,KAAS,GAAK,EAAM,OAAS,KAC7B,QAAQ,KAAK,8BAIrB,GAAM,GAAW,EAAgB,CAC7B,MAAO,AAAG,mBAAiB,EAAE,QAC7B,UAAW,MAGX,EAAQ,EACN,EAAM,GAGN,EAAQ,CACV,IAAK,CAAC,IACN,IAAK,IAIL,EAAW,GAGT,EAAa,CAAC,IAAK,IAAK,IAAM,IAAK,IAAK,IAAK,KAEnD,SAAS,GAAG,OAAQ,AAAC,GAAY,CAE7B,GAAI,IAAU,EAAG,CACb,EAAW,QAAQ,AAAC,GAAM,CACtB,AAAI,EAAQ,MAAM,GAAG,OAAS,GAC1B,GAAM,IAAM,EAAQ,MAAM,GAC1B,EAAM,IAAM,KAIhB,GAAM,MAAQ,IAAM,EAAM,IAAI,QAAU,IACxC,GAAM,OAAO,sBAA2B,GAAG,EAAE,8CAC7C,EAAM,OAAS,IAGnB,GAAM,GAAU,MAKhB,GAFyB,EAAM,IAAI,KAAK,AAAC,GAAO,EAAQ,KAAK,IAEvC,CAClB,EAAM,OAAS,GACf,EAAM,SAAS,SAAc,kBAC7B,IACA,OAGJ,EAAM,OAAS,GACf,EAAM,UAAY,EAAM,IACxB,EAAM,QAAU,EAAM,IAG1B,GAAI,EAAQ,GAAK,EAAQ,EAAK,CAE1B,GAAM,GAAe,EAAQ,MAAM,KAAK,OAAS,EAmBjD,GAjBI,GACI,EAAe,IAAM,GAGrB,GAAM,kBAAoB,IAK9B,EAAe,IAAM,GACrB,EAAQ,MAAM,MAAM,OAAS,IAAM,GAEnC,GAAW,GAKX,AAFU,EAAQ,MAAM,EAAM,KAAK,SAEzB,EAAM,IAAI,OAAQ,CAC5B,EAAM,OAAO,iBAAsB,qBACnC,OAEJ,EAAM,QAAQ,KAAK,EAAQ,MAAM,EAAM,MAE3C,MAEG,GAsBX,gBAAW,SAAC,EAAY,CAEpB,GAAM,GAAI,EAAE,WAUhB,gBAAoB,SAChB,EACA,EACA,EACe,CACf,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CACpC,GAAI,CACA,GAAM,GAAO,OAAK,KAAL,UAAkB,CAC3B,YAAa,EAAY,WACzB,OAAQ,cAGZ,GAAI,CAAE,aAAgB,IAClB,KAAM,IAAI,OAAM,yBAAyB,EAAE,UAE/C,GAAM,GAAU,GAAI,GAA6B,CAC7C,OAAQ,EACR,gBAAiB,OACjB,YAAa,WACb,IAAK,IAGT,EACK,KAAK,GACL,KAAK,AAAC,GAAS,CACZ,AAAI,EAAK,UACL,EAAQ,EAAK,UAEjB,EAAO,GAAI,OAAM,WAEpB,MAAM,AAAC,GAAU,CACd,EAAO,KAEV,QAAQ,IAAM,CACX,QAAQ,IAAI,iCAEf,EAAP,CACE,EAAO,OAQnB,gBAAW,SACP,EACA,EAUF,CACE,GAAM,GAAM,CACR,KAAM,GAAW,EAAQ,KAAO,EAAQ,KAAO,IAGnD,GAAI,CAAC,EAAI,WAAW,UAAY,EAAI,MAAM,MAAM,KAAO,KACnD,KAAM,IAAI,OAAM,kBAGpB,GAAI,GAAM,GAEJ,EAAS,CACX,OAAQ,GACR,IAAK,GACL,KAAM,IAGJ,EAAM,EAAI,MAAM,MAAM,GACtB,CAAC,KAAW,GAAQ,EAAI,MAAM,KAAK,OAAO,GAEhD,SAAO,OAAS,EAChB,EAAO,IAAM,EAAK,KAAK,KAEvB,EAAK,QAAQ,CAAC,EAAG,IAAM,CACnB,GAAI,IAAM,EAAK,OAAS,EAAG,CACvB,GAAM,GAAO,EAAE,MAAM,KAAK,OAG1B,GAFI,EAAI,MAAQ,IAAS,GAAG,GAAM,iCAAiC,KAE/D,CAAC,EAAI,MAAQ,IAAS,EAAG,OAE7B,GAAI,CAAC,EAAI,MAAQ,EAAO,EAAG,CACvB,EAAM,mBAAmB,oCACzB,OAGJ,AAAI,CAAC,EAAI,MAAQ,EAAE,MAAM,KAAK,KAAO,IAAM,EAAO,GAC9C,GAAM,GAAG,oCAAsC,KAE/C,EAAO,GAAK,EAAE,MAAM,KAAK,KAAO,IAAI,GAAO,KAAO,MAGvD,CACH,KAAM,EACN,IAAK,IAWV,WAAwB,EAAwB,CACnD,MAAO,IAAI,GAAS",
  "names": []
}
