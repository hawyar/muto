{
  "version": 3,
  "sources": ["../lib/engine.ts"],
  "sourcesContent": ["import * as fs from \"fs\";\nimport * as os from \"os\";\nimport {createInterface} from \"readline\"\nimport {spawn} from \"child_process\";\nimport {fromIni} from \"@aws-sdk/credential-providers\"\nimport * as fastq from \"fastq\";\n// import type {queueAsPromised} from \"fastq\";\nimport path from \"path\";\nimport {readFileSync, writeFileSync} from 'atomically';\nimport {\n    S3Client,\n    GetObjectCommand,\n    S3ClientConfig,\n    CreateMultipartUploadCommand\n} from \"@aws-sdk/client-s3\";\n\n// type ShapeErrType = 'unrecognizedDelimiter' | 'noHeader' | 'invalidFileType' | 'rowWidthMismatch'\n\ntype supportedDelimiters = \",\" | \";\" | \"|\" | \":\" | \"\\t\" | \" \" | \"^\" | \"~\" | \"*\" | \"!\" | \"-\" | \"_\"\ntype env = 'local' | 'remote'\ntype connectorType = S3Client | fs.ReadStream\n\n\n// TODO: better error message for errors happening in transform\ntype datasetStateType = 'init' | 'transforming' | 'uploading' | 'cancelled' | 'uploaded' | 'ready'\n\n// Shape of a dataset object\ninterface Shape {\n    type: string,\n    columns: Array<string>,\n    header: boolean,\n    encoding: string,\n    bom: boolean,\n    spanMultipleLines: boolean,\n    quotes: boolean,\n    delimiter: string,\n    errors: { [key: string]: string }\n    warnings: { [key: string]: string },\n    preview: string[][],\n}\n\n\n// Dataset represents a file from a supported a data source\ninterface Dataset {\n    source: string\n    options: Options;\n    shape?: Shape\n    data?: string[][];\n    createdAt: Date;\n    state: datasetStateType\n    connector: connectorType;\n}\n\n// Options for a dataset\ninterface Options {\n    destination: string;\n    columns: Array<string>,\n    header: boolean,\n    transform: (row: object) => object\n    bom: boolean,\n    delimiter: supportedDelimiters\n}\n\ntype Args = {\n    source: string,\n    options: Options\n}\n\n\nconst credentials = (profile: string) => fromIni({\n    profile: profile,\n    mfaCodeProvider: async (mfaSerial) => {\n        return mfaSerial\n    },\n});\n\nclass Dataset {\n    source: string\n    options: Options\n    createdAt: Date\n    state: datasetStateType\n\n    constructor({source, options}: Args) {\n        this.source = source;\n        this.options = options;\n        this.createdAt = new Date();\n        this.state = 'init'\n    }\n}\n\ninterface Cache {\n    path: string\n    init: Date\n\n    get(key: string): Dataset | undefined\n\n    set(key: string, value: Dataset): void\n\n    has(key: string): boolean\n\n    delete(key: string): void\n\n    clear(): void\n\n    size(): number\n\n    keys(): string[]\n}\n\nconst queue = (function () {\n    let q: fastq.queueAsPromised<Args, void>;\n\n    async function worker(arg: Args) {\n        console.log(arg)\n    }\n\n    return {\n        getInstance: () => {\n            if (!q) {\n                q = fastq.promise(worker, 10)\n            }\n            return q;\n        }\n    }\n})();\n\nconst cache = (function (): { getInstance: () => Cache } {\n    let cache: Cache;\n\n    function init() {\n        const cachePath = path.join(process.cwd(), '.muto-cache')\n\n        if (!fs.existsSync(cachePath)) {\n            writeFileSync(cachePath, JSON.stringify({}))\n        }\n\n        return {\n            init: new Date(),\n            path: cachePath,\n            get: (key: string): Dataset | undefined => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key].source !== key) {\n                    return undefined\n                }\n                return cache[key]\n            },\n            set: (key: string, value: Dataset): string => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                cache[key] = value\n                writeFileSync(cachePath, JSON.stringify(cache))\n                return key\n            },\n            has: (key: string): boolean => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return cache[key].source === key\n            },\n            delete: (key: string) => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                delete cache[key]\n\n                writeFileSync(cachePath, JSON.stringify(cache))\n            },\n            clear: () => {\n                writeFileSync(cachePath, JSON.stringify({}))\n            },\n            size: () => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return Object.keys(cache).length\n            },\n            keys: () => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return Object.keys(cache)\n            }\n        }\n    }\n\n    return {\n        getInstance: () => {\n            if (!cache) {\n                cache = init()\n            }\n            return cache\n        }\n    }\n})()\n\nfunction s3Connector(config: S3ClientConfig) {\n    const client = new S3Client(config);\n    return Object.freeze({\n        getObject: (command: GetObjectCommand) => client.send(command),\n        createMultipartUpload: (command: CreateMultipartUploadCommand) => client.send(command),\n    });\n}\n\nfunction fsConnector(filePath: string) {\n    return Object.freeze({\n        readStream(): Promise<fs.ReadStream> {\n            return new Promise((resolve, reject) => {\n                const stream = fs.createReadStream(filePath);\n                stream.on('error', (err) => {\n                    reject(err);\n                });\n                stream.on('open', () => {\n                    resolve(stream);\n                });\n            });\n        },\n        writeStream(): Promise<fs.WriteStream> {\n            return new Promise((resolve, reject) => {\n                const stream = fs.createWriteStream(filePath);\n                stream.on('error', (err) => {\n                    reject(err);\n                });\n                stream.on('open', () => {\n                    resolve(stream);\n                });\n            });\n        },\n    })\n}\n\n\nclass Workflow {\n    name: string;\n    datasets: Map<string, Dataset>;\n    readonly createdAt: Date;\n    env: env;\n    // queue: queueAsPromised<Args>\n    lcache: Cache\n\n    constructor(name: string) {\n        this.name = name;\n        this.datasets = new Map();\n        this.createdAt = new Date();\n        this.env = 'local';\n        // this.queue = queue.getInstance();\n        this.lcache = cache.getInstance()\n    }\n\n    // async #worker({source, options}: Args): Promise<Dataset> {}\n\n    list(): Dataset[] {\n        return Array.from(this.datasets.values());\n    }\n\n    remove(dataset: Dataset) {\n        this.datasets.delete(dataset.source);\n    }\n\n    add(source: string, options: Options): Promise<string> {\n        return new Promise((resolve, reject) => {\n            if (options.destination === \"\") {\n                console.warn(`dataset-source-not-provided: Dataset ${source} does not have a destination`);\n            }\n\n            if (this.lcache.has(source)) {\n                console.log(\"cache hit\")\n                const dataset = this.lcache.get(source)\n                resolve(source)\n            }\n\n            const type = this.#determineSource(source);\n\n            if (type === 'local') {\n                const fsConn = fsConnector(source)\n                const dataset = new Dataset({source, options});\n\n                this.lcache.set(source, dataset);\n                resolve(source);\n            }\n\n            // if (type === \"remote\") {\n            //     const exists = this.#existsInS3(source);\n            //\n            //     if (exists) {\n            //\n            //         const conn = s3Connector({\n            //             credentials: credentials(\"default\"),\n            //             region: \"us-east-2\",\n            //         });\n            //         const dataset = new Dataset({source, options}, conn);\n            //\n            //         this.datasets.set(source, dataset);\n            //         resolve(source);\n            //     }\n            // }\n        });\n    }\n\n    /**\n     * Checks if file exists in a S3 bucket\n     * @param source\n     * @param options\n     * @returns\n     */\n    #existsInS3(source: string): boolean {\n        const {data, err} = this.#parseS3URI(source, {\n            file: true,\n        });\n\n        if (err || !data.file) {\n            console.error(`Invalid S3 URI: ${source}, URI must point to a file`);\n            return false;\n        }\n\n        const conn = this.#s3Connector({\n            credentials: credentials(\"default\"),\n            region: \"us-east-2\",\n        });\n\n        const getObjectCommand = new GetObjectCommand({\n            Bucket: data.bucket,\n            Key: data.file,\n        });\n\n        conn.send(getObjectCommand).then((res) => {\n                if (res.$metadata.httpStatusCode === 200 && res.ContentType === \"text/csv\") {\n                    return true\n                }\n                return false\n            }\n        ).catch((err) => {\n            console.error(err);\n            return false;\n        });\n        return false\n    }\n\n    #determineSource(source: string): string {\n        if (\n            source.startsWith(\"/\") ||\n            source.startsWith(\"../\") ||\n            source.startsWith(\"./\")\n        ) {\n            return \"local\";\n        }\n\n        if (source.startsWith(\"s3://\")) {\n            return \"s3\";\n        }\n\n        throw new Error(`invalid-source-type: ${source}`);\n    }\n\n    /**\n     * Returns a readable stream for a local file\n     * @param path\n     * @returns {fs.Dirent[]}\n     */\n    #fsConnector(path: string): fs.ReadStream {\n        return fs.createReadStream(path);\n    }\n\n    #s3Connector(opt: S3ClientConfig): S3Client {\n        if (!opt.region) {\n            opt.region = 'us-east-2';\n        }\n        return new S3Client(opt);\n    }\n\n    #detectShape(path: string): Shape {\n        const shape: Shape = {\n            type: '',\n            columns: [''],\n            header: false,\n            encoding: 'utf-8',\n            bom: false,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: ',',\n            errors: {},\n            warnings: {},\n            preview: [['']],\n        };\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`${path} does not exist, provide a valid path to a CSV file`)\n        }\n\n        if (os.platform() === \"win32\") {\n            console.error(`handle windows later`)\n            return shape;\n        }\n\n        const mime = spawn(\"file\", [path, \"--mime-type\"])\n\n        mime.stdout.on(\"data\", (data) => {\n            const type = data.toString().split(\":\")[1].trim();\n\n            if (type === \"text/csv\" || type === \"text/plain\") {\n                shape.type = type;\n            } else {\n                shape.errors[\"incorrectType\"] = `${path} is not a CSV file`;\n            }\n        });\n\n        mime.on(\"close\", (code) => {\n            if (code !== 0 || shape.type === \"\") {\n                console.warn(\"unable to use file() cmd\");\n            }\n        });\n\n        const readLine = createInterface({\n            input: fs.createReadStream(path),\n            crlfDelay: Infinity,\n        });\n\n        let count = 0;\n        const max = 20;\n\n        // to store the column header if it exists for further checks\n        const first = {\n            row: [''],\n            del: \"\",\n        };\n\n        // hold the previous line while rl proceeds to next line using \\r\\n as a delimiter\n        let previous = \"\";\n\n        // create an array of delimiter from supported delimiter\n        const delimiters = [\",\", \";\", \"\\t\", \"|\", \":\", \" \", \"|\"];\n\n        readLine.on(\"line\", (current) => {\n            if (count === 0) {\n                delimiters.forEach((d) => {\n                    if (current.split(d).length > 1) {\n                        first.row = current.split(d)\n                        first.del = d;\n                    }\n                });\n\n                if (first.del === \"\" || first.row.length <= 1) {\n                    shape.errors[\"unrecognizedDelimiter\"] = `${path} does not have a recognized delimiter`;\n                    shape.header = false;\n                }\n\n                const isDigit = /\\d+/;\n\n                // betting on numbers should not appear as header values\n                const hasDigitInHeader = first.row.some((el) => isDigit.test(el));\n\n                if (hasDigitInHeader) {\n                    shape.header = false;\n                    shape.warnings[\"noHeader\"] = `no header found`;\n                    count++;\n                    return;\n                }\n\n                shape.header = true;\n                shape.delimiter = first.del;\n                shape.columns = first.row;\n            }\n\n            if (count > 0 && count < max) {\n                // there is a chance the record spans next line\n                const inlineQuotes = current.split(`\"`).length - 1;\n\n                if (previous) {\n                    if (inlineQuotes % 2 !== 0) {\n                        // TODO: make sure previous + current\n                        // console.log(previous + l);\n                        shape.spanMultipleLines = true;\n                    }\n                }\n                // if odd number of quotes and consider escaped quotes such as: \"aaa\",\"b\"\"bb\",\"ccc\"\n                if (\n                    inlineQuotes % 2 !== 0 &&\n                    current.split(`\"\"`).length - 1 !== 1\n                ) {\n                    previous = current;\n                }\n\n                const width = current.split(first.del).length;\n\n                if (width !== first.row.length) {\n                    shape.errors['rowWidthMismatch'] = `row width mismatch`;\n                    return;\n                }\n                shape.preview.push(current.split(first.del));\n            }\n            count++;\n        });\n        return shape;\n    }\n\n    #checkFileSize(path: string): number {\n        const max = 1024 * 1024 * 50\n        if (!fs.existsSync(path)) {\n            throw new Error(`path-doesnt-exists: ${path} ,provide a valid path to a CSV file`)\n        }\n        const file = fs.statSync(path)\n\n        if (file.size > max) {\n            throw new Error(`file-size-exceeds-limit: ${path} is too large, please limit to 50MB`)\n        }\n        return fs.statSync(path).size\n    }\n\n    /**\n     * Initiates a multipart upload and returns an upload ID\n     * @returns {string} uploadID\n     * @private\n     */\n    #initMultipartUpload(\n        d: Dataset,\n        bucket: string,\n        key: string\n    ): Promise<string> {\n        return new Promise((resolve, reject) => {\n            try {\n                const conn = this.#s3Connector({\n                    credentials: credentials(\"default\"),\n                    region: \"us-east-2\",\n                });\n\n                if (!(conn instanceof S3Client))\n                    // TODO: dont throw here, throw in the caller\n                    throw new Error(`invalid-operation: Invalid operation for ${d.source}`);\n\n                const command = new CreateMultipartUploadCommand({\n                    Bucket: bucket,\n                    ContentEncoding: \"utf8\",\n                    ContentType: \"text/csv\",\n                    Key: key,\n                });\n\n                conn\n                    .send(command)\n                    .then((data) => {\n                        if (data.UploadId) {\n                            resolve(data.UploadId);\n                        }\n                        reject(new Error(\"noop\"))\n                    })\n                    .catch((error) => {\n                        reject(error);\n                    })\n                    .finally(() => {\n                        console.log(\"init multipart upload\");\n                    });\n            } catch (err) {\n                reject(err);\n            }\n        });\n    }\n\n    #parseS3URI(\n        uri: string,\n        options: {\n            file: boolean;\n        }\n    ): {\n        data: {\n            bucket: string;\n            key: string;\n            file: string;\n        };\n        err: string;\n    } {\n        const opt = {\n            file: options && options.file ? options.file : false,\n        };\n\n        if (!uri.startsWith(\"s3://\") || uri.split(\":/\")[0] !== \"s3\") {\n            throw new Error(`invalid-s3-uri: ${uri}`);\n        }\n\n        let err = \"\";\n\n        const result = {\n            bucket: \"\",\n            key: \"\",\n            file: \"\",\n        };\n\n        const src = uri.split(\":/\")[1];\n        const [bucket, ...keys] = src.split(\"/\").splice(1);\n\n        result.bucket = bucket;\n        result.key = keys.join(\"/\");\n\n        keys.forEach((k, i) => {\n            if (i === keys.length - 1) {\n                const last = k.split(\".\").length;\n                if (opt.file && last === 1) err = `uri should be a given, given: ${uri}`;\n\n                if (!opt.file && last === 1) return;\n\n                if (!opt.file && last > 1) {\n                    err = `Invalid S3 uri, ${uri} should not end with a file name`;\n                    return;\n                }\n\n                if (!opt.file && k.split(\".\")[1] !== \"\" && last > 1)\n                    err = `${uri} should not be a file endpoint: ${k}`;\n\n                if (last > 1 && k.split(\".\")[1] !== \"\") result.file = k;\n            }\n        });\n        return {\n            data: result,\n            err: err,\n        };\n    }\n}\n\n/**\n * Returns a new workflow\n * @param {string} name - Name of the workflow\n * @returns {Workflow} - New workflow\n */\nexport function createWorkflow(name: string): Workflow {\n    return new Workflow(name);\n}"],
  "mappings": "qcAAA,qBACA,qBACA,2CACA,sCACA,wDACA,wBAEA,oBACA,6DACA,sGA4DA,GAAM,GAAc,AAAC,GAAoB,EAAQ,CAC7C,QAAS,EACT,gBAAiB,AAAO,GAAc,0BAClC,MAAO,OAIf,OAAc,CAMV,YAAY,CAAC,SAAQ,WAAgB,CACjC,KAAK,OAAS,EACd,KAAK,QAAU,EACf,KAAK,UAAY,GAAI,MACrB,KAAK,MAAQ,SAuBf,GAAS,UAAY,CACvB,GAAI,GAEJ,WAAsB,EAAW,gCAC7B,QAAQ,IAAI,KAGhB,MAAO,CACH,YAAa,IACJ,IACD,GAAI,AAAM,UAAQ,EAAQ,KAEvB,OAKb,EAAS,UAA0C,CACrD,GAAI,GAEJ,YAAgB,CACZ,GAAM,GAAY,EAAK,KAAK,QAAQ,MAAO,eAE3C,MAAK,AAAG,cAAW,IACf,EAAc,EAAW,KAAK,UAAU,KAGrC,CACH,KAAM,GAAI,MACV,KAAM,EACN,IAAK,AAAC,GAAqC,CACvC,GAAM,GAAO,EAAa,GACpB,EAAQ,KAAK,MAAM,EAAK,YAE9B,GAAI,EAAM,GAAK,SAAW,EAG1B,MAAO,GAAM,IAEjB,IAAK,CAAC,EAAa,IAA2B,CAC1C,GAAM,GAAO,EAAa,GACpB,EAAQ,KAAK,MAAM,EAAK,YAE9B,SAAM,GAAO,EACb,EAAc,EAAW,KAAK,UAAU,IACjC,GAEX,IAAK,AAAC,GAAyB,CAC3B,GAAM,GAAO,EAAa,GAE1B,MAAO,AADO,MAAK,MAAM,EAAK,YACjB,GAAK,SAAW,GAEjC,OAAQ,AAAC,GAAgB,CACrB,GAAM,GAAO,EAAa,GACpB,EAAQ,KAAK,MAAM,EAAK,YAE9B,MAAO,GAAM,GAEb,EAAc,EAAW,KAAK,UAAU,KAE5C,MAAO,IAAM,CACT,EAAc,EAAW,KAAK,UAAU,MAE5C,KAAM,IAAM,CACR,GAAM,GAAO,EAAa,GACpB,EAAQ,KAAK,MAAM,EAAK,YAC9B,MAAO,QAAO,KAAK,GAAO,QAE9B,KAAM,IAAM,CACR,GAAM,GAAO,EAAa,GACpB,EAAQ,KAAK,MAAM,EAAK,YAC9B,MAAO,QAAO,KAAK,KAK/B,MAAO,CACH,YAAa,IACJ,IACD,GAAQ,KAEL,OAanB,WAAqB,EAAkB,CACnC,MAAO,QAAO,OAAO,CACjB,YAAqC,CACjC,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CACpC,GAAM,GAAS,AAAG,mBAAiB,GACnC,EAAO,GAAG,QAAS,AAAC,GAAQ,CACxB,EAAO,KAEX,EAAO,GAAG,OAAQ,IAAM,CACpB,EAAQ,QAIpB,aAAuC,CACnC,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CACpC,GAAM,GAAS,AAAG,oBAAkB,GACpC,EAAO,GAAG,QAAS,AAAC,GAAQ,CACxB,EAAO,KAEX,EAAO,GAAG,OAAQ,IAAM,CACpB,EAAQ,UA/N5B,yCAuOA,OAAe,CAQX,YAAY,EAAc,CAiE1B,UAiCA,UAqBA,UAIA,UAOA,UA6HA,UAkBA,UA2CA,UA3TI,KAAK,KAAO,EACZ,KAAK,SAAW,GAAI,KACpB,KAAK,UAAY,GAAI,MACrB,KAAK,IAAM,QAEX,KAAK,OAAS,EAAM,cAKxB,MAAkB,CACd,MAAO,OAAM,KAAK,KAAK,SAAS,UAGpC,OAAO,EAAkB,CACrB,KAAK,SAAS,OAAO,EAAQ,QAGjC,IAAI,EAAgB,EAAmC,CACnD,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CAKpC,GAJI,EAAQ,cAAgB,IACxB,QAAQ,KAAK,wCAAwC,iCAGrD,KAAK,OAAO,IAAI,GAAS,CACzB,QAAQ,IAAI,aACZ,GAAM,GAAU,KAAK,OAAO,IAAI,GAChC,EAAQ,GAKZ,GAAI,AAFS,OAAK,KAAL,UAAsB,KAEtB,QAAS,CAClB,GAAM,GAAS,EAAY,GACrB,EAAU,GAAI,GAAQ,CAAC,SAAQ,YAErC,KAAK,OAAO,IAAI,EAAQ,GACxB,EAAQ,QA2BpB,iBAAW,SAAC,EAAyB,CACjC,GAAM,CAAC,OAAM,OAAO,OAAK,KAAL,UAAiB,EAAQ,CACzC,KAAM,KAGV,GAAI,GAAO,CAAC,EAAK,KACb,eAAQ,MAAM,mBAAmB,+BAC1B,GAGX,GAAM,GAAO,OAAK,KAAL,UAAkB,CAC3B,YAAa,EAAY,WACzB,OAAQ,cAGN,EAAmB,GAAI,GAAiB,CAC1C,OAAQ,EAAK,OACb,IAAK,EAAK,OAGd,SAAK,KAAK,GAAkB,KAAK,AAAC,GACtB,EAAI,UAAU,iBAAmB,KAAO,EAAI,cAAgB,YAKtE,MAAM,AAAC,GACL,SAAQ,MAAM,GACP,KAEJ,IAGX,gBAAgB,SAAC,EAAwB,CACrC,GACI,EAAO,WAAW,MAClB,EAAO,WAAW,QAClB,EAAO,WAAW,MAElB,MAAO,QAGX,GAAI,EAAO,WAAW,SAClB,MAAO,KAGX,KAAM,IAAI,OAAM,wBAAwB,MAQ5C,iBAAY,SAAC,EAA6B,CACtC,MAAO,AAAG,oBAAiB,IAG/B,gBAAY,SAAC,EAA+B,CACxC,MAAK,GAAI,QACL,GAAI,OAAS,aAEV,GAAI,GAAS,IAGxB,iBAAY,SAAC,EAAqB,CAC9B,GAAM,GAAe,CACjB,KAAM,GACN,QAAS,CAAC,IACV,OAAQ,GACR,SAAU,QACV,IAAK,GACL,kBAAmB,GACnB,OAAQ,GACR,UAAW,IACX,OAAQ,GACR,SAAU,GACV,QAAS,CAAC,CAAC,MAGf,GAAI,CAAC,AAAG,aAAW,GACf,KAAM,IAAI,OAAM,GAAG,wDAGvB,GAAI,AAAG,eAAe,QAClB,eAAQ,MAAM,wBACP,EAGX,GAAM,GAAO,EAAM,OAAQ,CAAC,EAAM,gBAElC,EAAK,OAAO,GAAG,OAAQ,AAAC,GAAS,CAC7B,GAAM,GAAO,EAAK,WAAW,MAAM,KAAK,GAAG,OAE3C,AAAI,IAAS,YAAc,IAAS,aAChC,EAAM,KAAO,EAEb,EAAM,OAAO,cAAmB,GAAG,wBAI3C,EAAK,GAAG,QAAS,AAAC,GAAS,CACvB,AAAI,KAAS,GAAK,EAAM,OAAS,KAC7B,QAAQ,KAAK,8BAIrB,GAAM,GAAW,EAAgB,CAC7B,MAAO,AAAG,mBAAiB,GAC3B,UAAW,MAGX,EAAQ,EACN,EAAM,GAGN,EAAQ,CACV,IAAK,CAAC,IACN,IAAK,IAIL,EAAW,GAGT,EAAa,CAAC,IAAK,IAAK,IAAM,IAAK,IAAK,IAAK,KAEnD,SAAS,GAAG,OAAQ,AAAC,GAAY,CAC7B,GAAI,IAAU,EAAG,CACb,EAAW,QAAQ,AAAC,GAAM,CACtB,AAAI,EAAQ,MAAM,GAAG,OAAS,GAC1B,GAAM,IAAM,EAAQ,MAAM,GAC1B,EAAM,IAAM,KAIhB,GAAM,MAAQ,IAAM,EAAM,IAAI,QAAU,IACxC,GAAM,OAAO,sBAA2B,GAAG,yCAC3C,EAAM,OAAS,IAGnB,GAAM,GAAU,MAKhB,GAFyB,EAAM,IAAI,KAAK,AAAC,GAAO,EAAQ,KAAK,IAEvC,CAClB,EAAM,OAAS,GACf,EAAM,SAAS,SAAc,kBAC7B,IACA,OAGJ,EAAM,OAAS,GACf,EAAM,UAAY,EAAM,IACxB,EAAM,QAAU,EAAM,IAG1B,GAAI,EAAQ,GAAK,EAAQ,EAAK,CAE1B,GAAM,GAAe,EAAQ,MAAM,KAAK,OAAS,EAmBjD,GAjBI,GACI,EAAe,IAAM,GAGrB,GAAM,kBAAoB,IAK9B,EAAe,IAAM,GACrB,EAAQ,MAAM,MAAM,OAAS,IAAM,GAEnC,GAAW,GAKX,AAFU,EAAQ,MAAM,EAAM,KAAK,SAEzB,EAAM,IAAI,OAAQ,CAC5B,EAAM,OAAO,iBAAsB,qBACnC,OAEJ,EAAM,QAAQ,KAAK,EAAQ,MAAM,EAAM,MAE3C,MAEG,GAGX,iBAAc,SAAC,EAAsB,CACjC,GAAM,GAAM,KAAO,KAAO,GAC1B,GAAI,CAAC,AAAG,aAAW,GACf,KAAM,IAAI,OAAM,uBAAuB,yCAI3C,GAAI,AAFS,AAAG,WAAS,GAEhB,KAAO,EACZ,KAAM,IAAI,OAAM,4BAA4B,wCAEhD,MAAO,AAAG,YAAS,GAAM,MAQ7B,iBAAoB,SAChB,EACA,EACA,EACe,CACf,MAAO,IAAI,SAAQ,CAAC,EAAS,IAAW,CACpC,GAAI,CACA,GAAM,GAAO,OAAK,KAAL,UAAkB,CAC3B,YAAa,EAAY,WACzB,OAAQ,cAGZ,GAAI,CAAE,aAAgB,IAElB,KAAM,IAAI,OAAM,4CAA4C,EAAE,UAElE,GAAM,GAAU,GAAI,GAA6B,CAC7C,OAAQ,EACR,gBAAiB,OACjB,YAAa,WACb,IAAK,IAGT,EACK,KAAK,GACL,KAAK,AAAC,GAAS,CACZ,AAAI,EAAK,UACL,EAAQ,EAAK,UAEjB,EAAO,GAAI,OAAM,WAEpB,MAAM,AAAC,GAAU,CACd,EAAO,KAEV,QAAQ,IAAM,CACX,QAAQ,IAAI,iCAEf,EAAP,CACE,EAAO,OAKnB,gBAAW,SACP,EACA,EAUF,CACE,GAAM,GAAM,CACR,KAAM,GAAW,EAAQ,KAAO,EAAQ,KAAO,IAGnD,GAAI,CAAC,EAAI,WAAW,UAAY,EAAI,MAAM,MAAM,KAAO,KACnD,KAAM,IAAI,OAAM,mBAAmB,KAGvC,GAAI,GAAM,GAEJ,EAAS,CACX,OAAQ,GACR,IAAK,GACL,KAAM,IAGJ,EAAM,EAAI,MAAM,MAAM,GACtB,CAAC,KAAW,GAAQ,EAAI,MAAM,KAAK,OAAO,GAEhD,SAAO,OAAS,EAChB,EAAO,IAAM,EAAK,KAAK,KAEvB,EAAK,QAAQ,CAAC,EAAG,IAAM,CACnB,GAAI,IAAM,EAAK,OAAS,EAAG,CACvB,GAAM,GAAO,EAAE,MAAM,KAAK,OAG1B,GAFI,EAAI,MAAQ,IAAS,GAAG,GAAM,iCAAiC,KAE/D,CAAC,EAAI,MAAQ,IAAS,EAAG,OAE7B,GAAI,CAAC,EAAI,MAAQ,EAAO,EAAG,CACvB,EAAM,mBAAmB,oCACzB,OAGJ,AAAI,CAAC,EAAI,MAAQ,EAAE,MAAM,KAAK,KAAO,IAAM,EAAO,GAC9C,GAAM,GAAG,oCAAsC,KAE/C,EAAO,GAAK,EAAE,MAAM,KAAK,KAAO,IAAI,GAAO,KAAO,MAGvD,CACH,KAAM,EACN,IAAK,IAUV,WAAwB,EAAwB,CACnD,MAAO,IAAI,GAAS",
  "names": []
}
