{
  "version": 3,
  "sources": ["../lib/engine.ts", "../lib/types.ts"],
  "sourcesContent": ["import * as fs from \"fs\";\nimport {readFileSync, writeFileSync} from 'atomically';\nimport {CreateMultipartUploadCommand, PutObjectCommand, S3Client, S3ClientConfig} from \"@aws-sdk/client-s3\";\nimport {fromIni} from \"@aws-sdk/credential-providers\";\nimport {AthenaClient, AthenaClientConfig} from \"@aws-sdk/client-athena\";\nimport {ChildProcessWithoutNullStreams, spawn} from \"child_process\";\nimport os from \"os\";\nimport path from \"path\";\nimport {createInterface} from \"readline\";\nimport {\n    Cache,\n    connectorType,\n    Dataset,\n    DatasetOptions,\n    datasetStateType,\n    env,\n    mlrCmd,\n    ProcessResult,\n    Shape\n} from \"./types\"\n\nconst credentials = (profile: string) => fromIni({\n    profile: profile,\n    mfaCodeProvider: async (mfaSerial) => {\n        return mfaSerial\n    },\n});\n\nlet s3: S3Client;\nlet athena: AthenaClient\n\n/**\n * Creates a new S3 client if one already doesn't exist.\n *  @param {S3ClientConfig} config\n *  @returns {S3Client}\n */\nfunction s3Client(config: S3ClientConfig): S3Client {\n    if (!s3) {\n        console.log('creating s3 client')\n        s3 = new S3Client(config);\n    }\n    return s3;\n}\n\n/**\n * Creates a new athena client if one already doesn't exist.\n *  @param {AthenaClientConfig} config\n *  @returns {AthenaClient}\n */\nfunction athenaClient(config: AthenaClientConfig): AthenaClient {\n    if (!s3) {\n        console.log('creating athena client')\n        athena = new AthenaClient(config);\n    }\n    return athena;\n}\n\n// TODO: amke sure dataet is uploaded to s3,  prepare athena query, run athena query, create function query(``)\n\n\n/**\n * Parses S3 (s3://) style URIs\n */\nfunction parseS3Uri(\n    uri: string,\n    options: {\n        file: boolean;\n    }\n): {\n    data: {\n        bucket: string;\n        key: string;\n        file: string;\n    };\n    err: string;\n} {\n    const opt = {\n        file: options && options.file ? options.file : false,\n    };\n\n    if (!uri.startsWith(\"s3://\") || uri.split(\":/\")[0] !== \"s3\") {\n        throw new Error(`invalid-s3-uri: ${uri}`);\n    }\n\n    let err = \"\";\n\n    const result = {\n        bucket: \"\",\n        key: \"\",\n        file: \"\",\n    };\n\n    const src = uri.split(\":/\")[1];\n    const [bucket, ...keys] = src.split(\"/\").splice(1);\n\n    result.bucket = bucket;\n    result.key = keys.join(\"/\");\n\n    keys.forEach((k, i) => {\n        if (i === keys.length - 1) {\n            const last = k.split(\".\").length;\n            if (opt.file && last === 1) err = `uri should be a given, given: ${uri}`;\n\n            if (!opt.file && last === 1) return;\n\n            if (!opt.file && last > 1) {\n                err = `Invalid S3 uri, ${uri} should not end with a file name`;\n                return;\n            }\n\n            if (!opt.file && k.split(\".\")[1] !== \"\" && last > 1)\n                err = `${uri} should not be a file endpoint: ${k}`;\n\n            if (last > 1 && k.split(\".\")[1] !== \"\") result.file = k;\n        }\n    });\n    return {\n        data: result,\n        err: err,\n    };\n}\n\n/**\n * Dataset represent a file for processing\n */\nclass _Dataset implements Dataset {\n    source: string;\n    destination: string;\n    addedAt: Date;\n    options: DatasetOptions;\n    shape: Shape\n    cached: boolean;\n    state: datasetStateType\n    connector: connectorType | null\n    env: string\n\n    constructor(source: string, options: DatasetOptions) {\n        this.source = source;\n        this.cached = false;\n        this.destination = options.destination\n        this.options = options;\n        this.env = this.determineSource();\n        this.shape = {\n            type: \"\",\n            columns: [],\n            header: false,\n            encoding: \"\",\n            bom: false,\n            size: 0,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: \"\",\n            errors: {},\n            warnings: {},\n            preview: [[]]\n        }\n        this.addedAt = new Date();\n        this.state = 'init'\n        this.connector = null\n    }\n\n    setDestination(destination: string) {\n        this.destination = destination\n    }\n\n    /**\n     * Convert CSV to JSON\n     * @return {Promise<string>} source of the dataset\n     */\n    async toJson(): Promise<string> {\n        const write = fs.createWriteStream(this.destination)\n\n        const json = this.exec(mlrCmd, [\"--icsv\", \"--ojson\", \"clean-whitespace\", \"cat\", this.source])\n        json.stdout.pipe(write)\n\n        write.on('close', () => {\n            console.log(\"\uD83D\uDCDD Dataset converted to JSON\")\n            return this.destination\n        })\n\n        write.on('error', (err) => {\n            throw new Error(err.message)\n        })\n        return this.destination\n    }\n\n    /**\n     * Count number of rows\n     * @return {Promise<string>} number of rows\n     */\n    async rowCount(): Promise<number> {\n        const count = await this.exec(mlrCmd, [`--ojson`, `count`, this.source])\n\n        const rowCountExec = await this.promisifyProcessResult(count)\n\n        if (rowCountExec.code !== 0) {\n            throw new Error(`Error while counting rows: ${rowCountExec.stderr}`)\n        }\n\n        if (rowCountExec.stderr) {\n            throw new Error(rowCountExec.stderr)\n        }\n\n        const r = JSON.parse(rowCountExec.stdout)\n\n        if (r.length === 0) {\n            throw new Error('No rows found')\n        }\n\n        return r[0].count\n    }\n\n    /**\n     * Extracts the header row from the dataset, defined columns\n     * @return Promise<string[] | null> header row or null if no header\n     */\n    async getColumnHeader(): Promise<string[] | null> {\n        const res = await this.exec(mlrCmd, [`--icsv`, `--ojson`, `head`, `-n`, `1`, this.source])\n\n        const colExec = await this.promisifyProcessResult(res)\n\n        if (colExec.code !== 0) {\n            return null\n        }\n\n        if (colExec.stderr) {\n            throw new Error(colExec.stderr)\n        }\n        const columns = JSON.parse(colExec.stdout)\n\n        if (columns.length === 0) {\n            this.shape.header = false\n            return null\n        }\n\n        this.shape.columns = Object.keys(columns[0])\n        this.shape.header = true\n        return this.shape.columns\n    }\n\n    async formatValues() {\n        // --opprint format-values\n        const res = await this.exec(mlrCmd, [`--icsv`, `format-values`, this.source])\n        const formatVal = await this.promisifyProcessResult(res)\n\n        if (formatVal.code !== 0) {\n            return null\n        }\n\n        if (formatVal.stderr) {\n            throw new Error(formatVal.stderr)\n        }\n\n        return this.shape.columns\n    }\n\n    /**\n     * Extracts rows from the dataset for preview.\n     * If the dataset is too large to preview then it will stream the result and return the file path\n     * @param {number} count - number of rows to preview\n     * @param {string} streamTo - path to the file to stream to\n     * @return Promise<string[][] | string> - preview rows or path to the file the preview was streamed to\n     */\n    async preview(count = 20, streamTo?: string): Promise<string[][] | string> {\n        let write: fs.WriteStream\n\n        const maxPreview = 1024 * 1024 * 10\n\n        const fsp = fs.promises\n        const stat = await fsp.stat(this.source)\n\n        if (streamTo && streamTo !== this.source && fs.createWriteStream(streamTo) instanceof fs.WriteStream || stat.size > maxPreview) {\n\n            if (streamTo === undefined) throw new Error('stream-destination-undefined')\n            write = fs.createWriteStream(streamTo)\n\n            const previewExec = await this.exec(mlrCmd, [`--icsv`, `--ojson`, `head`, `-n`, count.toString(), this.source])\n\n            previewExec.stdout.pipe(write)\n\n            console.warn(`\uD83D\uDC40 Preview saved to: ${streamTo}`)\n            return streamTo\n        }\n\n        const previewExec = await this.exec(mlrCmd, [`--icsv`, `--ojson`, `head`, `-n`, count.toString(), this.source])\n\n        const prev = await this.promisifyProcessResult(previewExec)\n\n        if (prev.stderr) {\n            throw new Error(prev.stderr)\n        }\n\n        if (prev.code !== 0) {\n            throw new Error(`Error while executing mlr command`)\n        }\n\n        this.shape.preview = JSON.parse(prev.stdout)\n        return this.shape.preview\n    }\n\n\n    async detectShape(): Promise<Shape> {\n        const path = this.source\n        const shape: Shape = {\n            type: '',\n            size: 0,\n            columns: [''],\n            header: false,\n            encoding: 'utf-8',\n            bom: false,\n            spanMultipleLines: false,\n            quotes: false,\n            delimiter: ',',\n            errors: {},\n            warnings: {},\n            preview: [['']],\n        };\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`path-doesnt-exists: ${path} ,provide a valid path to a CSV file`)\n        }\n\n        const stat = fs.statSync(path)\n        this.shape.size = stat.size\n\n        if (stat.size > 1024 * 1024 * 1024) {\n            throw new Error(`file-size-exceeds-limit: ${path} is too large, please limit to under 1GB for now`)\n        }\n\n        if (!fs.existsSync(path)) {\n            throw new Error(`${path} does not exist, provide a valid path to a CSV file`)\n        }\n\n        if (os.platform() === \"win32\") {\n            // TODO: handle\n            throw new Error(`scream`)\n        }\n\n        const mime = this.exec(\"file\", [path, \"--mime-type\"])\n\n        const mimeRes = await this.promisifyProcessResult(mime)\n\n        if (mimeRes.stderr) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        if (mimeRes.code !== 0) {\n            throw new Error(`failed-to-detect-mime-type: ${mimeRes.stderr}`)\n        }\n\n        const mimeType = mimeRes.stdout.trim()\n\n        const readLine = createInterface({\n            input: fs.createReadStream(path),\n            crlfDelay: Infinity,\n        });\n\n        let count = 0;\n        const max = 20;\n\n        const first = {\n            row: [''],\n            del: \"\",\n        };\n\n        // hold the previous line while rl proceeds to next line using \\r\\n as a delimiter\n        let previous = \"\";\n\n        const delimiters = [\",\", \";\", \"\\t\", \"|\", \":\", \" \", \"|\"];\n\n        readLine.on(\"line\", (current) => {\n            if (count === 0) {\n                delimiters.forEach((d) => {\n                    if (current.split(d).length > 1) {\n                        first.row = current.split(d)\n                        first.del = d;\n                    }\n                });\n\n                if (first.del === \"\" || first.row.length <= 1) {\n                    shape.errors[\"unrecognizedDelimiter\"] = `${path} does not have a recognized delimiter`;\n                    shape.header = false;\n                }\n                const isDigit = /\\d+/;\n\n                // assuming that numbers shouldn't start as column header\n                const hasDigitInHeader = first.row.some((el) => isDigit.test(el));\n                // if (hasDigitInHeader) {\n                //     shape.header = false;\n                //     shape.warnings[\"noHeader\"] = `no header found`;\n                //     count++;\n                //     return;\n                // }\n                shape.header = true;\n                shape.delimiter = first.del;\n                shape.columns = first.row;\n            }\n\n            if (count > 0 && count < max) {\n                // there is a chance the record spans next line\n                const inlineQuotes = current.split(`\"`).length - 1;\n\n                if (previous) {\n                    if (inlineQuotes % 2 !== 0) {\n                        // TODO: make sure previous + current\n                        // console.log(previous + l);\n                        shape.spanMultipleLines = true;\n                    }\n                }\n                // if odd number of quotes and consider escaped quotes such as: \"aaa\",\"b\"\"bb\",\"ccc\"\n                if (\n                    inlineQuotes % 2 !== 0 &&\n                    current.split(`\"\"`).length - 1 !== 1\n                ) {\n                    previous = current;\n                }\n\n                const width = current.split(first.del).length;\n\n                if (width !== first.row.length) {\n                    shape.errors['rowWidthMismatch'] = `row width mismatch`;\n                    return;\n                }\n                shape.preview.push(current.split(first.del));\n            }\n            count++;\n        });\n        return shape;\n    }\n\n    determineConnector(): connectorType {\n        const env = this.determineSource();\n        if (env === \"local\") {\n            const stream = fs.createReadStream(this.source);\n            return stream\n        }\n\n        if (env === \"aws\") {\n            const client = s3Client({\n                credentials: credentials(\"default\"),\n                region: \"us-east-2\",\n            });\n            return client\n        }\n        throw new Error(`unsupported-source for: ${this.source}`)\n    }\n\n    determineSource(): string {\n        if (\n            this.source.startsWith(\"/\") ||\n            this.source.startsWith(\"../\") ||\n            this.source.startsWith(\"./\")\n        ) {\n            return \"local\";\n        }\n\n        if (this.source.startsWith(\"s3://\")) {\n            return \"remote\";\n        }\n\n        throw new Error(`invalid-source-type: ${this.source}`);\n    }\n\n    fileSize(): number {\n        const max = 1024 * 1024 * 50\n\n        if (!fs.existsSync(this.source)) {\n            throw new Error(`path-doesnt-exists: ${this.source} ,provide a valid path to a CSV file`)\n        }\n\n        const stat = fs.statSync(this.source)\n\n        if (stat.size > max) {\n            throw new Error(`file-size-exceeds-limit: ${this.source} is too large, please limit to 50MB`)\n        }\n        return stat.size\n    }\n\n    async uploadToS3(): Promise<string> {\n        if (!this.source || !this.destination) {\n            throw new Error('source or destination not set. Both must be defined to upload to S3')\n        }\n\n        const fStream = fs.createReadStream(this.source)\n\n        if (!fStream.readable) {\n            throw new Error('failed-to-read-source: Make sure the provided file is readable')\n        }\n\n        const fSize = this.fileSize()\n\n        if (fSize > 100 * 1024 * 1024) {\n            //TODO: init multipart upload then upload parts\n            console.warn(`file size ${fSize} is larger than 100MB`)\n        }\n\n        const {data: uri, err} = parseS3Uri(this.destination, {\n            file: true,\n        });\n\n        if (err.toString().startsWith(`invalid-s3-uri`)) {\n            throw new Error(`failed-to-parse-s3-uri: ${err}`)\n        }\n\n        if (!uri.file) {\n            uri.file = path.basename(this.source)\n            console.warn(\"Destination filename not provided. Using source source basename\" + uri.file)\n        }\n\n        console.log(`uploading ${this.source} to ${this.destination}`);\n\n        const s3 = s3Client({\n            region: \"us-east-2\",\n        })\n\n        const res = await s3.send(new PutObjectCommand({\n            Bucket: uri.bucket,\n            Key: uri.key + uri.file,\n            Body: fStream,\n        })).catch(err => {\n            throw new Error(`failed-upload-s3: Error while uploading to S3: ${err}`)\n        }).finally(() => {\n            fStream.close()\n        })\n        if (res.$metadata.httpStatusCode !== 200) {\n            throw new Error(`failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`)\n        }\n\n        if (!res.$metadata.requestId) throw new Error(`failed-upload-s3: Error while uploading to S3: ${res.$metadata.httpStatusCode}`)\n        return res.$metadata.requestId\n    }\n\n    /**\n     * Initiates a multipart upload and returns an upload ID\n     * @returns {string} uploadID\n     * @private\n     */\n    async initMultipartUpload(\n        bucket: string,\n        key: string\n    ): Promise<string> {\n\n        const client = s3Client({\n            credentials: credentials(\"default\"),\n            region: \"us-east-2\",\n        });\n\n        const command = new CreateMultipartUploadCommand({\n            Bucket: bucket,\n            ContentEncoding: \"utf8\",\n            ContentType: \"text/csv\",\n            Key: key,\n        });\n\n        const result = await client.send(command);\n\n        if (result.$metadata.httpStatusCode !== 200) {\n            throw new Error(`failed-multipart-upload: Error while creating multipart upload: ${result.UploadId} with status code ${result.$metadata.httpStatusCode}`)\n        }\n\n        if (!result.UploadId) {\n            throw new Error(`failed-multipart-upload: Error while creating multipart upload: ${result.UploadId}`)\n        }\n\n        return result.UploadId\n    }\n\n    exec(cmd: string, args: string[]): ChildProcessWithoutNullStreams {\n        console.log(`exec: ${cmd} ${args.join(' ')}`)\n        return spawn(cmd, args)\n    }\n\n    promisifyProcessResult(child: ChildProcessWithoutNullStreams): Promise<ProcessResult> {\n        const result: ProcessResult = {\n            stdout: '',\n            stderr: '',\n            code: 0\n        }\n\n        return new Promise((resolve, reject) => {\n            child.stdout.on('data', (data) => {\n                result.stdout += data\n            })\n\n            child.stderr.on('data', (data) => {\n                result.stderr += data\n            })\n\n            child.on('close', (code) => {\n                result.code = code === 0 ? 0 : 1\n                resolve(result)\n            })\n\n            child.on('error', (err) => {\n                reject(err)\n            })\n        })\n    }\n}\n\n/**\n * Returns a new dataset\n * @param {string} source - Source of the dataset\n * @returns {Options} options - Options for the dataset\n */\nexport function createDataset(source: string, options: DatasetOptions): Dataset {\n    const d = new _Dataset(source, options);\n    Promise.all([d.detectShape(), d.determineSource(), d.determineConnector()]).then((val) => {\n        // console.log(val)\n    }).catch((err) => {\n        throw new Error(err)\n    })\n    return d;\n}\n\nconst cache = (function (): { getInstance: () => Cache } {\n    let cache: Cache;\n\n    function init() {\n        const cachePath = path.join(process.cwd(), '.muto-cache')\n\n        if (!fs.existsSync(cachePath)) {\n            console.log('creating cache file at', cachePath)\n            writeFileSync(cachePath, JSON.stringify({}))\n        } else {\n            console.log('loading cache from', cachePath)\n        }\n\n        return {\n            init: new Date(),\n            path: cachePath,\n            get: (key: string): Dataset | undefined => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key].source !== key) {\n                    return undefined\n                }\n                return cache[key]\n            },\n            set: (key: string, value: Dataset): string | void => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key]) {\n                    return\n                }\n\n                cache[key] = value\n                writeFileSync(cachePath, JSON.stringify(cache))\n                return key\n            },\n            has: (key: string): boolean => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                if (cache[key]) {\n                    return true\n                }\n                return false\n            },\n            delete: (key: string) => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n\n                delete cache[key]\n\n                writeFileSync(cachePath, JSON.stringify(cache))\n            },\n            clear: () => {\n                writeFileSync(cachePath, JSON.stringify({}))\n            },\n            size: () => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return Object.keys(cache).length\n            },\n            keys: () => {\n                const file = readFileSync(cachePath)\n                const cache = JSON.parse(file.toString())\n                return Object.keys(cache)\n            }\n        }\n    }\n\n    return {\n        getInstance: () => {\n            if (!cache) {\n                cache = init()\n            }\n            return cache\n        }\n    }\n})()\n\nclass Workflow {\n    name: string;\n    datasets: Map<string, Dataset>;\n    readonly createdAt: Date;\n    env: env;\n    lcache: Cache | null\n\n    constructor(name: string) {\n        this.name = name;\n        this.datasets = new Map();\n        this.createdAt = new Date();\n        this.env = 'local';\n        this.lcache = null;\n        // this.lcache = cache.getInstance()\n    }\n\n    list(): Dataset[] {\n        return Array.from(this.datasets.values());\n    }\n\n    remove(dataset: Dataset) {\n        this.datasets.delete(dataset.source);\n    }\n\n    async add(source: string, options: DatasetOptions): Promise<string> {\n        if (options.destination === \"\") {\n            console.warn(`destination-not-provided: provide a destination for ${source}`);\n        }\n\n        // if (this.lcache.has(source)) {\n        //     return source\n        // }\n        const dataset = new _Dataset(source, options);\n\n        this.datasets.set(source, dataset);\n        return source\n    }\n}\n\n\n/**\n * Returns a new workflow\n * @param {string} name - Name of the workflow\n * @returns {Workflow} - New workflow\n */\nexport function createWorkflow(name: string): Workflow {\n    return new Workflow(name);\n}\n", "import {S3Client} from \"@aws-sdk/client-s3\";\nimport {join} from \"path\";\nimport fs from \"fs\";\n\nexport enum Delimiters {\n    COMMA = \",\",\n    SEMICOLON = \";\",\n    PIPE = \"|\",\n    COLON = \":\",\n    TAB = \"\\t\",\n    SPACE = \" \",\n    TILDE = \"~\",\n    DASH = \"-\",\n    UNDERSCORE = \"_\"\n}\n\nexport type env = 'local' | 'aws'\nexport type connectorType = S3Client | fs.ReadStream\nexport const mlrCmd = join(process.cwd(), 'node_modules', '.bin', 'mlr@v6.0.0')\n\n\n// TODO: better error message for errors in transform\nexport type datasetStateType = 'init' | 'transforming' | 'uploading' | 'cancelled' | 'uploaded' | 'ready'\nexport type ShapeErrType = 'unrecognizedDelimiter' | 'noHeader' | 'invalidFileType' | 'rowWidthMismatch'\n\n\nexport type Shape = {\n    type: string,\n    columns: Array<string>,\n    header: boolean,\n    encoding: string,\n    bom: boolean,\n    size: number,\n    spanMultipleLines: boolean,\n    quotes: boolean,\n    delimiter: string,\n    errors: { [key: string]: string }\n    warnings: { [key: string]: string },\n    preview: string[][],\n}\n\nexport interface Dataset {\n    source: string\n    destination: string\n    addedAt: Date;\n    options: DatasetOptions;\n    shape: Shape\n    cached: boolean\n    state: datasetStateType\n    connector: connectorType | null\n\n    setDestination(destination: string): void\n\n    toJson(): Promise<string>\n\n    getColumnHeader(): Promise<string[] | null>\n\n    rowCount(): Promise<number>\n\n    fileSize(): number\n\n    preview(count: number, streamTo?: string): Promise<string[][] | string>\n\n    detectShape(): Promise<Shape>\n\n    determineSource(): string\n\n    determineSource(): string\n\n    determineConnector(): connectorType\n\n    uploadToS3(bucket: string, key: string): Promise<string>\n\n    initMultipartUpload(bucket: string, key: string): Promise<string>\n\n}\n\nexport type DatasetOptions = {\n    destination: string;\n    columns: Array<string>,\n    header: boolean,\n    quotes: boolean,\n    transform: (row: object) => object\n    delimiter: Delimiters\n}\n\nexport interface Cache {\n    path: string\n    init: Date\n\n    get(key: string): Dataset | undefined\n\n    set(key: string, value: Dataset): void\n\n    has(key: string): boolean\n\n    delete(key: string): void\n\n    clear(): void\n\n    size(): number\n\n    keys(): string[]\n}\n\nexport type ProcessResult = {\n    stdout: string,\n    stderr: string,\n    code: number\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;ACPA;AAiBO,IAAM,SAAS,KAAK,QAAQ,OAAO,gBAAgB,QAAQ;;;ADGlE,IAAM,cAAc,CAAC,YAAoB,QAAQ;AAAA,EAC7C;AAAA,EACA,iBAAiB,CAAO,cAAc;AAClC,WAAO;AAAA;AAAA;AAIf,IAAI;AAQJ,kBAAkB,QAAkC;AAChD,MAAI,CAAC,IAAI;AACL,YAAQ,IAAI;AACZ,SAAK,IAAI,SAAS;AAAA;AAEtB,SAAO;AAAA;AAsBX,oBACI,KACA,SAUF;AACE,QAAM,MAAM;AAAA,IACR,MAAM,WAAW,QAAQ,OAAO,QAAQ,OAAO;AAAA;AAGnD,MAAI,CAAC,IAAI,WAAW,YAAY,IAAI,MAAM,MAAM,OAAO,MAAM;AACzD,UAAM,IAAI,MAAM,mBAAmB;AAAA;AAGvC,MAAI,MAAM;AAEV,QAAM,SAAS;AAAA,IACX,QAAQ;AAAA,IACR,KAAK;AAAA,IACL,MAAM;AAAA;AAGV,QAAM,MAAM,IAAI,MAAM,MAAM;AAC5B,QAAM,CAAC,WAAW,QAAQ,IAAI,MAAM,KAAK,OAAO;AAEhD,SAAO,SAAS;AAChB,SAAO,MAAM,KAAK,KAAK;AAEvB,OAAK,QAAQ,CAAC,GAAG,MAAM;AACnB,QAAI,MAAM,KAAK,SAAS,GAAG;AACvB,YAAM,OAAO,EAAE,MAAM,KAAK;AAC1B,UAAI,IAAI,QAAQ,SAAS;AAAG,cAAM,iCAAiC;AAEnE,UAAI,CAAC,IAAI,QAAQ,SAAS;AAAG;AAE7B,UAAI,CAAC,IAAI,QAAQ,OAAO,GAAG;AACvB,cAAM,mBAAmB;AACzB;AAAA;AAGJ,UAAI,CAAC,IAAI,QAAQ,EAAE,MAAM,KAAK,OAAO,MAAM,OAAO;AAC9C,cAAM,GAAG,sCAAsC;AAEnD,UAAI,OAAO,KAAK,EAAE,MAAM,KAAK,OAAO;AAAI,eAAO,OAAO;AAAA;AAAA;AAG9D,SAAO;AAAA,IACH,MAAM;AAAA,IACN;AAAA;AAAA;AAOR,qBAAkC;AAAA,EAW9B,YAAY,QAAgB,SAAyB;AACjD,SAAK,SAAS;AACd,SAAK,SAAS;AACd,SAAK,cAAc,QAAQ;AAC3B,SAAK,UAAU;AACf,SAAK,MAAM,KAAK;AAChB,SAAK,QAAQ;AAAA,MACT,MAAM;AAAA,MACN,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,KAAK;AAAA,MACL,MAAM;AAAA,MACN,mBAAmB;AAAA,MACnB,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,QAAQ;AAAA,MACR,UAAU;AAAA,MACV,SAAS,CAAC;AAAA;AAEd,SAAK,UAAU,IAAI;AACnB,SAAK,QAAQ;AACb,SAAK,YAAY;AAAA;AAAA,EAGrB,eAAe,aAAqB;AAChC,SAAK,cAAc;AAAA;AAAA,EAOjB,SAA0B;AAAA;AAC5B,YAAM,QAAQ,AAAG,qBAAkB,KAAK;AAExC,YAAM,OAAO,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,oBAAoB,OAAO,KAAK;AACrF,WAAK,OAAO,KAAK;AAEjB,YAAM,GAAG,SAAS,MAAM;AACpB,gBAAQ,IAAI;AACZ,eAAO,KAAK;AAAA;AAGhB,YAAM,GAAG,SAAS,CAAC,QAAQ;AACvB,cAAM,IAAI,MAAM,IAAI;AAAA;AAExB,aAAO,KAAK;AAAA;AAAA;AAAA,EAOV,WAA4B;AAAA;AAC9B,YAAM,QAAQ,MAAM,KAAK,KAAK,QAAQ,CAAC,WAAW,SAAS,KAAK;AAEhE,YAAM,eAAe,MAAM,KAAK,uBAAuB;AAEvD,UAAI,aAAa,SAAS,GAAG;AACzB,cAAM,IAAI,MAAM,8BAA8B,aAAa;AAAA;AAG/D,UAAI,aAAa,QAAQ;AACrB,cAAM,IAAI,MAAM,aAAa;AAAA;AAGjC,YAAM,IAAI,KAAK,MAAM,aAAa;AAElC,UAAI,EAAE,WAAW,GAAG;AAChB,cAAM,IAAI,MAAM;AAAA;AAGpB,aAAO,EAAE,GAAG;AAAA;AAAA;AAAA,EAOV,kBAA4C;AAAA;AAC9C,YAAM,MAAM,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,QAAQ,MAAM,KAAK,KAAK;AAElF,YAAM,UAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,QAAQ,SAAS,GAAG;AACpB,eAAO;AAAA;AAGX,UAAI,QAAQ,QAAQ;AAChB,cAAM,IAAI,MAAM,QAAQ;AAAA;AAE5B,YAAM,UAAU,KAAK,MAAM,QAAQ;AAEnC,UAAI,QAAQ,WAAW,GAAG;AACtB,aAAK,MAAM,SAAS;AACpB,eAAO;AAAA;AAGX,WAAK,MAAM,UAAU,OAAO,KAAK,QAAQ;AACzC,WAAK,MAAM,SAAS;AACpB,aAAO,KAAK,MAAM;AAAA;AAAA;AAAA,EAGhB,eAAe;AAAA;AAEjB,YAAM,MAAM,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,iBAAiB,KAAK;AACrE,YAAM,YAAY,MAAM,KAAK,uBAAuB;AAEpD,UAAI,UAAU,SAAS,GAAG;AACtB,eAAO;AAAA;AAGX,UAAI,UAAU,QAAQ;AAClB,cAAM,IAAI,MAAM,UAAU;AAAA;AAG9B,aAAO,KAAK,MAAM;AAAA;AAAA;AAAA,EAUhB,QAAQ,QAAQ,IAAI,UAAiD;AAAA;AACvE,UAAI;AAEJ,YAAM,aAAa,OAAO,OAAO;AAEjC,YAAM,MAAS;AACf,YAAM,OAAO,MAAM,IAAI,KAAK,KAAK;AAEjC,UAAI,YAAY,aAAa,KAAK,UAAU,AAAG,qBAAkB,qBAAwB,kBAAe,KAAK,OAAO,YAAY;AAE5H,YAAI,aAAa;AAAW,gBAAM,IAAI,MAAM;AAC5C,gBAAQ,AAAG,qBAAkB;AAE7B,cAAM,eAAc,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,QAAQ,MAAM,MAAM,YAAY,KAAK;AAEvG,qBAAY,OAAO,KAAK;AAExB,gBAAQ,KAAK,+BAAwB;AACrC,eAAO;AAAA;AAGX,YAAM,cAAc,MAAM,KAAK,KAAK,QAAQ,CAAC,UAAU,WAAW,QAAQ,MAAM,MAAM,YAAY,KAAK;AAEvG,YAAM,OAAO,MAAM,KAAK,uBAAuB;AAE/C,UAAI,KAAK,QAAQ;AACb,cAAM,IAAI,MAAM,KAAK;AAAA;AAGzB,UAAI,KAAK,SAAS,GAAG;AACjB,cAAM,IAAI,MAAM;AAAA;AAGpB,WAAK,MAAM,UAAU,KAAK,MAAM,KAAK;AACrC,aAAO,KAAK,MAAM;AAAA;AAAA;AAAA,EAIhB,cAA8B;AAAA;AAChC,YAAM,QAAO,KAAK;AAClB,YAAM,QAAe;AAAA,QACjB,MAAM;AAAA,QACN,MAAM;AAAA,QACN,SAAS,CAAC;AAAA,QACV,QAAQ;AAAA,QACR,UAAU;AAAA,QACV,KAAK;AAAA,QACL,mBAAmB;AAAA,QACnB,QAAQ;AAAA,QACR,WAAW;AAAA,QACX,QAAQ;AAAA,QACR,UAAU;AAAA,QACV,SAAS,CAAC,CAAC;AAAA;AAGf,UAAI,CAAC,AAAG,cAAW,QAAO;AACtB,cAAM,IAAI,MAAM,uBAAuB;AAAA;AAG3C,YAAM,OAAO,AAAG,YAAS;AACzB,WAAK,MAAM,OAAO,KAAK;AAEvB,UAAI,KAAK,OAAO,OAAO,OAAO,MAAM;AAChC,cAAM,IAAI,MAAM,4BAA4B;AAAA;AAGhD,UAAI,CAAC,AAAG,cAAW,QAAO;AACtB,cAAM,IAAI,MAAM,GAAG;AAAA;AAGvB,UAAI,GAAG,eAAe,SAAS;AAE3B,cAAM,IAAI,MAAM;AAAA;AAGpB,YAAM,OAAO,KAAK,KAAK,QAAQ,CAAC,OAAM;AAEtC,YAAM,UAAU,MAAM,KAAK,uBAAuB;AAElD,UAAI,QAAQ,QAAQ;AAChB,cAAM,IAAI,MAAM,+BAA+B,QAAQ;AAAA;AAG3D,UAAI,QAAQ,SAAS,GAAG;AACpB,cAAM,IAAI,MAAM,+BAA+B,QAAQ;AAAA;AAG3D,YAAM,WAAW,QAAQ,OAAO;AAEhC,YAAM,WAAW,gBAAgB;AAAA,QAC7B,OAAO,AAAG,oBAAiB;AAAA,QAC3B,WAAW;AAAA;AAGf,UAAI,QAAQ;AACZ,YAAM,MAAM;AAEZ,YAAM,QAAQ;AAAA,QACV,KAAK,CAAC;AAAA,QACN,KAAK;AAAA;AAIT,UAAI,WAAW;AAEf,YAAM,aAAa,CAAC,KAAK,KAAK,KAAM,KAAK,KAAK,KAAK;AAEnD,eAAS,GAAG,QAAQ,CAAC,YAAY;AAC7B,YAAI,UAAU,GAAG;AACb,qBAAW,QAAQ,CAAC,MAAM;AACtB,gBAAI,QAAQ,MAAM,GAAG,SAAS,GAAG;AAC7B,oBAAM,MAAM,QAAQ,MAAM;AAC1B,oBAAM,MAAM;AAAA;AAAA;AAIpB,cAAI,MAAM,QAAQ,MAAM,MAAM,IAAI,UAAU,GAAG;AAC3C,kBAAM,OAAO,2BAA2B,GAAG;AAC3C,kBAAM,SAAS;AAAA;AAEnB,gBAAM,UAAU;AAGhB,gBAAM,mBAAmB,MAAM,IAAI,KAAK,CAAC,OAAO,QAAQ,KAAK;AAO7D,gBAAM,SAAS;AACf,gBAAM,YAAY,MAAM;AACxB,gBAAM,UAAU,MAAM;AAAA;AAG1B,YAAI,QAAQ,KAAK,QAAQ,KAAK;AAE1B,gBAAM,eAAe,QAAQ,MAAM,KAAK,SAAS;AAEjD,cAAI,UAAU;AACV,gBAAI,eAAe,MAAM,GAAG;AAGxB,oBAAM,oBAAoB;AAAA;AAAA;AAIlC,cACI,eAAe,MAAM,KACrB,QAAQ,MAAM,MAAM,SAAS,MAAM,GACrC;AACE,uBAAW;AAAA;AAGf,gBAAM,QAAQ,QAAQ,MAAM,MAAM,KAAK;AAEvC,cAAI,UAAU,MAAM,IAAI,QAAQ;AAC5B,kBAAM,OAAO,sBAAsB;AACnC;AAAA;AAEJ,gBAAM,QAAQ,KAAK,QAAQ,MAAM,MAAM;AAAA;AAE3C;AAAA;AAEJ,aAAO;AAAA;AAAA;AAAA,EAGX,qBAAoC;AAChC,UAAM,OAAM,KAAK;AACjB,QAAI,SAAQ,SAAS;AACjB,YAAM,SAAS,AAAG,oBAAiB,KAAK;AACxC,aAAO;AAAA;AAGX,QAAI,SAAQ,OAAO;AACf,YAAM,SAAS,SAAS;AAAA,QACpB,aAAa,YAAY;AAAA,QACzB,QAAQ;AAAA;AAEZ,aAAO;AAAA;AAEX,UAAM,IAAI,MAAM,2BAA2B,KAAK;AAAA;AAAA,EAGpD,kBAA0B;AACtB,QACI,KAAK,OAAO,WAAW,QACvB,KAAK,OAAO,WAAW,UACvB,KAAK,OAAO,WAAW,OACzB;AACE,aAAO;AAAA;AAGX,QAAI,KAAK,OAAO,WAAW,UAAU;AACjC,aAAO;AAAA;AAGX,UAAM,IAAI,MAAM,wBAAwB,KAAK;AAAA;AAAA,EAGjD,WAAmB;AACf,UAAM,MAAM,OAAO,OAAO;AAE1B,QAAI,CAAC,AAAG,cAAW,KAAK,SAAS;AAC7B,YAAM,IAAI,MAAM,uBAAuB,KAAK;AAAA;AAGhD,UAAM,OAAO,AAAG,YAAS,KAAK;AAE9B,QAAI,KAAK,OAAO,KAAK;AACjB,YAAM,IAAI,MAAM,4BAA4B,KAAK;AAAA;AAErD,WAAO,KAAK;AAAA;AAAA,EAGV,aAA8B;AAAA;AAChC,UAAI,CAAC,KAAK,UAAU,CAAC,KAAK,aAAa;AACnC,cAAM,IAAI,MAAM;AAAA;AAGpB,YAAM,UAAU,AAAG,oBAAiB,KAAK;AAEzC,UAAI,CAAC,QAAQ,UAAU;AACnB,cAAM,IAAI,MAAM;AAAA;AAGpB,YAAM,QAAQ,KAAK;AAEnB,UAAI,QAAQ,MAAM,OAAO,MAAM;AAE3B,gBAAQ,KAAK,aAAa;AAAA;AAG9B,YAAM,EAAC,MAAM,KAAK,QAAO,WAAW,KAAK,aAAa;AAAA,QAClD,MAAM;AAAA;AAGV,UAAI,IAAI,WAAW,WAAW,mBAAmB;AAC7C,cAAM,IAAI,MAAM,2BAA2B;AAAA;AAG/C,UAAI,CAAC,IAAI,MAAM;AACX,YAAI,OAAO,KAAK,SAAS,KAAK;AAC9B,gBAAQ,KAAK,oEAAoE,IAAI;AAAA;AAGzF,cAAQ,IAAI,aAAa,KAAK,aAAa,KAAK;AAEhD,YAAM,MAAK,SAAS;AAAA,QAChB,QAAQ;AAAA;AAGZ,YAAM,MAAM,MAAM,IAAG,KAAK,IAAI,iBAAiB;AAAA,QAC3C,QAAQ,IAAI;AAAA,QACZ,KAAK,IAAI,MAAM,IAAI;AAAA,QACnB,MAAM;AAAA,UACN,MAAM,UAAO;AACb,cAAM,IAAI,MAAM,kDAAkD;AAAA,SACnE,QAAQ,MAAM;AACb,gBAAQ;AAAA;AAEZ,UAAI,IAAI,UAAU,mBAAmB,KAAK;AACtC,cAAM,IAAI,MAAM,kDAAkD,IAAI,UAAU;AAAA;AAGpF,UAAI,CAAC,IAAI,UAAU;AAAW,cAAM,IAAI,MAAM,kDAAkD,IAAI,UAAU;AAC9G,aAAO,IAAI,UAAU;AAAA;AAAA;AAAA,EAQnB,oBACF,QACA,KACe;AAAA;AAEf,YAAM,SAAS,SAAS;AAAA,QACpB,aAAa,YAAY;AAAA,QACzB,QAAQ;AAAA;AAGZ,YAAM,UAAU,IAAI,6BAA6B;AAAA,QAC7C,QAAQ;AAAA,QACR,iBAAiB;AAAA,QACjB,aAAa;AAAA,QACb,KAAK;AAAA;AAGT,YAAM,SAAS,MAAM,OAAO,KAAK;AAEjC,UAAI,OAAO,UAAU,mBAAmB,KAAK;AACzC,cAAM,IAAI,MAAM,mEAAmE,OAAO,6BAA6B,OAAO,UAAU;AAAA;AAG5I,UAAI,CAAC,OAAO,UAAU;AAClB,cAAM,IAAI,MAAM,mEAAmE,OAAO;AAAA;AAG9F,aAAO,OAAO;AAAA;AAAA;AAAA,EAGlB,KAAK,KAAa,MAAgD;AAC9D,YAAQ,IAAI,SAAS,OAAO,KAAK,KAAK;AACtC,WAAO,MAAM,KAAK;AAAA;AAAA,EAGtB,uBAAuB,OAA+D;AAClF,UAAM,SAAwB;AAAA,MAC1B,QAAQ;AAAA,MACR,QAAQ;AAAA,MACR,MAAM;AAAA;AAGV,WAAO,IAAI,QAAQ,CAAC,SAAS,WAAW;AACpC,YAAM,OAAO,GAAG,QAAQ,CAAC,SAAS;AAC9B,eAAO,UAAU;AAAA;AAGrB,YAAM,OAAO,GAAG,QAAQ,CAAC,SAAS;AAC9B,eAAO,UAAU;AAAA;AAGrB,YAAM,GAAG,SAAS,CAAC,SAAS;AACxB,eAAO,OAAO,SAAS,IAAI,IAAI;AAC/B,gBAAQ;AAAA;AAGZ,YAAM,GAAG,SAAS,CAAC,QAAQ;AACvB,eAAO;AAAA;AAAA;AAAA;AAAA;AAWhB,uBAAuB,QAAgB,SAAkC;AAC5E,QAAM,IAAI,IAAI,SAAS,QAAQ;AAC/B,UAAQ,IAAI,CAAC,EAAE,eAAe,EAAE,mBAAmB,EAAE,uBAAuB,KAAK,CAAC,QAAQ;AAAA,KAEvF,MAAM,CAAC,QAAQ;AACd,UAAM,IAAI,MAAM;AAAA;AAEpB,SAAO;AAAA;AAGX,IAAM,QAAS,WAA0C;AACrD,MAAI;AAEJ,kBAAgB;AACZ,UAAM,YAAY,KAAK,KAAK,QAAQ,OAAO;AAE3C,QAAI,CAAC,AAAG,cAAW,YAAY;AAC3B,cAAQ,IAAI,0BAA0B;AACtC,oBAAc,WAAW,KAAK,UAAU;AAAA,WACrC;AACH,cAAQ,IAAI,sBAAsB;AAAA;AAGtC,WAAO;AAAA,MACH,MAAM,IAAI;AAAA,MACV,MAAM;AAAA,MACN,KAAK,CAAC,QAAqC;AACvC,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,YAAI,OAAM,KAAK,WAAW,KAAK;AAC3B,iBAAO;AAAA;AAEX,eAAO,OAAM;AAAA;AAAA,MAEjB,KAAK,CAAC,KAAa,UAAkC;AACjD,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,YAAI,OAAM,MAAM;AACZ;AAAA;AAGJ,eAAM,OAAO;AACb,sBAAc,WAAW,KAAK,UAAU;AACxC,eAAO;AAAA;AAAA,MAEX,KAAK,CAAC,QAAyB;AAC3B,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,YAAI,OAAM,MAAM;AACZ,iBAAO;AAAA;AAEX,eAAO;AAAA;AAAA,MAEX,QAAQ,CAAC,QAAgB;AACrB,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAE9B,eAAO,OAAM;AAEb,sBAAc,WAAW,KAAK,UAAU;AAAA;AAAA,MAE5C,OAAO,MAAM;AACT,sBAAc,WAAW,KAAK,UAAU;AAAA;AAAA,MAE5C,MAAM,MAAM;AACR,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAC9B,eAAO,OAAO,KAAK,QAAO;AAAA;AAAA,MAE9B,MAAM,MAAM;AACR,cAAM,OAAO,aAAa;AAC1B,cAAM,SAAQ,KAAK,MAAM,KAAK;AAC9B,eAAO,OAAO,KAAK;AAAA;AAAA;AAAA;AAK/B,SAAO;AAAA,IACH,aAAa,MAAM;AACf,UAAI,CAAC,QAAO;AACR,iBAAQ;AAAA;AAEZ,aAAO;AAAA;AAAA;AAAA;AAKnB,qBAAe;AAAA,EAOX,YAAY,MAAc;AACtB,SAAK,OAAO;AACZ,SAAK,WAAW,oBAAI;AACpB,SAAK,YAAY,IAAI;AACrB,SAAK,MAAM;AACX,SAAK,SAAS;AAAA;AAAA,EAIlB,OAAkB;AACd,WAAO,MAAM,KAAK,KAAK,SAAS;AAAA;AAAA,EAGpC,OAAO,SAAkB;AACrB,SAAK,SAAS,OAAO,QAAQ;AAAA;AAAA,EAG3B,IAAI,QAAgB,SAA0C;AAAA;AAChE,UAAI,QAAQ,gBAAgB,IAAI;AAC5B,gBAAQ,KAAK,uDAAuD;AAAA;AAMxE,YAAM,UAAU,IAAI,SAAS,QAAQ;AAErC,WAAK,SAAS,IAAI,QAAQ;AAC1B,aAAO;AAAA;AAAA;AAAA;AAUR,wBAAwB,MAAwB;AACnD,SAAO,IAAI,SAAS;AAAA;",
  "names": []
}
